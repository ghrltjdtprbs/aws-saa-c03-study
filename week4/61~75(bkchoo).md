# Q61

## 요구사항
- **애플리케이션**: 2계층 웹 애플리케이션 (EC2 인스턴스에서 실행)
- **백엔드**: Amazon RDS 데이터베이스
- **요구 사항**:
  - 데이터베이스 자격 증명을 **하드코딩하지 말 것**
  - **정기적으로 자격 증명을 자동 교체**하는 솔루션 필요
  - **운영 오버헤드 최소화** 필수

---

## 설명

### A. 인스턴스 메타데이터에 데이터베이스 자격 증명을 저장
- **장점**:
  - EC2 인스턴스 내에서 바로 접근 가능
- **단점**:
  - **EC2 인스턴스 메타데이터는 자격 증명을 저장하는 보안 솔루션이 아님**
  - **EventBridge와 Lambda를 통한 갱신 방식은 복잡하고 운영 오버헤드가 큼**
  - **비밀번호 보호 및 관리 기능 부족**
- **결론**: ❌ 오답 (보안 및 운영 효율성 문제)

---

### B. 암호화된 Amazon S3 버킷의 구성 파일에 데이터베이스 자격 증명을 저장
- **장점**:
  - 암호화된 S3 버킷을 사용하여 보안을 강화할 수 있음
  - S3 버전 관리를 통해 롤백 가능
- **단점**:
  - **S3는 보안 비밀을 저장하는 전문적인 서비스가 아님**
  - **자동 회전 기능 부족 → Lambda와 EventBridge를 통한 관리가 필요하여 운영 부담 증가**
  - **S3 접근 제어 정책을 추가적으로 구성해야 함**
- **결론**: ❌ 오답 (보안 및 운영 오버헤드 문제)

---

### C. AWS Secrets Manager에 데이터베이스 자격 증명을 저장 (✅ 정답)
- **장점**:
  - **보안 비밀(Secret) 저장 전용 서비스**로, AWS에서 공식적으로 권장
  - **자동 자격 증명 회전(Rotation) 기능 제공** → 정기적 갱신 가능
  - **IAM 역할 기반 접근 제어 지원**  
  - **EC2 인스턴스에서 보안 비밀을 안전하게 가져올 수 있음**
- **단점**:
  - 추가 비용 발생 (하지만 운영 효율성을 고려하면 가치 있음)
- **결론**: ✅ 정답 (보안 및 운영 오버헤드 최소화)

---

### D. AWS Systems Manager Parameter Store에 암호화된 파라미터로 저장
- **장점**:
  - AWS KMS 기반 암호화 지원
  - IAM 정책을 활용한 보안 관리 가능
- **단점**:
  - **자동 회전 기능이 없음** → Lambda를 사용하여 수동으로 구현해야 함
  - **Secrets Manager에 비해 보안 비밀 관리 기능이 제한적**
- **결론**: ❌ 오답 (자동 회전 기능 부족)

---

## 정답: ✅ C. AWS Secrets Manager 사용
### 이유:
1. **보안 비밀 저장 전용 서비스**이므로 **보안성이 높음**
2. **자동 회전 기능을 지원**하여 **운영 오버헤드 최소화**
3. **IAM 역할을 통한 접근 제어 가능**
4. AWS 공식 문서에서도 데이터베이스 자격 증명 관리 시 **Secrets Manager 사용을 권장**

---

# Q62

## 요구사항
- **애플리케이션**: ALB(Application Load Balancer) 뒤에서 실행되는 공개 웹 애플리케이션
- **보안 요구 사항**:
  - **외부 CA(인증 기관)에서 발급한 SSL/TLS 인증서를 사용해야 함**
  - **에지(Edge)에서 암호화 필요**
  - **인증서를 매년 교체해야 함**
- **운영 오버헤드 최소화 필요**

---

## 설명

### A. AWS Certificate Manager(ACM)를 사용하여 인증서를 발급하고 자동 갱신
- **장점**:
  - ACM은 **AWS에서 제공하는 공용 인증서 자동 갱신 기능**을 지원
  - ALB와 통합하여 **자동 갱신 및 적용 가능**
- **단점**:
  - **문제 요구 사항에서는 "외부 CA에서 발급한 인증서"를 사용해야 함**  
  - **ACM의 자동 갱신 기능은 AWS에서 발급한 인증서에만 해당됨**  
- **결론**: ❌ 오답 (외부 CA 인증서 요구사항을 충족하지 않음)

---

### B. AWS ACM에서 키 자료를 가져와 ALB에 인증서 적용 후 자동 갱신
- **장점**:
  - AWS ACM을 통해 인증서를 발급 및 적용 가능
- **단점**:
  - **ACM에서 키 자료를 직접 가져와 적용하는 방식은 지원되지 않음**
  - **키 자료를 직접 관리하는 것은 보안상 바람직하지 않음**
- **결론**: ❌ 오답 (잘못된 키 관리 방식)

---

### C. ACM 사설 인증 기관(Private CA)을 사용하여 루트 CA에서 인증서 발급 후 자동 갱신
- **장점**:
  - AWS Private CA는 내부 조직을 위한 **사설 인증서 발급**을 지원
- **단점**:
  - **사설 CA는 내부 시스템용이며, 공용 웹 애플리케이션에는 사용할 수 없음**
  - **공개 웹사이트에 필요한 외부 CA 인증서를 제공하지 않음**
- **결론**: ❌ 오답 (사설 CA는 내부용, 문제 요구사항과 맞지 않음)

---

### D. ACM을 사용하여 외부에서 발급한 인증서를 가져오고 EventBridge로 알림 후 수동 교체 (✅ 정답)
- **장점**:
  - **ACM을 사용하여 외부 CA에서 발급한 인증서를 가져와 적용 가능**
  - **ALB와 통합하여 SSL/TLS 트래픽을 보호 가능**
  - **EventBridge(Amazon CloudWatch Events)를 활용하여 인증서 만료 전에 알림 설정 가능**
  - **외부 인증서는 ACM의 자동 갱신 대상이 아니므로, 수동 교체가 필요함**
- **단점**:
  - **인증서를 직접 갱신해야 하는 운영 오버헤드 발생**
- **결론**: ✅ 정답 (외부 CA 인증서 요구사항을 충족하고, 인증서 갱신을 위한 적절한 관리 방법 제공)

---

## 정답: ✅ D. AWS Certificate Manager(ACM)를 사용하여 외부 CA 인증서를 가져오고, EventBridge를 사용하여 만료 알림 후 수동 교체
### 이유:
1. **문제 요구사항에서 외부 CA에서 발급한 인증서를 사용해야 함**  
   - ACM의 자동 갱신 기능은 **AWS에서 발급한 인증서에만 적용됨**  
   - 외부 CA 인증서는 자동 갱신이 불가능하므로 **수동 교체 필요**
2. **AWS ACM을 통해 외부 CA 인증서를 가져와 ALB에 적용 가능**
3. **Amazon EventBridge(Amazon CloudWatch Events)를 사용하여 인증서 만료 알림 가능**
4. **AWS에서 공식적으로 권장하는 외부 인증서 관리 방법과 일치**

---
# Q63

## 요구사항
- **대상 애플리케이션**: 문서 관리 애플리케이션 (700,000명 사용자 기반)  
- **주요 기능**:  
  - 평균 5MB 크기의 **.pdf 파일을 .jpg로 변환**  
  - 원본 파일(.pdf)과 변환된 파일(.jpg) **모두 저장**  
  - **급증하는 수요를 감당할 수 있는 확장 가능한 솔루션** 필요  
  - **비용 효율적이어야 함**  

---

## 정답: ✅ A. Amazon S3 + AWS Lambda 활용  

### 이유:  
1. **확장성(Scalability)**:  
   - S3는 무제한 스토리지 제공  
   - Lambda는 이벤트 기반으로 확장 가능  

2. **비용 효율성(Cost Efficiency)**:  
   - Lambda는 사용한 만큼만 비용이 발생 → EC2보다 저렴  
   - S3는 저비용 스토리지 제공 → EBS/EFS보다 경제적  

3. **자동화(Auto-processing)**:  
   - **S3 PUT 이벤트 트리거** → 파일 업로드 시 자동 변환 실행  
   - 별도 서버 운영 없이 **완전 관리형(serverless) 아키텍처**  

4. **운영 부담 최소화**:  
   - EC2 인프라 관리 불필요  
   - 유지보수 부담 없이 **파일 변환 자동 처리 가능**
     
---  

- A(O) : S3 에 넣으면 Lambda 를 통해 자동으로 처리가 되도록 하는 거라 OK. S3 는 저렴함.
- B(X) : dynamodb 는 이미지 저장용으론…
- C(X) : 저렴한 S3 가 있는데 굳이... 인스턴스 비용도 나감.
- D(x) : C 와 마찬가지.

---
# Q64

## 요구사항
- **대상 환경**: 온프레미스 Windows 파일 서버 (5TB 이상 데이터 보유)  
- **주요 요구사항**:  
  - AWS 마이그레이션 진행 중  
  - **온프레미스 & AWS 간 최소 지연시간 보장**  
  - **운영 오버헤드 최소화**  
  - **기존 파일 액세스 패턴 변경 없이 유지**  
  - AWS 연결 방식: **Site-to-Site VPN 사용**  

---

## 정답: ✅ D. **Amazon FSx + FSx 파일 게이트웨이 사용**  

### 이유:  
1. **Windows 환경에 최적화**  
   - **Amazon FSx for Windows File Server**는 **네이티브 SMB 프로토콜** 지원  
   - Active Directory 통합 가능 → 기존 Windows 워크로드와 호환  

2. **온프레미스 및 클라우드 간 원활한 파일 공유**  
   - **FSx 파일 게이트웨이**를 온프레미스에 배포 → 로컬 캐싱으로 **지연 시간 최소화**  
   - 클라우드 워크로드는 FSx를 직접 사용  

3. **운영 오버헤드 최소화**  
   - **기존 파일 액세스 패턴 유지** → 사용자 및 애플리케이션 변경 불필요  
   - **AWS 관리형 서비스**로 유지보수 부담 감소  

4. **VPN 연결과 호환 가능**  
   - FSx 파일 게이트웨이가 Site-to-Site VPN을 통해 AWS FSx와 연결 가능  

---
# Q65

## 요구사항  
- **환경**: 병원이 Amazon API Gateway + AWS Lambda 기반 RESTful API 사용  
- **업무 내용**: PDF 및 JPEG 보고서 업로드 처리  
- **주요 요구사항**:  
  - **보고서에서 보호되는 건강 정보(PHI) 식별 필요**  
  - **Lambda 코드를 수정하여 기능 추가**  
  - **운영 오버헤드 최소화**  

---

## 설명 

### A. **기존 Python 라이브러리를 사용하여 PHI 식별**  
- **구성**:  
  - Python의 OCR 라이브러리(예: Tesseract)로 보고서에서 텍스트 추출  
  - 문자열 분석을 통해 PHI 정보 탐색  

- **단점**:  
  - **OCR 품질이 낮을 가능성 있음** → 특히 비정형 문서에서 정확도가 떨어질 수 있음  
  - **PHI 식별을 위한 규칙 기반 접근 방식은 한계가 있음** → 머신러닝 기반 분석보다 부정확  
  - **추가적인 코드 및 데이터 관리 필요** → 운영 오버헤드 증가  

- **결론**: ❌ **오답** (운영 오버헤드 높음, 정확도 낮음)  

---

### B. **Amazon Textract + Amazon SageMaker 사용**  
- **구성**:  
  - Textract로 보고서에서 텍스트 추출  
  - SageMaker를 사용해 맞춤형 ML 모델을 학습하여 PHI 식별  

- **단점**:  
  - **SageMaker에서 직접 ML 모델을 학습해야 함** → 데이터 준비, 학습, 배포 필요  
  - **PHI 분석을 위한 머신러닝 모델을 병원이 직접 운영해야 함** → 운영 오버헤드 증가  

- **결론**: ❌ **오답** (추가적인 ML 모델 관리 필요)  

---

### C. **Amazon Textract + Amazon Comprehend Medical 사용** (✅ 정답)  
- **구성**:  
  - **Amazon Textract** → PDF 및 JPEG 보고서에서 텍스트 자동 추출  
  - **Amazon Comprehend Medical** → 추출된 텍스트에서 PHI(개인 건강 정보) 자동 식별  

- **장점**:  
  - **AWS 관리형 서비스 사용** → 추가적인 모델 학습 및 배포 필요 없음  
  - **운영 오버헤드 최소화** → Lambda 코드에서 API 호출만 추가하면 됨  
  - **Comprehend Medical이 의료 데이터 분석에 특화됨** → 정확도 높음  

- **결론**: ✅ **정답** (운영 부담 최소화, 정확도 높음)  

---

### D. **Amazon Rekognition + Amazon Comprehend Medical 사용**  
- **구성**:  
  - Rekognition을 사용하여 이미지에서 텍스트 추출  
  - Comprehend Medical을 사용하여 PHI 식별  

- **단점**:  
  - **Rekognition은 주로 얼굴 인식 및 객체 탐지에 최적화됨**  
  - **OCR 기능은 제공하지만, 문서 분석에는 Textract가 더 적합**  
  - **PDF 문서에는 Rekognition을 사용할 수 없음** → JPEG만 처리 가능  

- **결론**: ❌ **오답** (문서 OCR에는 Textract가 더 적합)  

---

## **정답: ✅ C. Amazon Textract + Amazon Comprehend Medical 사용**  
- **운영 오버헤드 최소화**: AWS 관리형 서비스 활용  
- **최적의 구성**: Textract → **정확한 문서 OCR**, Comprehend Medical → **PHI 자동 식별**  
- **Lambda에서 간단한 API 호출로 구현 가능**
---

# **Q66: 파일 스토리지 솔루션 선택**

## **요구사항**  
- **파일 크기**: 약 5MB  
- **파일 저장소**: Amazon S3  
- **파일 보존 기간**: 4년  
- **파일 액세스 패턴**: 객체 생성 후 첫 30일 동안 자주 액세스되며, 이후에는 거의 액세스되지 않음  
- **비즈니스 데이터 중요성**: 재생산이 어려운 중요한 데이터 포함, 즉각적인 액세스 필요

---

### **설명**  

#### **A. 객체 생성 후 30일 동안 S3 Standard에서 S3 Glacier로 파일을 이동하는 S3 버킷 수명 주기 정책을 생성합니다. 객체 생성 후 4년이 지나면 파일을 삭제합니다. (❌ 오답)**  
- **설명**:  
  - **S3 Glacier**는 저비용 스토리지로, 주로 장기 보관용으로 사용됩니다. 하지만 **즉각적인 액세스가 항상 필요**한 파일에 적합하지 않습니다.  
  - **S3 Glacier**는 검색에 시간이 걸리므로 비즈니스 요구 사항에 맞지 않음.  

- **결론**: ❌ **오답** (즉각적인 액세스가 필요하므로 S3 Glacier는 적합하지 않음)  

---

#### **B. 객체 생성 후 30일 동안 S3 Standard에서 S3 One Zone-Infrequent Access(S3 One Zone-IA)로 파일을 이동하는 S3 버킷 수명 주기 정책을 생성합니다. 객체 생성 후 4년이 지나면 파일을 삭제합니다. (❌ 오답)**  
- **설명**:  
  - **S3 One Zone-IA**는 단일 가용 영역에서 데이터를 저장하여 비용을 절감할 수 있지만, **데이터 내구성**이 **S3 Standard-IA**보다 낮습니다.  
  - 데이터 손실 위험이 있을 수 있으므로 중요한 비즈니스 데이터를 저장하기에는 부적합.  

- **결론**: ❌ **오답** (내구성 문제가 있어 중요한 데이터에 적합하지 않음)  

---

#### **C. 객체 생성 후 30일 동안 S3 Standard에서 S3 Standard-Infrequent Access(S3 Standard-IA)로 파일을 이동하는 S3 버킷 수명 주기 정책을 생성합니다. 객체 생성 후 4년이 지나면 파일을 삭제합니다. (✅ 정답)**  
- **설명**:  
  - **S3 Standard-IA**는 자주 액세스되지 않는 데이터에 적합하며, **즉각적인 액세스**를 제공하면서 비용 효율적인 스토리지 옵션입니다.  
  - **4년 후 삭제**는 파일 삭제 정책으로 적합합니다.  

- **결론**: ✅ **정답** (즉각적인 액세스가 필요한 데이터를 저장하면서 비용을 절감할 수 있는 적합한 선택)  

---

#### **D. 객체 생성 후 30일 동안 S3 Standard에서 S3 Standard-Infrequent Access(S3 Standard-IA)로 파일을 이동하는 S3 버킷 수명 주기 정책을 생성합니다. 객체 생성 4년 후 파일을 S3 Glacier로 이동합니다. (❌ 오답)**  
- **설명**:  
  - **4년 후 S3 Glacier로 이동**하는 것은 파일이 거의 액세스되지 않더라도 **즉각적인 액세스**가 필요한 경우 부적합합니다.  
  - **S3 Standard-IA**는 파일이 거의 액세스되지 않더라도 **즉각적인 액세스**를 지원하므로, 파일을 **S3 Glacier로 이동할 필요가 없음**.  

- **결론**: ❌ **오답** (즉각적인 액세스가 계속 필요하기 때문에 S3 Glacier로 이동하는 것은 적합하지 않음)  

---

## **정답: ✅ C**  
- **C. 객체 생성 후 30일 동안 S3 Standard에서 S3 Standard-Infrequent Access(S3 Standard-IA)로 파일을 이동하는 S3 버킷 수명 주기 정책을 생성합니다. 객체 생성 후 4년이 지나면 파일을 삭제합니다.**  
- **비용 효율적**이고 **즉각적인 액세스**를 지원하는 적합한 스토리지 솔루션입니다.

---
# Q67  

## 요구사항  
- **환경**: Amazon EC2 인스턴스에서 애플리케이션 실행  
- **구성 요소**:  
  - **Amazon SQS** → 메시지 대기열에서 작업 요청 수신  
  - **Amazon RDS** → 데이터 저장  
- **문제점**:  
  - 가끔 RDS 테이블에 **중복 레코드**가 발생  
  - 하지만 **SQS 대기열 자체에는 중복 메시지가 없음**  
- **목표**: 메시지를 **한 번만** 처리하도록 개선  

---

## 설명

### A. **CreateQueue API 호출을 사용하여 새 대기열 생성**  
- **설명**:  
  - `CreateQueue` API는 새로운 SQS 대기열을 생성하는 데 사용됨  
  - 기존 대기열이 중복 메시지를 보내지 않으므로 **대기열을 새로 생성해도 중복 문제 해결 불가**  

- **결론**: ❌ **오답** (새 대기열을 만든다고 중복이 해결되지 않음)  

---

### B. **AddPermission API 호출을 사용하여 권한 추가**  
- **설명**:  
  - `AddPermission` API는 SQS 대기열의 액세스 권한을 관리하는 데 사용됨  
  - 현재 문제는 **중복 레코드 발생**이지 **권한 문제**가 아님  

- **결론**: ❌ **오답** (권한 문제와 무관)  

---

### C. **ReceiveMessage API 호출을 사용하여 적절한 대기 시간 설정**  
- **설명**:  
  - `ReceiveMessage` API에서 `WaitTimeSeconds` 값을 설정하면 **긴 폴링**(Long Polling) 가능  
  - 하지만 긴 폴링은 메시지 수신 방식을 최적화할 뿐, **중복 처리 문제 해결과 무관**  

- **결론**: ❌ **오답** (메시지 수신 방식과 관련, 중복 방지 효과 없음)  

---

### D. **ChangeMessageVisibility API 호출을 사용하여 가시성 시간 초과(Visibility Timeout) 증가** (✅ 정답)  
- **설명**:  
  - **SQS는 기본적으로 최소 1회 전달(at-least-once delivery) 보장**  
  - 메시지가 **처리 중인 동안 가시성 시간 초과(Visibility Timeout)** 가 만료되면, **다른 EC2 인스턴스가 같은 메시지를 다시 가져갈 수 있음** → **중복 처리 발생 가능**  
  - `ChangeMessageVisibility` API를 사용해 **가시성 시간 초과를 늘리면**, 같은 메시지가 다른 인스턴스에서 중복 처리되는 문제 해결 가능  

- **결론**: ✅ **정답** (가시성 시간 초과 증가로 중복 방지)  

---

## **정답: ✅ D. ChangeMessageVisibility API 호출을 사용하여 가시성 시간 초과를 늘림**  
- **중복 발생 원인**: 메시지 처리 시간이 초과되어 다른 인스턴스가 메시지를 재처리함  
- **해결 방법**: `ChangeMessageVisibility` API를 사용해 가시성 시간 초과를 증가  
- **결과**: 메시지가 완료될 때까지 다른 인스턴스에서 가져가지 않도록 보호됨  
---
# Q68  

## 요구사항  
- **온프레미스 인프라 → AWS 확장**  
- **짧은 지연 시간 & 고가용성 보장**  
- **비용 최소화**  
- **기본 연결 장애 시 더 느린 트래픽 허용 가능**  

---

## 설명

### A. **Direct Connect + VPN 백업 (✅ 정답)**  
- **설명**:  
  - **AWS Direct Connect(DX)** → 저지연, 안정적인 전용 연결  
  - **AWS Site-to-Site VPN** → 백업 연결로 사용 (저비용)  
  - **DX 장애 발생 시 VPN으로 트래픽 전환** (비용 절감 & 가용성 보장)  
  - AWS 공식 문서에서도 DX 백업으로 VPN을 권장함  

- **결론**: ✅ **정답** (비용 절감 + 고가용성 유지)  

---

### B. **VPN 터널 두 개 사용 (❌ 오답)**  
- **설명**:  
  - **VPN만 사용** → 낮은 비용이지만 **Direct Connect보다 높은 지연 시간**  
  - **고가용성은 유지 가능하지만 지연 시간 요구 사항 충족 불가**  

- **결론**: ❌ **오답** (Direct Connect 없이 VPN만 사용하면 저지연 요구 사항 미충족)  

---

### C. **Direct Connect 이중화 (❌ 오답)**  
- **설명**:  
  - **DX 두 개를 동일 리전에 프로비저닝** → 고가용성 보장  
  - 하지만 **비용이 높음** (VPN보다 더 비싼 백업 옵션)  
  - 문제에서 "비용 최소화"가 중요하므로 적절하지 않음  

- **결론**: ❌ **오답** (비용 절감 목표와 맞지 않음)  

---

### D. **Direct Connect 장애 조치 속성 사용 (❌ 오답)**  
- **설명**:  
  - **AWS CLI에서 Direct Connect 장애 조치 설정**  
  - 하지만 **자동 백업 연결을 제공하지 않음**  
  - **대체 연결**을 자동으로 생성하는 기능은 존재하지 않음  

- **결론**: ❌ **오답** (Direct Connect 장애 시 VPN 같은 백업이 필요)  

---

## **정답: ✅ A. Direct Connect + VPN 백업**  
- **DX → 저지연 및 안정적 연결 제공**  
- **VPN → 비용 절감 백업 솔루션으로 사용**  
- **DX 장애 발생 시 VPN으로 트래픽 전환 가능**  
- **AWS 권장 아키텍처**  

---
# Q69

## 요구사항

- **EC2 인스턴스 + ALB + Auto Scaling 그룹 사용**
- **Aurora PostgreSQL 단일 가용 영역 배포**
- **다운타임과 데이터 손실 최소화**
- **최소한의 운영 노력으로 고가용성 보장**

---

## 설명

### A. **EC2 인스턴스를 다른 리전에 배치 + Route 53 + Aurora 교차 리전 복제 (❌ 오답)**

- **설명**:

  - EC2 인스턴스를 **다른 리전에 배치** → 리전 간 전환이 복잡하고 운영 부담 증가
  - **Route 53 상태 확인**으로 트래픽 리디렉션 가능하지만 리전 간 네트워크 지연 발생
  - **Aurora 교차 리전 복제** 가능하지만 다중 AZ보다 장애 조치 시간이 김
  - **다중 AZ 구성이 더 바람직함**

- **결론**: ❌ **오답** (다중 AZ 사용이 더 적절함, 불필요한 리전 간 배포)

---

### B. **다중 AZ Auto Scaling + 다중 AZ 데이터베이스 + RDS 프록시 (✅ 정답)**

- **설명**:

  - **Auto Scaling 그룹을 여러 가용 영역에 배포** → 단일 AZ 장애 대비
  - **Aurora 다중 AZ 배포** → 자동 장애 조치 지원
  - **Amazon RDS 프록시 사용** → 연결 풀링으로 장애 조치 시간 단축 및 가용성 향상
  - **운영 부담 최소화 & 데이터 손실 방지 & 고가용성 보장**

- **결론**: ✅ **정답** (다중 AZ + Auto Scaling + RDS Proxy로 고가용성 확보)

---

### C. **단일 AZ Auto Scaling + 데이터베이스 스냅샷 복구 (❌ 오답)**

- **설명**:

  - **하나의 가용 영역만 사용** → 장애 발생 시 서비스 중단 위험
  - **시간별 스냅샷 생성** → 데이터 복구 가능하지만 **장애 조치 속도가 느림**
  - **다운타임 최소화 요구사항 미충족**

- **결론**: ❌ **오답** (다중 AZ 사용 필요, 스냅샷 복구 방식은 장애 조치 속도가 느림)

---

### D. **다중 리전 Auto Scaling + S3 이벤트 기반 Lambda 데이터 쓰기 (❌ 오답)**

- **설명**:

  - **다중 리전 배포** → 운영 부담 증가 및 네트워크 비용 증가
  - **S3 이벤트 + Lambda를 통한 데이터 처리** → 복잡한 아키텍처, RDS 직접 쓰기가 더 효과적
  - **Aurora 다중 AZ보다 장애 조치 속도가 느림**

- **결론**: ❌ **오답** (불필요한 복잡성 증가, 다중 AZ Aurora가 더 적절함)

---

## **정답: ✅ B. 다중 AZ Auto Scaling + 다중 AZ Aurora + RDS 프록시**

- **Auto Scaling 그룹을 다중 AZ로 구성** → EC2 인스턴스 가용성 확보
- **Aurora 다중 AZ 구성** → 자동 장애 조치로 데이터 손실 방지
- **Amazon RDS Proxy 사용** → 연결 장애 최소화 및 가용성 향상
- **운영 부담 최소화하면서 고가용성 보장**
---
# Q70

## 요구사항

- HTTP 애플리케이션이 NLB(Network Load Balancer) 뒤에서 실행됨.
- NLB의 대상 그룹은 EC2 Auto Scaling 그룹을 사용하여 웹 서비스 제공.
- NLB가 HTTP 오류를 감지하지 못함, 오류 발생 시 EC2 인스턴스를 수동으로 재시작해야 함.
- 사용자 정의 스크립트나 코드 없이 애플리케이션의 가용성을 개선해야 함.


## 설명
### A. NLB에서 HTTP 상태 확인 활성화 (❌ 오답)
- 설명:

  - NLB는 L4(Network Layer) 로드 밸런서로, HTTP 상태 확인을 지원하지 않음.
  - NLB의 상태 확인은 TCP 수준에서만 동작하며, HTTP 오류(예: 500 에러)를 감지할 수 없음.
  - HTTP 상태 확인을 지원하려면 Application Load Balancer(ALB)가 필요함.
결론: ❌ 오답 (NLB는 HTTP 상태 확인을 제공하지 않음)

### B. EC2 인스턴스에 cron 작업 추가 (❌ 오답)
- 설명:

  - 로컬에서 애플리케이션 로그를 확인하고, HTTP 오류가 감지되면 EC2 인스턴스를 재시작하는 방식.
    하지만 수동 스크립트 및 코드 없이 문제를 해결해야 하므로 요구사항에 부합하지 않음.
    또한, 로컬 감시는 중앙 집중식 로드 밸런서 기반 가용성 관리보다 효율성이 떨어짐.
  - 결론: ❌ 오답 (사용자 정의 스크립트 없이 해결해야 함)

### C. NLB → ALB로 교체 + HTTP 상태 확인 + Auto Scaling 조정 (✅ 정답)
- 설명:

  - Application Load Balancer(ALB)는 L7(Application Layer) 로드 밸런서로 HTTP 상태 확인을 지원함.
  - ALB에서 HTTP 상태 확인을 활성화하여 HTTP 오류를 감지 가능.
  - Auto Scaling 그룹과 연계하여 비정상 인스턴스를 자동으로 교체할 수 있음.
  - 사용자가 직접 스크립트를 작성하지 않고도 AWS 기본 기능만으로 해결 가능.
  - 결론: ✅ 정답 (HTTP 상태 확인 + 자동 복구 지원)

### D. NLB의 UnhealthyHostCount 지표 모니터링 + CloudWatch 알람 (❌ 오답)
-설명:
  - NLB는 TCP 상태 확인만 지원하므로, HTTP 오류를 감지할 수 없음.
  - CloudWatch 알람을 설정한다고 해도 HTTP 오류를 직접 감지하는 것이 아니라 비효율적임.
  - HTTP 오류가 발생한 경우에도 TCP 연결이 유지되면 비정상 인스턴스가 감지되지 않을 수 있음.
  - 결론: ❌ 오답 (NLB는 HTTP 상태 확인이 불가능하며, CloudWatch만으로 해결 불가)

## 정답: ✅ C. NLB → ALB로 교체 + HTTP 상태 확인 + Auto Scaling 조정
- ALB는 L7 로드 밸런서로 HTTP 상태 확인을 지원하여 HTTP 오류를 감지 가능.
- Auto Scaling 그룹과 연계하여 비정상 인스턴스를 자동으로 교체 가능.
- 사용자 정의 스크립트 없이 AWS 기본 기능만으로 문제 해결 가능.
- 가용성과 운영 편의성을 동시에 만족하는 최적의 솔루션.

--- 
# **Q71**  

## **요구사항**  
- **Amazon DynamoDB를 사용하여 고객 정보 저장**  
- 데이터 손상 발생 시 **RPO(복구 시점 목표) 15분, RTO(복구 시간 목표) 1시간을 충족해야 함**  
- **빠르고 효과적인 데이터 복구 방법 필요**  

---  

### **설명**  

#### **A. DynamoDB 전역 테이블 구성 (❌ 오답)**  
- **설명**:  
  - DynamoDB **전역 테이블(Global Table)은 다중 리전 고가용성을 제공**하지만, **RPO 15분 요구사항과 직접적인 연관 없음**.  
  - 전역 테이블은 **데이터 동기화** 목적이지, 특정 시점으로 데이터 복원을 제공하지 않음.  
  - 데이터가 손상된 경우, **잘못된 데이터가 모든 리전으로 동기화될 위험**이 있음.  

- **결론**: ❌ **오답** (전역 테이블은 RPO 보장 솔루션이 아님)  

---  

#### **B. DynamoDB 지정 시간 복구(Point-in-Time Recovery, PITR) 구성 (✅ 정답)**  
- **설명**:  
  - **DynamoDB PITR(Point-in-Time Recovery)**는 **최대 35일 내의 특정 시점으로 테이블 복원을 지원**함.  
  - **RPO 15분 요구사항을 충족**하며, **RTO 1시간 내에 복원 가능**.  
  - **AWS에서 제공하는 기본 기능**으로 추가적인 설정이나 관리가 필요 없음.  

- **결론**: ✅ **정답** (최소한의 운영 노력으로 RPO & RTO 충족)  

---  

#### **C. DynamoDB 데이터를 매일 Amazon S3 Glacier로 내보내기 (❌ 오답)**  
- **설명**:  
  - S3 Glacier는 **장기 백업용** 스토리지로, 빠른 복구에는 적합하지 않음.  
  - **데이터 복원 시간이 수 시간~수일 소요될 가능성**이 있음.  
  - **RPO 15분 & RTO 1시간 요구사항을 충족할 수 없음**.  

- **결론**: ❌ **오답** (복구 시간이 너무 길어 요구사항 미충족)  

---  

#### **D. DynamoDB 테이블을 Amazon EBS 스냅샷으로 백업 (❌ 오답)**  
- **설명**:  
  - **DynamoDB는 EBS 볼륨 기반이 아니므로 EBS 스냅샷으로 직접 백업 불가능**.  
  - EBS 스냅샷은 **EC2 인스턴스나 RDS에 적합한 백업 방식**.  
  - **잘못된 백업 방법 선택**으로 DynamoDB 데이터 복구 불가능.  

- **결론**: ❌ **오답** (DynamoDB에는 EBS 스냅샷을 사용할 수 없음)  

---  

## **정답: ✅ B. DynamoDB 지정 시간 복구(Point-in-Time Recovery, PITR) 구성**  
- **PITR → 최대 35일 내 특정 시점으로 복원 가능**  
- **RPO 15분, RTO 1시간 요구사항 충족**  
- **추가적인 운영 노력 없이 자동화된 솔루션**  
- **AWS 권장 아키텍처**
---
# **Q72**  

## **요구사항**  
- **Amazon S3 버킷에서 사진을 자주 업로드 및 다운로드 해야 하는 사진 처리 어플리케이션을 실행**  
- 비용을 줄이기 위한 솔루션 구현
---  

## **정답: ✅ D. S3 VPC 게이트웨이 엔드포인트를 VPC 에 배포하고 S3 버킷에 대한 액세스를 허용하는
엔드포인트 정책을 연결합니다.**  
- **S3 VPC 게이트웨이 엔드포인트를 VPC 에 배포하고 S3 버킷에 대한 액세스를 허용하는 엔드포인트 정책을 연결**  
- 위와 같이 배포하면 애플리케이션이 VPC 내의 프라이빗 네트워크 연결을 통해 S3 버킷에 액세스할 수 있으므로 인터넷을 통한 데이터 전송이 필요하지 않음.
---
# **Q73**  

## **요구사항**  
- **퍼블릭 서브넷**: 배스천 호스트 (Bastion Host, Linux 기반)  
- **프라이빗 서브넷**: 애플리케이션 서버 (Linux 기반)  
- **사내 네트워크 → 인터넷 → 배스천 호스트 → 애플리케이션 서버로 접근 가능해야 함**  
- **EC2 보안 그룹이 올바르게 설정되어야 함**  

---  

### **설명**  

#### **A. 배스천 호스트 보안 그룹을 애플리케이션 인스턴스만 허용하도록 변경 (❌ 오답)**  
- **설명**:  
  - 배스천 호스트는 **사내 네트워크에서 접근 가능해야 함**.  
  - 애플리케이션 서버만 허용하면 **배스천 호스트에 대한 외부 접근이 차단됨**.  

- **결론**: ❌ **오답** (배스천 호스트가 사내 네트워크에서 접근 불가능해짐)  

---  

#### **B. 배스천 호스트 보안 그룹을 내부 IP 범위에서만 허용하도록 변경 (❌ 오답)**  
- **설명**:  
  - "내부 IP"는 VPC 내부에서만 사용됨.  
  - **사내 네트워크에서 배스천 호스트로 연결해야 하므로 외부 IP를 허용해야 함**.  

- **결론**: ❌ **오답** (사내 네트워크에서 배스천 호스트로 접근 불가)  

---  

#### **C. 배스천 호스트 보안 그룹을 회사의 외부 IP에서만 허용하도록 변경 (✅ 정답)**  
- **설명**:  
  - 사내 네트워크에서 인터넷을 통해 **배스천 호스트(퍼블릭 IP)에 접근해야 함**.  
  - 보안 그룹에서 **회사 사내 네트워크의 외부 IP만 허용해야 보안이 강화됨**.  

- **결론**: ✅ **정답** (보안성을 유지하면서 배스천 호스트 접근 허용)  

---  

#### **D. 애플리케이션 인스턴스 보안 그룹을 배스천 호스트의 프라이빗 IP만 허용하도록 변경 (✅ 정답)**  
- **설명**:  
  - **배스천 호스트 → 애플리케이션 서버로 SSH 접속 가능해야 함**.  
  - 프라이빗 서브넷에 있는 애플리케이션 서버는 **퍼블릭 인터넷을 통하지 않음**.  
  - 따라서 보안 그룹에서 **배스천 호스트의 프라이빗 IP만 허용해야 보안이 강화됨**.  

- **결론**: ✅ **정답** (배스천 호스트를 통한 안전한 SSH 접근 허용)  

---  

#### **E. 애플리케이션 인스턴스 보안 그룹을 배스천 호스트의 공용 IP만 허용하도록 변경 (❌ 오답)**  
- **설명**:  
  - 배스천 호스트에서 **프라이빗 서브넷의 애플리케이션 서버로 SSH 연결할 때는 프라이빗 IP를 사용**.  
  - 공용 IP를 사용하면 **VPC 내부 통신이 불필요하게 인터넷을 거쳐야 하므로 비효율적이고 보안상 위험**.  

- **결론**: ❌ **오답** (배스천 호스트의 퍼블릭 IP를 허용하면 불필요한 보안 위험 발생)  

---  

## **정답: ✅ C, D**  
- **C. 배스천 호스트 보안 그룹에서 회사 외부 IP만 허용** → 사내 네트워크에서 안전하게 접근  
- **D. 애플리케이션 인스턴스 보안 그룹에서 배스천 호스트의 프라이빗 IP만 허용** → 내부 보안 강화  
- **AWS 보안 모범 사례를 준수하는 접근 방식**
---
# **Q74: 2계층 웹 애플리케이션의 보안 그룹 구성**  

## **요구사항**  
- **웹 계층**: 퍼블릭 서브넷에서 Amazon EC2에서 호스팅  
- **데이터베이스 계층**: 프라이빗 서브넷에서 Microsoft SQL Server 실행  
- **보안이 최우선**  

---

### **설명**  

#### **A. 0.0.0.0/0에서 포트 443(HTTPS) 인바운드 허용 (✅ 정답)**  
- **설명**:  
  - 웹 계층은 **인터넷에서 직접 접근 가능해야 하므로 443(HTTPS) 포트를 열어야 함**.  
  - 보안 강화를 위해 **포트 80(HTTP)가 아닌 443(HTTPS) 사용**.  

- **결론**: ✅ **정답** (웹 계층이 인터넷에서 HTTPS 트래픽을 수신 가능해야 함)  

---

#### **B. 0.0.0.0/0에서 포트 443 아웃바운드 허용 (❌ 오답)**  
- **설명**:  
  - 아웃바운드 트래픽은 기본적으로 모든 트래픽이 허용됨 (보안 그룹 기본 설정).  
  - 추가적인 443 포트 아웃바운드 설정이 **필수적이지 않음**.  

- **결론**: ❌ **오답** (불필요한 설정)  

---

#### **C. 웹 계층의 보안 그룹에서 포트 1433(SQL Server) 인바운드 허용 (✅ 정답)**  
- **설명**:  
  - **웹 계층 → 데이터베이스 계층** 간 통신을 위해 **포트 1433(SQL Server) 허용**해야 함.  
  - **단, 1433을 전체 허용하는 것이 아니라 웹 계층의 보안 그룹만 허용해야 함**.  

- **결론**: ✅ **정답** (웹 계층이 데이터베이스에 접근 가능해야 함)  

---

#### **D. 데이터베이스 계층에서 포트 443, 1433 아웃바운드 트래픽을 웹 계층으로 전달 (❌ 오답)**  
- **설명**:  
  - **데이터베이스 계층에서 웹 계층으로 아웃바운드 트래픽이 필요 없음**.  
  - 웹 계층이 데이터베이스에 접근하는 것이지, 반대로 데이터베이스가 웹 계층에 요청할 필요 없음.  

- **결론**: ❌ **오답** (불필요한 설정)  

---

#### **E. 데이터베이스 계층에서 포트 443 및 1433의 인바운드 트래픽 허용 (❌ 오답)**  
- **설명**:  
  - **443(HTTPS)는 웹 계층에서 사용하며, 데이터베이스 계층에서는 필요 없음**.  
  - **1433(SQL Server)만 허용해야 하며, 웹 계층의 보안 그룹만 허용해야 함**.  

- **결론**: ❌ **오답** (불필요한 포트 열림)  

---

## **정답: ✅ A, C**  
- **A. 0.0.0.0/0에서 포트 443(HTTPS) 인바운드 허용** → 웹 계층이 인터넷에서 접근 가능해야 함  
- **C. 웹 계층의 보안 그룹에서 포트 1433(SQL Server) 인바운드 허용** → 웹 계층이 데이터베이스 계층에 접근 가능해야 함  
- **보안 모범 사례 준수** ✅
---
# **Q75**  

## **요구사항**  
- **다계층 애플리케이션**을 온프레미스에서 AWS로 이전  
- **RESTful 서비스 기반 통신**  
- 특정 계층이 **오버로드되면 트랜잭션 손실 발생**  
- **운영 효율성**을 극대화하면서 문제 해결 필요  

---

### **설명**  

#### **A. API Gateway + Lambda + SQS 사용 (✅ 정답)**  
- **설명**:  
  - **Amazon API Gateway** → RESTful API 서비스 제공  
  - **AWS Lambda** → 서버리스 컴퓨팅으로 자동 확장 및 관리 부담 감소  
  - **Amazon SQS** → 비동기 메시징을 통한 **트랜잭션 손실 방지** (큐에 저장 후 처리)  
  - **운영 비용 절감 & 서버 관리 최소화 가능**  

- **결론**: ✅ **정답** (트랜잭션 손실 방지 + 운영 효율성 극대화)  

---

#### **B. CloudWatch로 성능 분석 후 EC2 인스턴스 크기 증가 (❌ 오답)**  
- **설명**:  
  - CloudWatch로 성능을 분석하는 것은 유용하지만, **EC2 인스턴스 크기만 키우는 방식은 확장성 부족**  
  - 트랜잭션 손실이 발생하는 근본적인 문제를 해결하지 않음  
  - **수직 확장(Scale-up)보다 수평 확장(Scale-out)이 적절한 시나리오**  

- **결론**: ❌ **오답** (확장성 부족 & 트랜잭션 손실 해결 불가)  

---

#### **C. SNS + Auto Scaling 사용 (❌ 오답)**  
- **설명**:  
  - SNS는 **푸시 기반 메시징 시스템**으로, **트랜잭션을 보장하지 않음**  
  - 트랜잭션 손실을 방지하려면 **메시지 큐(SQS)**를 활용하는 것이 더 적절  
  - Auto Scaling은 적절하지만, 트랜잭션 유실 방지 측면에서 부족함  

- **결론**: ❌ **오답** (SNS는 메시지 보장 기능 부족)  

---

#### **D. SQS + Auto Scaling 사용 (❌ 오답)**  
- **설명**:  
  - SQS를 사용하여 EC2 인스턴스 간 메시지를 처리하는 것은 적절하지만,  
    **서버리스 아키텍처(Lambda)를 활용하는 것이 운영 효율성이 더 높음**  
  - API Gateway 및 Lambda를 사용하면 **EC2 서버 관리 부담이 없어짐**  
  - 운영 효율성을 고려할 때 **Lambda 기반 솔루션(A)이 더 적절**  

- **결론**: ❌ **오답** (EC2 기반보다 Lambda가 더 효율적)  

---

## **정답: ✅ A. API Gateway + Lambda + SQS**  
- **SQS를 통한 메시지 큐 활용 → 트랜잭션 손실 방지**  
- **API Gateway + Lambda → 서버리스 아키텍처로 운영 부담 최소화**  
- **자동 확장 가능 → 높은 유연성 & 비용 절감**  
- **AWS 모범 사례에 적합한 구조** ✅  
