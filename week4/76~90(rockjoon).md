# Q76

## **1. 문제 요구 사항 정리**
- **일일 데이터 전송량:** 10TB의 JSON 파일
- **데이터 위치:** 공장의 온프레미스 데이터센터(SAN 스토리지)
- **전송 대상:** Amazon S3
- **추가 요구사항:**
    - 데이터는 여러 시스템에서 사용될 예정
    - **근실시간(near-real-time) 분석** 필요
    - 데이터는 민감하므로 **보안 전송** 중요
    - **신뢰성 있는 데이터 전송**이 핵심

---

## **2. 각 보기에 대한 설명: 정답인 이유와 오답인 이유**

### **A. AWS DataSync over public internet**
- **장점:**
    - AWS DataSync는 대량의 데이터를 자동으로 전송하고 S3와 통합이 용이함
    - 네트워크 최적화 및 데이터 검증 기능으로 신뢰성 제공
- **단점:**
    - 공용 인터넷(public internet)을 사용하면 전송 속도가 불안정하며 보안 위험이 존재
    - 민감한 데이터 전송 시 요구사항인 보안에 부적합
- **결론:** ❌ **오답** (보안 및 신뢰성 측면에서 부적합)

---

### **B. AWS DataSync over AWS Direct Connect** ✅ **(정답)**
- **장점:**
    - **AWS DataSync**는 대규모 파일을 빠르고 신뢰성 있게 전송하며 전송 중 데이터 검증 제공
    - **AWS Direct Connect**는 전용 네트워크 연결로 공용 인터넷을 우회 → 보안성과 안정성 확보
    - DataSync와 Direct Connect의 조합은 **근실시간 데이터 처리**와 **10TB/일의 대용량 전송**에 이상적
    - 암호화 기능으로 데이터의 기밀성과 무결성을 유지
- **결론:** ✅ **정답** (속도, 신뢰성, 보안 모두 충족)

---

### **C. AWS Database Migration Service (AWS DMS) over public internet**
- **단점:**
    - **AWS DMS**는 주로 **데이터베이스 마이그레이션**에 특화됨 → 파일 전송에는 비효율적
    - 공용 인터넷 사용으로 보안 및 안정성 저하
- **결론:** ❌ **오답** (DMS는 JSON 파일 전송에 적합하지 않음)

---

### **D. AWS Database Migration Service (AWS DMS) over AWS Direct Connect**
- **단점:**
    - AWS Direct Connect로 보안과 속도는 보장되지만, **DMS는 JSON 파일과 같은 비구조화 데이터 전송에 부적합**
- **결론:** ❌ **오답** (DMS의 사용 목적이 문제 요구사항과 불일치)

---

## **최종 정답:** ✅ **B. AWS DataSync over AWS Direct Connect**
- **이유:**
    - AWS DataSync는 대용량 데이터의 자동화된 전송 및 검증을 지원하여 신뢰성이 높음
    - AWS Direct Connect는 전용 네트워크로 보안을 강화하면서 빠른 속도를 제공
    - 근실시간 분석을 위한 안정적이고 빠른 데이터 전송을 보장함

---

# Q77

## 1. 문제 요구 사항 정리

- **목표:** 실시간 데이터 수집 아키텍처 구성
- **필요 요소:**
    - **API**: 외부에서 데이터를 수신할 API 필요
    - **데이터 변환 프로세스**: 데이터 스트림 중 실시간 변환
    - **저장소**: 수집 및 변환된 데이터를 저장할 솔루션
- **추가 요구사항:** 최소한의 **운영 오버헤드**로 구성할 것

---

## 2. 주요 개념

## **Amazon Kinesis Data Streams vs. Amazon Kinesis Data Firehose**

### ✅ **Amazon Kinesis Data Streams (KDS)**
- **기능:**
    - 실시간 데이터 스트리밍 및 처리를 위한 서비스
    - 데이터를 순차적으로 수집 및 유지하여 사용자가 직접 데이터를 읽고 처리 가능
    - 데이터는 **Shard** 단위로 관리되며 각 Shard는 초당 최대 1MB 또는 1,000개의 레코드를 수집 및 전송 가능
    - 데이터를 최대 **7일간 저장** 가능 (기본은 24시간, 최대 7일로 확장 가능)

- **특징:**
    - 데이터의 소비자(Consumer)가 직접 데이터를 읽고 처리 (예: AWS Lambda, Kinesis Data Analytics, Custom Consumer)
    - 저지연(Low Latency)으로 실시간 처리가 가능
    - 다양한 애플리케이션이 동일한 데이터 스트림을 동시에 구독 가능

- **운영 부담:**
    - Shard의 수를 직접 관리해야 하며, 확장성 및 비용 관리를 위해 **Shard Scaling** 필요
    - 데이터 읽기 및 소비자 애플리케이션의 코드 작성 필요 → **운영 오버헤드가 상대적으로 높음**

---

### ✅ **Amazon Kinesis Data Firehose (KDF)**
- **기능:**
    - 데이터의 수집, 변환, 전달을 자동화하여 대상 스토리지(S3, Redshift, OpenSearch, Splunk 등)로 전송
    - 데이터를 **Batch**로 전달하여 대기열 없이 빠르게 전송
    - 실시간에 가까운 처리 속도 제공 (몇 초의 지연 허용)
    - 기본적인 데이터 변환 기능 제공 (예: JSON to Parquet/ORC)
    - AWS Lambda와 통합하여 데이터에 대한 추가 변환 가능

- **특징:**
    - **완전 관리형 서비스**로 Shard 관리가 필요 없음 → **운영 오버헤드 최소화**
    - 자동 스케일링을 통해 사용량에 따라 확장 가능
    - **순차성 및 저지연**은 Data Streams보다 약간 떨어질 수 있음 (수 초의 지연이 발생할 수 있음)

- **운영 부담:**
    - 설정만으로 데이터 수집과 전송이 가능하며 유지보수와 확장에 대한 부담이 거의 없음
    - 기본적인 데이터 전송 및 변환에 적합하며 **최소한의 관리와 유지보수**로 사용 가능

---

## **📋 차이점 요약 (KDS vs. KDF)**

| **특징**                                   | **Amazon Kinesis Data Streams (KDS)**                           | **Amazon Kinesis Data Firehose (KDF)**                          |
|------------------------------------------|----------------------------------------------------------------|----------------------------------------------------------------|
| **주요 기능**                             | 실시간 데이터 스트리밍 및 사용자 정의 처리                       | 데이터 수집, 변환 및 대상 스토리지로의 전송                     |
| **저지연성(Latency)**                     | **밀리초(ms)** 단위의 저지연 처리                               | **수 초(seconds)** 단위의 저지연 처리                           |
| **데이터 저장 기간**                      | 최대 **7일** (기본은 24시간)                                   | 실시간 전송으로 데이터는 임시 저장하지 않음                     |
| **Shard 관리**                           | 사용자가 **Shard** 수를 직접 관리해야 함                        | 자동 스케일링으로 **Shard** 관리 불필요                         |
| **데이터 소비 방법**                      | 사용자가 데이터를 직접 읽고 처리 (Lambda, Analytics 등)         | 자동으로 데이터를 대상 스토리지에 전달                           |
| **데이터 처리 및 변환**                   | 소비자가 자유롭게 데이터 처리 가능                              | 기본적인 변환 기능 제공 (Lambda와 통합 시 추가 변환 가능)       |
| **운영 오버헤드**                         | **높음** (Shard 관리 및 소비자 애플리케이션 개발 필요)         | **낮음** (완전 관리형, 최소한의 설정으로 사용 가능)             |
| **사용 사례**                             | 실시간 모니터링, 알림 시스템, 금융 거래 처리                   | 로그 및 이벤트 데이터 수집, 데이터 웨어하우스에 전송           |

---

## **💡 사용 사례 (Use Cases)**

### 1. **Amazon Kinesis Data Streams (KDS) 사용 사례**
- **실시간 분석 및 모니터링:**
    - IoT 센서 데이터의 실시간 처리 및 분석
    - 금융 거래 및 주식 거래의 실시간 모니터링
    - 게임 애플리케이션에서 사용자 이벤트 분석
- **알림 및 경고 시스템:**
    - 실시간 이상 탐지 및 알림 시스템
- **다양한 데이터 소비자:**
    - 여러 시스템이 동일한 데이터 스트림을 동시에 사용할 때

---

### 2. **Amazon Kinesis Data Firehose (KDF) 사용 사례**
- **로그 및 이벤트 데이터 수집:**
    - 웹사이트 클릭스트림 및 로그 데이터를 Amazon S3에 저장
    - 애플리케이션 로그를 Amazon Redshift 또는 OpenSearch로 전송
- **데이터 웨어하우스 및 분석:**
    - AWS Glue와 통합하여 S3에 저장된 데이터를 분석
    - 데이터 파이프라인에서 최소한의 코드로 데이터 수집 및 전송
- **보안 및 규정 준수:**
    - 실시간으로 감사 로그를 저장하여 규정 준수 요구사항 충족

---

## **🚀 결론**
- **Amazon Kinesis Data Streams (KDS)**:
    - **고성능 실시간 데이터 처리**가 필요하거나, 다양한 시스템이 동일한 스트림을 소비해야 할 때 사용
    - 하지만 **Shard 관리와 소비자 애플리케이션 개발**로 인해 운영 오버헤드가 높을 수 있음

- **Amazon Kinesis Data Firehose (KDF)**:
    - **운영 오버헤드가 최소화된 데이터 수집 및 전송**이 필요할 때 사용
    - 실시간에 가까운 전송 속도와 기본적인 데이터 변환 기능 제공
    - 데이터 웨어하우스, 로그 관리, 데이터 분석 등 **대량의 이벤트 데이터를 안정적으로 저장**할 때 이상적


---

## 3. 해설

### A. **EC2 + Kinesis Data Firehose + Lambda + S3**
- **단점:**
    - **EC2 인스턴스**로 API를 호스팅하므로 서버 관리가 필요 → **운영 오버헤드 증가**
    - Lambda를 사용한 데이터 변환은 유연하지만 추가 구성 및 유지보수 필요

---

### B. **EC2 + AWS Glue + S3**
- **단점:**
    - 실시간 처리를 원하지만, **AWS Glue**는 **배치 처리**에 특화되어 있음 → 실시간 처리에 부적합
    - **EC2 인스턴스** 사용으로 인해 **운영 오버헤드** 증가

---

### C. **API Gateway + Kinesis Data Firehose + Lambda + S3** ✅ **(정답)**
- **장점:**
    - **API Gateway**는 완전 관리형 서비스로 API 호스팅 시 **운영 오버헤드 최소화**
    - **Kinesis Data Firehose**가 실시간으로 데이터를 S3로 전송
    - **Lambda**를 사용해 스트림 중간에서 필요한 데이터 변환 수행
- **결론:**
    - **완전 관리형 서비스**로 구성되어 **운영 오버헤드가 가장 적음**
    - 실시간 처리 요구사항을 충족하므로 **정답**

---

### D. **API Gateway + AWS Glue + Lambda + S3**
- **단점:**
    - **AWS Glue**는 **배치 처리**로 실시간 처리에 적합하지 않음
    - Lambda와 Glue의 결합으로 불필요한 복잡성 증가

---

## ✅ **최종 정답:** **C. API Gateway + Kinesis Data Firehose + Lambda + S3**
- **이유:**
    - **완전 관리형 서비스**들로 구성되어 **운영 오버헤드 최소화


---

# Q78

## 1. 문제 요구 사항 정리

- **목표:** 사용자의 거래 데이터를 Amazon DynamoDB 테이블에 보관
- **보관 기간:** 데이터를 최소 **7년간** 유지해야 함
- **요구사항:**
    - **운영 효율성(Operational Efficiency)**을 최적화할 것
    - 관리 및 유지보수 부담이 최소화되어야 함

---

## 2. 주요 개념

### ✅ **AWS Backup**
- **완전 관리형 서비스**로 다양한 AWS 서비스(DynamoDB 포함)의 백업 및 복구 기능 제공
- **백업 일정(Schedule)** 및 **보존 정책(Retention Policy)** 설정 가능
- **자동화된 백업 및 삭제** 기능으로 유지보수 부담 최소화
- 백업 데이터는 자동으로 암호화되며, 규정 준수를 위해 장기 보관에 최적화됨
- **운영 오버헤드가 최소화**되면서 **장기 데이터 보관**에 이상적

---

## 3. 해설

### A. **DynamoDB Point-in-Time Recovery (PITR)**
- **단점:**
    - PITR은 최대 **35일**간의 데이터를 복원할 수 있음 → **7년 보관 요건 충족 불가**
- **결론:** ❌ **오답** (보관 기간 제한으로 부적합)

---

### B. **AWS Backup (정답)**
- **장점:**
    - **자동화된 백업** 일정과 **보존 정책**을 설정하여 최소한의 관리로 7년간 데이터 유지 가능
    - DynamoDB와 통합되어 별도의 Lambda 함수나 수동 작업이 불필요함
    - **운영 오버헤드가 최소화**되어 요구사항에 가장 부합함
- **결론:** ✅ **정답** (운영 효율성과 장기 보관 요구사항을 모두 충족)

---

### C. **수동(On-Demand) 백업 + Amazon S3**
- **단점:**
    - 수동(On-Demand) 백업은 **자동화 및 일정 관리 기능 없음** → **운영 오버헤드 증가**
    - S3 수명 주기 구성은 가능하지만 **수동 백업의 비효율성**으로 비적합
- **결론:** ❌ **오답** (수동 백업으로 인해 운영 부담 증가)

---

### D. **EventBridge + Lambda + S3**
- **단점:**
    - EventBridge와 Lambda를 통한 **사용자 정의 자동화**는 가능하지만 **구현 및 유지보수 부담 증가**
    - AWS Backup과 비교 시 **불필요한 복잡성**이 추가됨
- **결론:** ❌ **오답** (운영 오버헤드가 더 크기 때문에 비효율적)

---

## ✅ **최종 정답:** **B. Use AWS Backup to create backup schedules and retention policies for the table**
- **이유:**
    - **완전 관리형 서비스**로 DynamoDB와 통합되어 추가 코드 작성 불필요
    - **백업 일정 및 보존 정책**을 설정하여 **7년간** 자동으로 데이터를 보관
    - **운영 오버헤드가 최소화**되어 **장기 데이터 보관**에 가장 적합한 솔루션


---

# Q79.

## 1. 문제 요구 사항 정리

- **목표:** 비용 최적화를 고려하여 Amazon DynamoDB 테이블을 사용
- **사용 패턴:**
    - **오전:** 대부분 사용되지 않음 (저비용 유지 필요)
    - **저녁:** 읽기 및 쓰기 트래픽이 종종 **예측 불가능**하며 **급격한 스파이크** 발생
- **추가 요구사항:**
    - 트래픽 급증 시 빠르게 대응할 수 있어야 함
    - 안정적인 성능과 비용 효율성을 모두 고려

---

## 2. 주요 개념

### ✅ **DynamoDB Capacity Modes**
1. **On-Demand Capacity Mode:**
    - 사용한 읽기/쓰기 요청에 대해서만 요금 부과 → **트래픽 예측이 어렵거나 불규칙할 때 비용 효율적**
    - **급격한 트래픽 스파이크**에도 즉시 확장 → 성능 저하 없이 안정적으로 처리

2. **Provisioned Capacity Mode:**
    - 사전에 정의된 읽기/쓰기 용량으로 비용이 고정됨
    - **Auto Scaling** 기능으로 트래픽 변동에 대응 가능하지만 **급격한 스파이크**에는 지연 발생 가능

---

## 3. 해설

### A. **On-Demand Capacity Mode (정답)**
- **장점:**
    - **사용한 만큼만 비용 지불**하여 **비용 최적화**에 이상적
    - 트래픽이 없을 때 비용 발생 없음
    - **급격한 트래픽 스파이크**에도 **자동 확장**하여 **지연 없이 처리**
- **결론:** ✅ **정답** (불규칙한 사용 패턴과 급격한 트래픽 증가에 최적화)

---

### B. **Global Secondary Index (GSI)**
- **목적:**
    - **데이터 접근성 및 쿼리 성능**을 개선하기 위한 인덱스
    - 비용 최적화나 트래픽 급증에 직접적인 영향 없음
- **결론:** ❌ **오답** (비용 최적화와 트래픽 스파이크 대응과 무관)

---

### C. **Provisioned Capacity + Auto Scaling**
- **단점:**
    - **Auto Scaling**은 **예측 가능한 증가**에 최적화되며, **급격한 트래픽 스파이크**에는 **대응 속도에 제한**이 있음
    - 트래픽이 없는 시간에도 **기본 용량 비용** 발생 → **비용 비효율적**
- **결론:** ❌ **오답** (급격한 트래픽 증가 및 비용 최적화에 부적합)

---

### D. **Provisioned Capacity + Global Table**
- **단점:**
    - **Global Table**은 다중 리전 간 데이터 복제에 적합하지만, 비용 최적화와는 거리가 있음
    - 트래픽 패턴과는 관련이 없으며, **비용이 더 높아질 수 있음**
- **결론:** ❌ **오답** (비용 최적화 및 예측 불가능한 트래픽 대응에 부적합)

---

## ✅ **최종 정답:** **A. Create a DynamoDB table in on-demand capacity mode**
- **이유:**
    - **비정기적 사용** 및 **급격한 트래픽 스파이크**에 자동 대응
    - 사용한 만큼만 비용을 지불하여 **비용 효율성**을 극대화
    - 추가 설정 없이 **즉시 확장** 가능하여 **운영 오버헤드가 최소화됨**

---

# Q80 

## 1. 문제 요구 사항 정리

- **목표:** 기존 AWS 계정에서 생성한 Amazon Machine Image (AMI)를 MSP Partner의 AWS 계정에 **보안성**을 유지하면서 공유
- **조건:**
    - AMI는 **Amazon EBS**로 지원되며, **AWS KMS 고객 관리 키(Customer Managed Key, CMK)**로 암호화됨
    - 다른 계정에 **키 접근 권한**을 적절히 부여해야 함
    - **보안(Security)**이 최우선 고려사항이며, **운영 오버헤드 최소화** 필요

---

## 2. 주요 개념

### ✅ **Amazon Machine Image (AMI) Sharing**
- **공유 방식:**
    - AMI를 **특정 계정**에만 공유 가능 (`launchPermission` 속성 사용)
    - 퍼블릭으로 공개하지 않고 **지정된 AWS 계정에만 접근** 허용 가능

### ✅ **AWS Key Management Service (AWS KMS)**
- **고객 관리 키(CMK):**
    - 특정 AWS 계정에 속하며, 기본적으로 다른 계정에서는 사용할 수 없음
    - **Key Policy**를 수정하여 특정 외부 계정이 해당 키를 사용할 수 있도록 권한 부여 가능

### ✅ **보안 원칙**
- AWS에서 권장하는 방법은 **Key Policy**를 통해 **최소한의 권한**만 외부 계정에 부여하는 것
- 외부 계정에 대한 **KMS 키 소유권을 이전하지 않고** 필요한 권한만 공유함으로써 보안성을 유지

---

## 3. 해설

### A. **AMI 및 스냅샷을 퍼블릭으로 공개 + Key Policy 수정**
- **단점:**
    - AMI와 스냅샷을 **공개(Public)**로 설정하면 **보안 위협** 발생
    - 불특정 다수가 접근할 수 있으므로 요구사항인 **보안성**에 부적합
- **결론:** ❌ **오답** (보안 기준에 맞지 않음)

---

### B. **LaunchPermission 수정 + Key Policy 수정하여 Partner 계정에 권한 부여 (정답)**
- **장점:**
    - **`launchPermission`** 속성을 사용하여 **특정 AWS 계정에만** AMI 공유 → **접근 통제 강화**
    - **KMS Key Policy**를 수정하여 **MSP Partner의 AWS 계정에만** 해당 키 사용 권한 부여
    - **데이터 소유권은 소스 계정이 유지**하면서 외부 계정이 필요한 **최소한의 권한만 부여**
    - **AWS 모범 사례(Best Practice)**에 부합: KMS 키 소유권을 이전하지 않으면서 **보안성과 운영 효율성** 유지
- **결론:** ✅ **정답** (보안성, 운영 효율성 및 권한 최소화 원칙을 모두 충족)

---

### C. **LaunchPermission 수정 + MSP Partner가 소유한 새 KMS 키 사용**
- **단점:**
    - KMS 키를 새로 생성하고 **암호화를 다시 적용**해야 하므로 **운영 오버헤드** 증가
    - **보안성은 유지**되지만 **추가적인 작업과 시간**이 필요하여 **비효율적**임
- **결론:** ❌ **오답** (보안성은 유지되나 **비용 및 운영 부담 증가**)

---

### D. **AMI를 S3 버킷으로 내보내기 + MSP Partner가 새 KMS 키로 재암호화**
- **단점:**
    - **S3를 통한 데이터 전송 및 재암호화** 과정으로 **복잡성**과 **운영 비용** 증가
    - **AMI 직접 공유** 방식보다 **시간과 비용이 더 많이 소요됨**
- **결론:** ❌ **오답** (보안성은 유지되나 **비효율적이며 복잡성 증가**)

---

## ✅ **최종 정답:** **B. Modify the launchPermission property of the AMI. Share the AMI with the MSP Partner's AWS account only. Modify the key policy to allow the MSP Partner's AWS account to use the key.**
- **이유:**
    - **`launchPermission`** 속성을 사용하여 **특정 계정에만** AMI를 공유하여 **접근 제한**
    - **Key Policy** 수정으로 **MSP Partner**가 **소스 계정의 KMS 키**를 사용할 수 있도록 허용
    - **운영 오버헤드 최소화:** 새로운 키를 생성하거나 데이터를 재암호화할 필요 없음
    - **보안성 유지:** **최소한의 권한만 부여**하므로 외부 계정의 불필요한 접근을 차단함
    - **AWS 모범 사례**에 따라 **필요한 권한만 제공**하여 **보안성과 비용 효율성** 모두 충족  

---

# Q81.

## 1. 문제 요구 사항 정리

- **목표:** AWS에서 새로운 애플리케이션의 클라우드 아키텍처를 설계
- **특징:**
    - **병렬 처리:** 여러 작업을 동시에 실행해야 함
    - **확장성:** 작업량에 따라 애플리케이션 노드를 자동으로 추가 및 제거해야 함
    - **Stateless:** 애플리케이션은 상태를 유지하지 않음
    - **내구성:** 작업 항목(job items)이 **내구성 있게 저장**되어야 함
- **주요 요구사항:**
    - **애플리케이션의 느슨한 결합(Loosely Coupled)** 구조 필요
    - **작업 항목이 안정적으로 보관**되며, **Auto Scaling**에 따라 자동으로 노드 추가/제거 가능

---

## 2. 주요 개념

### ✅ **Amazon Simple Queue Service (SQS)**
- **메시지 큐 서비스:**
    - **비동기식 메시지 전달**을 통해 시스템 간 **느슨한 결합(Loosely Coupled)**을 지원
    - 메시지가 **내구성 있게 저장(Durable Storage)**되며, **노드 장애 시에도 메시지가 손실되지 않음**
    - Auto Scaling과 통합하여 **큐에 쌓인 메시지 수**에 따라 인스턴스 수를 자동 조정 가능
- **특징:**
    - **FIFO 큐:** 순서가 중요한 경우 사용
    - **Standard 큐:** 고성능 및 대량의 메시지 전송에 적합 (순서 보장은 안 됨)
    - **Auto Scaling과 자연스럽게 연동**되어 **큐의 메시지 수**에 따라 자동으로 노드가 추가/제거됨

### ✅ **Amazon Simple Notification Service (SNS)**
- **Pub/Sub(발행/구독) 모델**로 메시지를 여러 구독자에게 동시에 전송
- **메시지를 일시적으로 보관**하지만, **지속적으로 저장하지 않으므로** **내구성(Durability)**이 요구되는 작업에는 부적합
- **Auto Scaling과 직접적으로 연동되지 않음** → **SNS 메시지 수**로 Auto Scaling을 트리거할 수 없음

### ✅ **Amazon EC2 Auto Scaling**
- **Auto Scaling 그룹:**
    - **Launch Configuration** 또는 **Launch Template**을 통해 인스턴스 시작
    - **Scaling Policy:** 특정 지표(예: CPU 사용량, SQS 대기열의 메시지 수)를 기반으로 노드 수를 자동으로 조정
    - **Launch Template**은 **Launch Configuration**보다 **더 유연하고 기능이 향상됨**

---

## 3. 해설

### A. **SNS + Launch Configuration + Auto Scaling (CPU 기반)**
- **단점:**
    - **SNS**는 메시지를 **내구성 있게 저장하지 않음** → **Stateless 작업 큐**로 부적합
    - Auto Scaling이 **CPU 사용량** 기반으로 작동하여, **작업 수에 따른 자동 확장 불가능**
- **결론:** ❌ **오답** (내구성 부족 및 잘못된 확장 기준)

---

### B. **SQS + Launch Configuration + Auto Scaling (네트워크 사용량 기반)**
- **장점:**
    - **SQS**는 작업 항목을 **내구성 있게 저장**하여 **느슨한 결합** 구조를 지원
- **단점:**
    - Auto Scaling이 **네트워크 사용량**을 기반으로 작동하여 **작업 수에 따른 확장**이 불가능
    - **Launch Configuration**은 **Launch Template**에 비해 **기능이 제한됨**
- **결론:** ❌ **오답** (잘못된 확장 기준 및 Launch Configuration 사용)

---

### C. **SQS + Launch Template + Auto Scaling (SQS 큐의 메시지 수 기반) (정답)**
- **장점:**
    - **SQS**는 **메시지를 내구성 있게 저장**하며 **Stateless** 애플리케이션과 완벽히 호환됨
    - Auto Scaling이 **SQS 큐의 메시지 수**를 기반으로 작동하여 **실제 작업량에 맞게 자동으로 노드 추가/제거**
    - **Launch Template** 사용으로 **유연성과 기능성**이 증가 (예: 더 나은 보안 및 태깅 기능)
- **결론:** ✅ **정답** (내구성, 느슨한 결합 및 확장성 요구사항 모두 충족)

---

### D. **SNS + Launch Template + Auto Scaling (SNS 메시지 수 기반)**
- **단점:**
    - **SNS**는 **메시지를 지속적으로 저장하지 않으므로** 작업 큐로 부적합
    - **Auto Scaling**은 **SNS 메시지 수**를 기반으로 **직접적으로 확장하지 않음**
- **결론:** ❌ **오답** (내구성 부족 및 Auto Scaling과의 부적합성)

---

## ✅ **최종 정답:** **C. Create an Amazon SQS queue to hold the jobs that need to be processed. Create an Amazon Machine Image (AMI) that consists of the processor application. Create a launch template that uses the AMI. Create an Auto Scaling group using the launch template. Set the scaling policy for the Auto Scaling group to add and remove nodes based on the number of items in the SQS queue.**
- **이유:**
    - **SQS**는 **내구성 있게 작업을 저장**하며, 시스템 간 **느슨한 결합**을 구현
    - **Auto Scaling**이 **SQS의 메시지 수**에 따라 **동적으로 확장 및 축소**
    - **Launch Template** 사용으로 **더 많은 기능과 유연성** 제공
    - **Stateless** 아키텍처에 완벽히 적합하며, **AWS 모범 사례(Best Practice)**를 충족

---

# Q82

## 1. 문제 요구 사항 정리

- **목표:** AWS Certificate Manager (ACM)에 가져온 인증서의 **만료 30일 전**에 보안팀에 알림 전송
- **조건:**
    - 알림은 **자동화**되어야 함
    - **Amazon Simple Notification Service (SNS)**를 통해 보안팀에 통지
    - **운영 오버헤드 최소화**와 **보안 요구사항 충족** 필요

---

## 2. 주요 개념

### ✅ **AWS Certificate Manager (ACM)**
- ACM은 관리되는 인증서에 대해 **자동 갱신 알림**을 지원하지만, **가져온 인증서(Imported Certificates)** 는 수동으로 관리해야 함
- 가져온 인증서는 기본적으로 만료 전 **자동 알림 기능이 없음** → **EventBridge** 또는 **Config Rule**을 사용해 알림을 설정해야 함

### ✅ **AWS Config**
- **리소스의 구성 상태를 지속적으로 모니터링**하고, 규칙 위반 시 **EventBridge**와 통합하여 **알림** 전송 가능
- **ACM 인증서 만료**를 모니터링하는 **Config Rule**을 정의할 수 있음 → **가장 효율적인 방법**

### ✅ **Amazon EventBridge (CloudWatch Events)**
- **EventBridge**는 **정기적인 검사 및 알림**을 위한 규칙을 생성하여 특정 조건 발생 시 **SNS**로 알림 전송 가능
- **Lambda 함수** 없이 직접 **SNS** 호출도 가능하여 **운영 오버헤드 최소화**

### ✅ **AWS Trusted Advisor**
- Trusted Advisor는 인증서 만료를 감지할 수 있지만, **유료 플랜**에서만 사용 가능하며, **알림 기능**이 제한적임

---

## 3. 해설

### A. **ACM Rule + SNS**
- **문제점:**
    - ACM에는 **사용자 정의 알림 규칙**을 생성하는 기능이 없음
    - **직접적인 알림 기능**이 없으므로 **SNS에 메시지를 게시할 수 없음**
- **결론:** ❌ **오답** (ACM 자체에는 해당 기능이 없음)

---

### B. **AWS Config Rule + EventBridge + SNS (정답)**
- **장점:**
    - **AWS Config**를 사용해 인증서 만료 여부를 **자동으로 모니터링**
    - **EventBridge**와 통합하여 **SNS로 알림 전송** → **Lambda 함수 불필요**
    - **운영 오버헤드가 최소화**되면서 **자동화**와 **보안 요구사항** 모두 충족
- **결론:** ✅ **정답** (가장 효율적이고 권장되는 방법)

---

### C. **Trusted Advisor + CloudWatch Alarm + SNS**
- **문제점:**
    - **Trusted Advisor**는 **유료 지원 플랜(Business 또는 Enterprise)**에서만 사용 가능
    - **비용이 증가**하며 **모든 계정에 적용되지 않음**
- **결론:** ❌ **오답** (비용 증가와 제한적인 사용성)

---

### D. **EventBridge + Lambda + SNS**
- **문제점:**
    - **Lambda 함수**를 사용해야 하므로 **운영 오버헤드 증가**
    - EventBridge는 **직접 SNS와 통합** 가능하므로 **Lambda가 불필요함**
- **결론:** ❌ **오답** (Lambda 사용으로 인해 불필요한 복잡성 추가)

---

## ✅ **최종 정답:**
- **이유:**
    - **AWS Config**는 **가져온 인증서**의 만료 여부를 **자동으로 모니터링**
    - **EventBridge**는 **Lambda 없이** 직접 **SNS로 알림 전송** 가능 → **운영 오버헤드 최소화**
    - **30일 전에 자동으로 알림**하여 **보안 요구사항을 충족**하며, **가장 비용 효율적**인 방법

---

# Q83

## 1. 문제 요구 사항 정리

- **목표:** 유럽 사용자를 위해 웹사이트의 **로딩 속도 최적화**
- **제한사항:**
  - **백엔드 서버**는 여전히 **미국(On-Premises)**에 유지되어야 함
  - **빠른 해결책**이 필요하며 **즉시 적용 가능**해야 함
- **핵심 요구사항:**
  - **콘텐츠 전송 속도**를 개선하여 **지연 시간(Latency)**을 최소화할 것
  - **웹사이트의 백엔드 위치를 변경하지 않고** 해결할 것

---

## 2. 주요 개념

### ✅ **Amazon CloudFront (CDN)**
- **글로벌 콘텐츠 전송 네트워크**로 사용자의 **지리적 위치**에 따라 가장 가까운 **엣지 로케이션(Edge Location)**에서 콘텐츠를 제공하여 **지연 시간**을 최소화
- **Custom Origin** 기능을 통해 **On-Premises 서버** 또는 **타사 호스팅 서버**를 원본으로 사용할 수 있음
- **빠른 배포 및 즉시 사용 가능**하여 **긴급한 상황**에 이상적

---

## 3. 해설

### A. **Amazon EC2 (us-east-1)**
- **단점:**
  - **서버 위치**가 여전히 **미국**에 있으므로 **지연 시간**이 개선되지 않음
  - 기존 **On-Premises 서버**를 유지해야 한다는 조건에 부적합
- **결론:** ❌ **오답** (유럽 사용자의 로딩 속도 개선에 도움이 되지 않음)

---

### B. **Amazon S3 + Cross-Region Replication**
- **단점:**
  - **웹사이트 백엔드**는 여전히 **On-Premises**에 있어야 하므로 **마이그레이션 불가**
  - **Cross-Region Replication**은 **정적 콘텐츠** 전송에는 적합하지만, **동적 콘텐츠**에는 비효율적
- **결론:** ❌ **오답** (웹사이트 백엔드가 변경되므로 요구사항에 맞지 않음)

---

### C. **Amazon CloudFront + Custom Origin**
- **장점:**
  - **CloudFront**는 **전 세계 엣지 로케이션(Edge Location)**을 통해 **지연 시간을 최소화**
  - **Custom Origin** 기능을 통해 기존 **On-Premises 서버**를 유지하면서도 **유럽 사용자의 로딩 속도**를 개선
  - **즉시 배포 가능**하여 **몇일 내로 적용**할 수 있음
  - **보안 기능**(SSL/TLS 및 DDoS 보호)을 기본으로 제공
- **결론:** ✅ **정답** (가장 빠르고 효율적인 해결책)

---

### D. **Amazon Route 53 (Geoproximity Routing)**
- **단점:**
  - **Route 53**은 DNS 기반의 **라우팅 정책**으로 **지연 시간 개선**에 직접적인 도움을 주지 않음
  - **지리적 라우팅**은 가장 가까운 **DNS 엔드포인트**로 사용자를 라우팅하지만, **콘텐츠 전송 속도**에는 영향을 미치지 않음
- **결론:** ❌ **오답** (지연 시간 개선을 위해 적합하지 않음)

---

## ✅ **최종 정답:**
- **기존 On-Premises 서버 유지**라는 요구사항을 충족하면서 **지연 시간을 최소화**
- **글로벌 엣지 로케이션**을 통해 **유럽 사용자**에게 **가장 가까운 CDN 노드**에서 콘텐츠 제공
- **즉시 배포 가능**하여 **긴급한 일정**에도 적합
- **AWS 모범 사례(Best Practice)**로 **글로벌 웹사이트 성능 최적화**에 가장 이상적인 솔루션

---

# Q84

## 1. 문제 요구 사항 정리

- **목표:** 기존의 3계층 웹 아키텍처(웹, 애플리케이션, 데이터베이스)의 **비용 절감**
- **환경:**
  - **Production EC2 인스턴스:** 24시간 상시 실행, CPU 사용률 평균 30%
  - **Development & Test EC2 인스턴스:** 하루 최소 8시간 실행, 자동화로 사용하지 않을 때는 중지 예정
- **조건:**
  - **Production:** 안정성과 가용성이 요구됨 (중단 불가)
  - **Development & Test:** 비용을 최소화하기 위해 **중단 가능**한 인스턴스 사용 가능
  - **목표:** 비용 효과적인 인스턴스 구매 옵션 선택

---

## 2. 주요 개념

### ✅ **EC2 인스턴스 구매 옵션**
1. **Reserved Instances (RI)**
  - **1년 또는 3년 약정**으로 사용 시 최대 **75% 비용 절감**
  - **지속적으로 실행되는** 인스턴스에 이상적 (예: Production 환경)

2. **Spot Instances & Spot Blocks**
  - **AWS의 유휴 용량**을 사용하여 최대 **90% 비용 절감**
  - **Spot Instances:** 중단될 수 있으므로 **Production**에는 부적합
  - **Spot Blocks:** 특정 시간(1~6시간) 동안 중단 없이 사용 가능하여 **Development & Test 환경**에 적합

3. **On-Demand Instances**
  - 사용한 만큼만 비용 지불, **유연성**은 높지만 **비용이 가장 높음**
  - **간헐적 사용**이나 **예측 불가능한 워크로드**에 적합하지만 비용 절감을 위해 장기 사용에는 부적합

---

## 3. 해설

### A. **Spot Instances (Production) + Reserved Instances (Development & Test)**
- **문제점:**
  - **Spot Instances**는 **중단될 수 있으므로** **Production 환경**에 사용하기에는 **안정성 부족**
- **결론:** ❌ **오답** (Production 환경에 부적합)

---

### B. **Reserved Instances (Production) + On-Demand Instances (Development & Test)**
- **장점:**
  - **Reserved Instances**는 **24시간 실행되는 Production 환경**에 가장 비용 효과적
  - **On-Demand Instances**는 **필요할 때만 사용**하지만, 비용이 상대적으로 비쌈
- **단점:**
  - **Development & Test**에서는 **Spot Blocks**을 사용하면 **더 큰 비용 절감** 가능
- **결론:** ❌ **오답** (Development & Test 환경에서 더 저렴한 옵션이 있음)

---

### C. **Spot Blocks (Production) + Reserved Instances (Development & Test)**
- **문제점:**
  - **Spot Blocks**는 최대 **6시간**까지만 중단 없이 실행되며, **24시간 실행**해야 하는 **Production**에는 부적합
- **결론:** ❌ **오답** (Production 환경에 적합하지 않음)

---

### D. **On-Demand Instances (Production) + Spot Blocks (Development & Test)** ✅ **정답**
- **장점:**
  - **On-Demand Instances**는 **Production 환경**에서 **중단 위험 없이 안정적인 서비스** 제공
  - **Spot Blocks**은 **Development & Test 환경**에서 **일정 시간 동안 중단 없이 저비용 사용** 가능
    - 예: 하루 8시간 동안만 실행 → **비용 절감 극대화**
- **비용 최적화:**
  - **Production:** 안정성과 가용성을 위해 **On-Demand** 사용 (필수 요건)
  - **Development & Test:** **Spot Blocks**으로 비용 절감 (자동화로 중지 및 재시작 가능)
- **결론:** ✅ **정답** (안정성과 비용 절감을 모두 충족하는 최적의 옵션)

---

## ✅ **최종 정답:**
- **Production EC2 인스턴스:** On-Demand Instances (24시간 상시 실행으로 안정성 확보)
- **Development & Test EC2 인스턴스:** Spot Blocks (하루 8시간 사용으로 비용 절감 및 중단 없는 실행 보장)
- **이유:**
  - **Production:** 중단되면 안 되므로 **Spot Instances**나 **Spot Blocks**은 사용 불가
  - **Development & Test:** 일정 시간 동안만 필요하므로 **Spot Blocks**으로 비용 절감
  - **비용 효율성과 안정성을 모두 확보**하면서 **AWS 모범 사례(Best Practice)**에 부합

---

# Q85

## 1. 문제 요구 사항 정리

- **목표:** 업로드된 문서를 **저장 후 수정 및 삭제가 불가능**하도록 구성
- **업로드 방식:**
  - **웹 인터페이스** 또는 **모바일 앱**을 통해 사용자가 문서를 업로드
- **규제 요건:**
  - **수정 및 삭제 금지(Immutability)**
  - 규제에 맞는 **보관 정책**이 필요함

---

## 2. 주요 개념

### ✅ **Amazon S3 Object Lock**
- **S3 Object Lock**을 사용하면 **문서를 변경하거나 삭제하지 못하도록 보호**
- **모드 종류:**
  - **Governance Mode:** 계정 관리자(root 또는 IAM 사용자)는 예외적으로 삭제 가능
  - **Compliance Mode:** **어떠한 사용자도 삭제 또는 수정 불가능** (법적 요구사항에 적합)
- **S3 Versioning**이 **필수로 활성화**되어야 사용 가능

### ✅ **S3 Versioning**
- 객체의 모든 버전을 유지하여 **삭제나 덮어쓰기에 대비**
- **단점:** 기존 버전은 삭제가 가능하므로 **수정 및 삭제 금지**를 위해서는 **Object Lock**과 함께 사용해야 함

---

## 3. 해설

### A. **S3 Versioning + S3 Object Lock (정답)**
- **장점:**
  - **S3 Object Lock**을 통해 **문서를 수정 및 삭제 불가**하도록 보장
  - **Versioning**과 함께 사용하여 **규제 요구사항**을 충족
  - **Compliance Mode** 사용 시 **어떠한 사용자도 삭제 및 수정 불가**
- **결론:** ✅ **정답** (가장 보안성이 높고 규제 요구사항을 충족하는 옵션)

---

### B. **S3 Bucket + S3 Lifecycle Policy**
- **단점:**
  - **Lifecycle Policy**는 **문서 보관 및 이동**을 자동화하지만 **수정 및 삭제를 방지하지 않음**
- **결론:** ❌ **오답** (수정 및 삭제 방지 기능 없음)

---

### C. **S3 Versioning + ACL (Read-Only)**
- **단점:**
  - **S3 Versioning**만으로는 **이전 버전 삭제 가능** → **완벽한 불변성 보장 불가**
  - **ACL**은 **권한 설정**만 가능하므로 **규제 요건**을 충족하지 못함
- **결론:** ❌ **오답** (버전 관리만으로는 규제 요구사항에 부적합)

---

### D. **Amazon EFS (Read-Only Mode)**
- **단점:**
  - **EFS**는 **네트워크 파일 시스템(NFS)**으로 설계되어 **수정 및 삭제 방지**를 보장하지 않음
  - **규제 요구사항**에는 부적합하며 **데이터 무결성**을 보장할 방법이 없음
- **결론:** ❌ **오답** (EFS는 해당 사용 사례에 맞지 않음)

---

## ✅ **최종 정답:**
- 업로드된 문서를 **수정 및 삭제 불가능**하도록 하기 위해 **Amazon S3**에 **Versioning**과 **S3 Object Lock**을 활성화하여 저장
- **S3 Object Lock (Compliance Mode)**을 사용하면 **모든 사용자**가 **수정 및 삭제가 불가능**하므로 **법적 및 규제 요구사항**을 충족함
- AWS의 **모범 사례(Best Practice)**에 부합하며, **안정성**과 **보안성**이 보장됨

---

# Q86

## 1. 문제 요구 사항 정리

- **목표:** 여러 웹 서버가 **Amazon RDS MySQL Multi-AZ** 인스턴스에 **보안적으로 접근**해야 함
- **보안 요구사항:**
  - 데이터베이스 사용자 **자격 증명(credentials)**을 자주 **회전(rotate)**해야 함
  - **보안 및 자동화**가 중요하며, **웹 서버의 IAM 권한**을 통해 접근해야 함

---

## 2. 주요 개념

### ✅ **AWS Secrets Manager**
- **보안 비밀 관리 서비스:**
  - 데이터베이스 **자격 증명**, **API 키**, 및 기타 **비밀 정보**를 **안전하게 저장 및 관리**
  - **자동 비밀번호 회전** 기능 제공 → **수동 관리 불필요**
- **IAM 권한 기반 접근:**
  - **IAM 정책**을 통해 **웹 서버**가 **AWS Secrets Manager**에 **안전하게 접근** 가능
  - **네이티브 통합:** Amazon RDS와의 통합을 통해 **비밀번호 자동 회전**이 가능하여 **운영 오버헤드 최소화**

---

## 3. 해설

### A. **AWS Secrets Manager (정답)**
- **장점:**
  - **RDS MySQL**과 **통합**되어 **자동으로 비밀번호 회전** 가능
  - 웹 서버는 **IAM 권한**을 통해 **비밀번호를 안전하게 검색**
  - **운영 오버헤드 최소화** 및 **보안 요구사항 충족**
- **결론:** ✅ **정답** (가장 보안성 높고 효율적인 솔루션)

---

### B. **AWS Systems Manager OpsCenter**
- **단점:**
  - **OpsCenter**는 **운영 이슈 관리 및 추적**을 위한 도구로 **자격 증명 관리에 적합하지 않음**
- **결론:** ❌ **오답** (비밀번호 회전 및 보안 관리 기능 없음)

---

### C. **Amazon S3 (Encrypted Bucket)**
- **단점:**
  - **S3 버킷**은 **비밀번호 회전**을 자동화하지 않으며, **수동 업데이트**가 필요함
  - 데이터가 **버킷에 저장**되므로 **직접 접근**에 대한 **보안 위험**이 있음
- **결론:** ❌ **오답** (비밀번호 회전 및 보안 요구사항 충족 불가)

---

### D. **AWS KMS + 파일 시스템에 자격 증명 저장**
- **단점:**
  - **웹 서버 파일 시스템**에 자격 증명을 저장하는 것은 **보안상 권장되지 않음**
  - **자동 비밀번호 회전**이 불가능하며 **수동으로 유지보수**해야 함
- **결론:** ❌ **오답** (보안성과 자동화가 부족함)

---

## ✅ **최종 정답:**
- **AWS Secrets Manager**를 사용하여 **RDS MySQL 자격 증명**을 **안전하게 관리**하고 **자동으로 회전**하도록 설정
- **웹 서버**는 **IAM 권한**을 통해 비밀번호를 검색하여 **보안적으로 접근** 가능
- **AWS 모범 사례(Best Practice)**에 부합하며, **운영 오버헤드 최소화** 및 **보안 요구사항**을 모두 충족

---

# Q87

## 1. 문제 요구 사항 정리

- **시나리오:**
  - **AWS Lambda** 함수가 **Amazon API Gateway**에 의해 호출됨
  - Lambda 함수는 **고객 데이터**를 **Amazon Aurora MySQL**에 저장
- **문제점:**
  - **Aurora 데이터베이스 업그레이드** 중에는 **Lambda 함수가 데이터베이스에 연결 실패**
  - 이로 인해 **고객 데이터 손실** 발생
- **목표:**
  - **데이터베이스 업그레이드 중에도** 고객 데이터를 **손실 없이 저장**하도록 해결책 설계

---

## 2. 주요 개념

### ✅ **Amazon SQS (Simple Queue Service) - FIFO Queue**
- **메시지 큐 서비스**로 **비동기식 처리**를 통해 시스템 간 **느슨한 결합(Loosely Coupled)**을 구현
- **FIFO(First-In-First-Out)** 큐는 메시지를 **순차적으로 처리**하여 **데이터의 순서 보장**
- **내구성(Durability):** 메시지가 **저장되며 손실되지 않음** → 데이터베이스가 **업그레이드 중**이라도 **데이터 손실 방지**
- **Lambda 함수**가 큐에 데이터를 전송하고, **별도의 Lambda 소비자 함수**가 **큐에서 메시지를 읽고** 데이터베이스에 **저장**

---

## 3. 해설

### A. **Amazon RDS Proxy**
- **기능:**
  - 데이터베이스 연결을 **풀링(pooling)**하여 **Lambda 함수**의 연결 관리 최적화
- **문제점:**
  - **RDS Proxy**는 데이터베이스가 **완전히 다운될 경우**에도 **연결을 제공하지 못함**
  - **업그레이드 중**에는 **연결 불가** 상태가 지속되므로 **데이터 손실 방지**에 실패
- **결론:** ❌ **오답** (업그레이드 시 데이터 손실을 방지하지 못함)

---

### B. **Lambda 함수의 실행 시간 연장 + 재시도(Retry)**
- **문제점:**
  - **Lambda의 최대 실행 시간(15분)**을 넘는 업그레이드에는 **데이터 손실** 발생
  - **재시도(Retry)**는 일시적인 장애에만 효과적이며 **지속적인 업그레이드**에는 비효율적
- **결론:** ❌ **오답** (지속적인 업그레이드 중 데이터 손실을 방지하지 못함)

---

### C. **Lambda 로컬 스토리지 사용**
- **문제점:**
  - Lambda 함수는 **임시 로컬 스토리지(/tmp)**만 제공하며 **최대 10GB 제한**
  - **Lambda 함수 종료 시 데이터가 사라지므로** **지속적인 데이터 보관 불가능**
- **결론:** ❌ **오답** (Lambda 종료 시 데이터 손실 발생)

---

### D. **Amazon SQS FIFO Queue (정답)**
- **장점:**
  - **Lambda 함수**가 고객 데이터를 **SQS FIFO Queue**에 저장 → 데이터가 **내구성 있게 유지**
  - **Aurora 업그레이드 중**에도 **고객 데이터 손실 방지**
  - 업그레이드가 완료되면 **별도의 Lambda 함수**가 큐의 메시지를 읽어 **데이터베이스에 저장**
  - **FIFO(First-In-First-Out)** 큐로 **데이터 순서 보장**
  - **비동기 처리**로 **Lambda 함수**와 **데이터베이스** 간의 **결합도**가 감소하여 **시스템 안정성 향상**
- **결론:** ✅ **정답** (가장 효율적이며 AWS 모범 사례에 부합)

---

## ✅ **최종 정답:**
- 고객 데이터를 **Amazon SQS FIFO Queue**에 저장하여 **Aurora 업그레이드 중에도 데이터 손실을 방지**
- 업그레이드 완료 후 **Lambda 소비자 함수**가 **SQS FIFO Queue**의 메시지를 읽어 **순차적으로 데이터베이스에 저장**
- **AWS 모범 사례(Best Practice)**에 따라 **비동기 처리**와 **내구성 보장**으로 **안정성 및 확장성**을 확보

---

# Q88

## 1. 문제 요구 사항 정리

- **목표:** 미국에 있는 Amazon S3 버킷(3TB 이상)에 저장된 데이터를 **유럽의 마케팅 회사**와 **비용을 최소화**하면서 공유
- **데이터 크기:** 3TB 이상이며 지속적으로 증가 중
- **중요 조건:**
  - **데이터 전송 비용을 최소화**할 것
  - **효율적이고 안전한 공유 방식** 필요

---

## 2. 주요 개념

### ✅ **Amazon S3 Requester Pays**
- **기능:**
  - **S3 Requester Pays** 옵션을 사용하면 **데이터 요청자(마케팅 회사)**가 **S3 데이터 전송 비용**을 부담
  - 소유자(데이터 제공자)는 **데이터 저장 비용만 지불**
- **비용 절감:**
  - 데이터 제공자는 **전송 비용을 절감**하며, 데이터 사용자는 필요에 따라 비용을 지불함

### 🔁 **S3 Cross-Region Replication (CRR)**
- **기능:**
  - **S3 CRR**은 한 AWS 리전의 데이터를 **다른 리전으로 복제**하여 **복사본을 유지**
  - **비용:** 데이터 전송 시 **복제 비용과 데이터 전송 비용**이 발생 → **비용 증가**

### 🔗 **Cross-Account Access**
- **기능:**
  - **S3 권한**을 통해 **다른 AWS 계정**이 **원본 버킷**에 직접 접근 가능
  - 하지만 **데이터 전송 비용**은 **원본 버킷 소유자**가 부담

### 💾 **S3 Intelligent-Tiering**
- **기능:**
  - **S3 Intelligent-Tiering**은 **액세스 패턴에 따라** 데이터를 자동으로 **비용 효율적인 스토리지 클래스로 이동**
  - **전송 비용 절감**과는 **직접적인 관계 없음**

---

## 3. 해설

### A. **Requester Pays (정답)**
- **장점:**
  - **데이터 전송 비용**을 **요청자(마케팅 회사)**가 부담
  - **데이터 제공자(회사)**는 **저장 비용**만 지불 → **비용 절감**
  - **구성 및 유지보수 간단**하며 **추가 인프라 불필요**
- **결론:** ✅ **정답** (비용 최소화를 위한 가장 효과적이고 단순한 솔루션)

---

### B. **S3 Cross-Region Replication**
- **단점:**
  - **복제 비용과 데이터 전송 비용**이 발생하여 **비용이 증가**
  - 지속적으로 **데이터가 증가**하므로 비용이 계속 상승
- **결론:** ❌ **오답** (비용 절감에 부적합)

---

### C. **Cross-Account Access**
- **단점:**
  - **전송 비용**은 **버킷 소유자(회사)**가 부담
  - **마케팅 회사가 비용을 지불하지 않으므로** 비용 절감 불가
- **결론:** ❌ **오답** (비용 최소화 목표에 맞지 않음)

---

### D. **S3 Intelligent-Tiering + Sync**
- **단점:**
  - **Intelligent-Tiering**은 **저장 비용**을 절감하지만, **데이터 전송 비용**에는 영향이 없음
  - **Sync**는 추가적인 **네트워크 비용**을 발생시켜 **비용 증가**
- **결론:** ❌ **오답** (전송 비용을 절감하지 못함)

---

## ✅ **최종 정답:**
- **Amazon S3 Requester Pays** 기능을 활성화하여 **마케팅 회사가 데이터 전송 비용을 부담**
- 데이터 제공자는 **저장 비용만 지불**하여 **비용 절감**
- **간단한 구성**으로 **운영 오버헤드**가 최소화되며 **AWS 모범 사례(Best Practice)**에 부합

---

# Q89

## 1. 문제 요구 사항 정리

- **목표:** Amazon S3에 저장된 **기밀 감사 문서(audit documents)**를 **실수로 삭제되는 것**을 방지
- **현재 상태:**
  - **버킷 정책(bucket policy)**을 사용하여 **IAM 사용자 권한**을 최소 권한 원칙(Least Privilege)에 따라 설정
- **추가 요구사항:**
  - **문서의 보안 강화** 및 **삭제 방지** 필요

---

## 2. 주요 개념

### ✅ **Amazon S3 Versioning**
- **모든 객체의 버전을 저장**하여 **삭제 및 덮어쓰기 방지**
- 사용자가 **객체를 삭제**해도 해당 객체는 **"삭제 마커(Delete Marker)"**로 표시되며 **완전히 삭제되지 않음**

### ✅ **Amazon S3 MFA Delete**
- **다단계 인증(MFA)**을 사용하여 객체를 **완전히 삭제**하거나 **버전 삭제** 시 **추가 인증** 요구
- **버킷 소유자만 활성화 가능**하며, **S3 버전 관리와 함께 사용**
- **실수로 인한 삭제 방지**에 **가장 강력한 보안** 제공

---

## 3. 해설

### A. **S3 Versioning + MFA Delete (정답)**
- **장점:**
  - **Versioning**으로 **실수로 삭제**된 객체를 **복원 가능**
  - **MFA Delete**는 **버전 삭제 시 추가 인증**이 필요하여 **의도치 않은 삭제 방지**
  - **보안 및 컴플라이언스 요구사항**을 모두 충족
- **결론:** ✅ **정답** (삭제 방지 및 보안 강화에 가장 적합한 옵션)

---

### B. **MFA on IAM User Credentials**
- **단점:**
  - **IAM 사용자 계정 보호**에만 해당되며, **S3 객체 삭제 방지와는 무관**
- **결론:** ❌ **오답** (삭제 방지에 대한 해결책이 아님)

---

### C. **S3 Lifecycle Policy to Deny Deletion During Audit Dates**
- **단점:**
  - **특정 날짜에만** 삭제를 제한하므로 **지속적인 보호** 제공 불가
  - **Audit 날짜 외**에는 **삭제가 가능**하여 **완벽한 보안**을 보장하지 못함
- **결론:** ❌ **오답** (지속적인 삭제 방지에 부적합)

---

### D. **AWS KMS Encryption + Restrict Access**
- **단점:**
  - **KMS 암호화**는 **데이터 보호**에 적합하지만 **삭제 방지 기능**은 없음
  - **IAM 사용자**가 접근할 수 없으면 **업무에 지장** 발생
- **결론:** ❌ **오답** (삭제 방지와는 관련이 없음)

---

## ✅ **최종 정답:**
- **Amazon S3 Versioning**을 사용하여 **객체의 모든 버전**을 유지하여 **실수로 인한 삭제를 방지**
- **MFA Delete** 기능을 활성화하여 **버전 삭제 시 추가 인증**을 요구하여 **보안을 강화**
- 이 조합은 **AWS 모범 사례(Best Practice)**에 따라 **감사 문서의 보안 및 무결성**을 보장

---

# Q90

## 1. 문제 요구 사항 정리

- **목표:** SQL 데이터베이스의 성능 저하를 방지하면서도 스크립트가 **하루 동안 추가된 영화 수를 집계**
- **현재 상태:**
  - **Amazon RDS Single-AZ DB 인스턴스** 사용 중
  - **스크립트**가 **랜덤하게 실행**되며, **업무 시간에 최종 합계**를 보고
  - **스크립트 실행 시 개발팀의 DB 성능 저하** 발생
- **해결책 요구사항:**
  - **DB 성능 저하 방지**
  - **운영 오버헤드 최소화**
  - **스크립트가 계속 작동**하도록 보장

---

## 2. 주요 개념

### ✅ **Amazon RDS Read Replica**
- **목적:**
  - **읽기 전용 데이터베이스**를 제공하여 **메인 DB의 읽기 부하 감소**
  - **다수의 읽기 작업**을 **Read Replica**로 전환하여 **성능 향상**
- **운영 오버헤드:**
  - **자동 동기화**로 **메인 DB와 동일한 데이터 유지**
  - **운영 및 유지보수 부담이 최소화**됨
- **비용:**
  - **비용 효율적**이며, **읽기 작업**이 많은 워크로드에 이상적

---

## 3. 해설

### A. **Multi-AZ Deployment**
- **목적:**
  - **고가용성(High Availability)** 제공으로 **성능 개선이 목적이 아님**
- **문제점:**
  - **읽기 성능 개선 없음** → **스크립트의 읽기 작업**에 도움을 주지 않음
  - **비용 증가** 및 **운영 오버헤드 증가**
- **결론:** ❌ **오답** (성능 개선이 아닌 가용성 목적이므로 부적합)

---

### B. **Read Replica (정답)**
- **장점:**
  - **메인 DB의 읽기 부하 감소** → 개발팀의 **DB 성능 저하 방지**
  - **스크립트는 Read Replica**에 연결되므로 **메인 DB에 영향 없음**
  - **자동 동기화**로 **운영 오버헤드 최소화**
- **결론:** ✅ **정답** (가장 간단하면서도 효율적인 해결책)

---

### C. **수동 데이터 내보내기 (Manual Export)**
- **단점:**
  - **수동 작업**으로 인해 **운영 오버헤드 증가**
  - **스크립트 자동화 요구사항을 충족하지 못함**
- **결론:** ❌ **오답** (운영 오버헤드가 크고 자동화 요구사항 미충족)

---

### D. **Amazon ElastiCache**
- **목적:**
  - **자주 조회되는 데이터**를 캐싱하여 **읽기 속도**를 개선
- **문제점:**
  - **스크립트의 읽기 쿼리**가 **랜덤 간격**으로 실행되어 **캐싱 효과가 제한적**
  - **운영 오버헤드** 및 **캐시 일관성 유지** 필요
- **결론:** ❌ **오답** (랜덤 쿼리에 대한 효과 제한 및 유지보수 부담 증가)

---

## ✅ **최종 정답:**
- **Amazon RDS Read Replica**를 생성하여 **스크립트의 읽기 작업**을 **Read Replica**에서 실행
- **메인 DB의 부하 감소**로 **개발팀의 성능 저하 방지**
- **자동 데이터 동기화**로 **운영 오버헤드 최소화**
- **AWS 모범 사례(Best Practice)**에 부합하며 **비용 효율성**과 **성능 개선**을 동시에 달성
