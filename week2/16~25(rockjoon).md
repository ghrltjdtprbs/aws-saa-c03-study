
# Q16.
## (1) 문제
한 회사가 **Amazon S3와 Amazon RDS for PostgreSQL을 포함하는 데이터 레이크**를 운영하고 있다.
- **데이터 시각화 및 보고 솔루션이 필요**하다.
- **모든 데이터 소스를 포함해야 한다.**
- **경영진은 전체 대시보드 접근 가능해야 하고, 나머지 직원은 제한된 접근 권한을 가져야 한다.**

## (2) 보기에 대한 설명

### ✅ A. 정답 (⭕)
**주요 키워드: Amazon QuickSight, 데이터 소스 연결, IAM 역할을 통한 접근 제어**
- **Amazon QuickSight**: AWS에서 제공하는 BI(비즈니스 인텔리전스) 도구로 **Amazon S3 및 RDS 데이터를 시각화하는 데 적합**하다.
- **데이터 소스 연결**: QuickSight는 **Amazon S3, Amazon RDS, Athena 등의 데이터 소스와 연결 가능**하다.
- **IAM 역할 기반 접근 제어**: QuickSight의 대시보드는 IAM 역할을 사용하여 공유할 수 있으므로, **경영진과 나머지 직원의 접근 차별화 가능**하다.

---

### ✅ B. 정답 (⭕)
**주요 키워드: Amazon QuickSight, 데이터 소스 연결, 사용자 및 그룹을 통한 접근 제어**
- **Amazon QuickSight**: A와 동일하게 **데이터 시각화 및 대시보드 제공 가능**
- **데이터 소스 연결**: 다양한 데이터 소스를 연결하여 **대시보드에서 시각화 가능**
- **사용자 및 그룹 기반 접근 제어**: A와의 차이점은 **IAM 역할이 아니라 사용자 및 그룹을 활용하여 접근을 제어한다는 점**이다.
- **AWS IAM Identity Center(AWS SSO)와 연계하면 더욱 세밀한 권한 제어 가능**

👉 **A와 B 모두 올바른 정답이 될 수 있으며, 접근 제어 방식의 차이만 존재한다.**

---

### ❌ C. 오답 (❌)
- AWS Glue ETL을 사용하여 데이터를 처리하고 Amazon S3에 보고서를 저장하는 방식
- 하지만 **이 방식은 "데이터 시각화" 기능이 부족**하여 대시보드 제공이 어렵다.
- 단순히 보고서를 S3에 저장하는 방식이므로, **실시간 데이터 분석 및 접근 제어 요구 사항을 충족하지 못함**

---

### ❌ D. 오답 (❌)
- Amazon Athena Federated Query를 활용하여 S3 및 RDS 데이터를 분석하는 방식
- **Amazon Athena는 SQL 기반 쿼리 서비스이며, 시각적 대시보드 제공 기능이 없음**
- 보고서를 S3에 저장하는 방식이므로, **인터랙티브한 대시보드 요구사항을 충족하지 못함**

---

## ✅ 최종 정답: **A 또는 B (Amazon QuickSight 사용)**
- **C, D는 데이터 시각화 요구사항을 충족하지 못하므로 오답**

---

# Q17.

## (1) 문제
한 회사가 새로운 비즈니스 애플리케이션을 구현하고 있다.
- **애플리케이션은 두 개의 Amazon EC2 인스턴스에서 실행되며, Amazon S3 버킷을 문서 저장소로 사용한다.**
- **EC2 인스턴스가 S3 버킷에 접근할 수 있도록 솔루션을 설계해야 한다.**

## (2) 보기에 대한 설명

### ✅ A. 정답 (⭕)
**주요 키워드: IAM Role(역할), EC2 Instance Profile, 최소 권한 원칙**
- **IAM Role(역할) 사용**: EC2 인스턴스가 AWS 리소스(S3 등)에 안전하게 접근하려면 **IAM 역할을 생성하고 EC2 인스턴스에 부착해야 한다.**
- **Instance Profile 활용**: IAM 역할을 EC2 인스턴스에 부착하면 **인스턴스가 해당 역할의 권한을 사용하여 S3에 접근 가능**하다.
- **최소 권한 원칙 적용 가능**: 필요 최소한의 S3 권한을 역할에 부여하여 보안성을 높일 수 있다.

👉 **EC2에서 AWS 리소스에 접근할 때는 IAM Role을 사용해야 한다.**

---

### ❌ B. 오답 (❌)
- **IAM 정책은 직접 EC2 인스턴스에 부착할 수 없다.**
- 정책은 **IAM 역할, 사용자 또는 그룹에 연결되는 객체**이므로, **단독으로 EC2에 적용할 수 없음**

---

### ❌ C. 오답 (❌)
- **IAM 그룹은 IAM 사용자에게만 적용 가능하며, EC2 인스턴스에 적용할 수 없음**
- EC2 인스턴스에는 **IAM Role을 사용해야 한다.**

---

### ❌ D. 오답 (❌)
- **IAM 사용자를 EC2 인스턴스에 부착하는 방식은 존재하지 않음**
- **보안 모범 사례를 위반**하며, 애플리케이션이 액세스 키를 사용해야 하는 비효율적인 방식이므로 비추천됨  


--- 

# Q18.

## (1) 문제
한 개발팀이 **마이크로서비스를 설계**하고 있다.
- 사용자가 이미지를 업로드하면 **S3 버킷에 저장**
- AWS Lambda 함수가 이미지를 **처리 및 압축**
- 압축된 이미지를 **다른 S3 버킷에 저장**
- **내구성이 높고(stateless) 자동으로 실행되는 솔루션을 설계해야 함**

## (2) 보기에 대한 설명

### ✅ A. 정답 (⭕)
**주요 키워드: Amazon S3 이벤트 알림, Amazon SQS, 비동기 처리**
- **Amazon S3 이벤트 알림**을 사용하여 **새로운 이미지 업로드 시 SQS에 메시지를 전송**
- **SQS는 Lambda 또는 다른 컴퓨팅 서비스에서 비동기적으로 메시지를 처리할 수 있도록 지원**
- **이벤트 기반 아키텍처를 구축하는데 적합한 선택**

---

### ✅ B. 정답 (⭕)
**주요 키워드: Lambda SQS 트리거, 메시지 삭제**
- **Lambda를 SQS의 이벤트 소스로 설정**하여 **대량의 이미지 처리 요청을 효율적으로 관리 가능**
- **Lambda가 SQS 메시지를 처리한 후, 메시지를 삭제하여 중복 처리를 방지**
- **SQS를 활용하면 트래픽 급증 시에도 안정적으로 처리 가능 (비동기 메시지 큐 방식)**

---

### ❌ C. 오답 (❌)
- Lambda 함수가 **S3 업로드를 직접 모니터링하도록 설계하는 것은 비효율적**
- **파일 이름을 메모리에 저장하는 방식은 내구성이 부족하며, 다중 인스턴스 환경에서 충돌 가능**

---

### ❌ D. 오답 (❌)
- **EC2 인스턴스를 실행하여 SQS를 모니터링하는 것은 불필요한 비용과 복잡성을 초래**
- **Lambda를 직접 SQS와 연동하는 것이 더 적절한 설계 방식**

---

### ❌ E. 오답 (❌)
- **SNS를 사용하여 알람을 보내는 것은 이미지 자동 처리를 위한 적절한 솔루션이 아님**
- **SNS는 알림 및 이벤트 브로드캐스트용이며, 직접 이미지 처리를 수행할 수 없음**

---

## ✅ 최종 정답: **A, B (Amazon S3 이벤트 → SQS → Lambda 트리거)**
- **S3 업로드 이벤트를 SQS로 전달하고, SQS를 트리거로 Lambda를 실행하는 것이 가장 적절한 설계**


---

# Q19.


## (1) 문제
한 회사가 **3계층 웹 애플리케이션을 AWS에서 운영**하고 있다.
- **웹 서버는 VPC의 퍼블릭 서브넷에 배포**
- **애플리케이션 서버 및 데이터베이스 서버는 프라이빗 서브넷에 배포**
- **AWS Marketplace에서 제공하는 가상 방화벽 어플라이언스를 "검사 VPC"에 배포**
- **웹 애플리케이션으로 들어오는 모든 트래픽이 방화벽을 거쳐 웹 서버로 전달되어야 함**
- **운영 오버헤드(Operational Overhead)가 최소화되는 솔루션을 설계해야 함**

## (2) 보기에 대한 설명

### ✅ D. 정답 (⭕)
**주요 키워드: Gateway Load Balancer (GWLB), VPC Endpoint, 트래픽 검사**
- **Gateway Load Balancer (GWLB)**는 **가상 어플라이언스(방화벽 등)와의 원활한 통합을 지원하는 AWS 서비스**
- **GWLB는 트래픽을 방화벽 어플라이언스로 라우팅하고, 처리된 트래픽을 다시 애플리케이션으로 전달 가능**
- **Gateway Load Balancer Endpoint(GWLB Endpoint)를 활용하면 애플리케이션 VPC에서 쉽게 트래픽을 검사 VPC로 보낼 수 있음**
- **운영 오버헤드가 낮고, 네트워크 경로가 자동으로 관리되므로 가장 적합한 해결책**

---

### ❌ A. 오답 (❌)
- **Network Load Balancer (NLB)**는 주로 **고속 패킷 라우팅 및 TCP/UDP 기반 부하 분산을 위한 용도**
- **NLB는 트래픽 검사 기능이 없으며, 방화벽 어플라이언스와 직접 연동하기 어렵다.**
- **트래픽이 웹 서버에 직접 전달될 가능성이 있어 요구사항을 충족하지 못함**

---

### ❌ B. 오답 (❌)
- **Application Load Balancer (ALB)**는 **HTTP/HTTPS 트래픽을 기반으로 부하 분산하는 역할**
- **ALB는 방화벽을 통과하는 네트워크 패킷 레벨 검사를 수행하지 않으며, 타사 방화벽과의 통합이 어려움**
- **방화벽을 통한 모든 트래픽 검사를 요구하는 문제의 조건을 충족하지 못함**

---

### ❌ C. 오답 (❌)
- **Transit Gateway는 VPC 간 트래픽을 연결하는 데 유용하지만, 방화벽과의 직접적인 통합 기능이 없음**
- **트래픽을 검사하는 기능을 제공하지 않으며, 트래픽이 직접 웹 서버로 전달될 수 있음**
- **보안 요구사항을 충족하기 위해 추가적인 라우팅 및 NAT 구성이 필요하여 운영 오버헤드가 증가**

---

## ✅ 최종 정답: **D (Gateway Load Balancer + GWLB Endpoint)**
- **GWLB는 AWS에서 제공하는 공식적인 방화벽 통합 솔루션**
- **운영 오버헤드가 낮고, 자동으로 트래픽을 검사할 수 있어 최적의 선택**  


```
참고) 검사 VPC(Inspection VPC)란?
검사 VPC(Inspection VPC)는 네트워크 트래픽을 검사하고 보안 정책을 적용하는 역할을 하는 별도의 VPC다.

애플리케이션 VPC(실제 서비스가 배포된 VPC)와 분리하여 보안 및 네트워크 관리를 쉽게 할 수 있음
외부에서 들어오는 모든 트래픽을 검사 VPC를 통해 필터링한 후 애플리케이션으로 전달
보통 방화벽, IDS/IPS, 로깅 시스템 등을 배포하여 보안 강화
검사 VPC와 애플리케이션 VPC 관계
📌 검사 VPC는 별도의 VPC이며, 애플리케이션 VPC와는 분리되어 있음
📌 VPC 피어링, Transit Gateway, Gateway Load Balancer(GWLB) 등을 사용해 애플리케이션 VPC와 연결
📌 외부에서 유입되는 트래픽이 웹 서버로 가기 전에 검사 VPC를 통해 보안 점검 수행

검사 VPC를 사용하는 이유
✅ 보안 강화: 모든 인바운드 트래픽을 방화벽을 통해 필터링하여 악성 트래픽 차단
✅ 중앙 집중식 관리: 여러 애플리케이션 VPC의 보안 정책을 한 곳에서 관리 가능
✅ 운영 오버헤드 감소: 각 애플리케이션 VPC마다 방화벽을 배포할 필요 없이 중앙에서 관리 가능

AWS에서 검사 VPC를 구현하는 방법
AWS Marketplace에서 제공하는 가상 방화벽(예: Palo Alto, Fortinet, Check Point 등)을 배포
Gateway Load Balancer(GWLB)와 GWLB 엔드포인트를 활용하여 트래픽을 검사 VPC로 우회
Transit Gateway를 사용해 여러 VPC 간 트래픽을 검사 VPC를 경유하도록 설정

```

---

# Q20.

## (1) 문제
한 회사가 **대량의 프로덕션 데이터를 빠르게 클론하여 테스트 환경을 구축하고자 한다.**
- **데이터는 EC2 인스턴스의 EBS 볼륨에 저장됨**
- **클론된 데이터는 프로덕션 환경에 영향을 주지 않아야 함**
- **소프트웨어는 일관되게 높은 I/O 성능을 요구**
- **최대한 빠르게 데이터를 복제해야 함**

## (2) 보기에 대한 설명

### ✅ D. 정답 (⭕)
**주요 키워드: EBS 스냅샷, Fast Snapshot Restore(FSR), 빠른 데이터 복구**
- **EBS Fast Snapshot Restore (FSR)**: EBS 스냅샷을 **즉시 사용 가능한 상태**로 복원하여, **지연 시간 없이 고성능 I/O를 보장**
- **빠른 데이터 복사**: FSR을 활성화하면 **새 EBS 볼륨이 프로덕션 데이터와 동일한 상태로 즉시 준비됨**
- **독립적인 테스트 환경**: **새 EBS 볼륨을 생성하여 프로덕션 데이터에 영향을 주지 않음**
- **운영 오버헤드 최소화**: EBS 스냅샷을 활용하면서, FSR로 속도를 극대화

👉 **EBS 스냅샷을 기반으로 빠르게 클론을 생성해야 하므로 FSR을 사용하는 것이 가장 적절한 해결책**

---

### ❌ A. 오답 (❌)
- **EC2 인스턴스 스토어 볼륨은 휘발성(Volatile) 스토리지이며, 영구 데이터 저장에 적합하지 않음**
- **EBS 스냅샷을 인스턴스 스토어로 복구할 수 없음**
- **I/O 성능은 높지만, 테스트 환경에서 지속적인 데이터 유지가 어려움**

---

### ❌ B. 오답 (❌)
- **EBS Multi-Attach은 동일한 EBS 볼륨을 여러 EC2 인스턴스에서 공유하는 기능**이지만, **대상으로 사용할 수 있는 볼륨이 제한됨**
- **프로덕션 EBS 볼륨을 직접 테스트 환경에 연결하면 데이터 무결성이 손상될 가능성이 있음**
- **스냅샷을 활용하여 독립적인 볼륨을 생성해야 하는 요구사항을 충족하지 못함**

---

### ❌ C. 오답 (❌)
- **EBS 스냅샷을 새 EBS 볼륨으로 복원하는 과정에서 초기 I/O 성능 저하 발생**
- **EBS 볼륨은 스냅샷을 기반으로 처음 사용될 때 데이터를 점진적으로 로드(Lazy Load)하기 때문에, 고성능이 필요한 경우 FSR이 필요함**
- **FSR 없이 복원하면, 초기 데이터 접근 시 높은 I/O 성능을 보장할 수 없음**

---

## ✅ 최종 정답: **D (EBS Fast Snapshot Restore 활용)**
- **EBS Fast Snapshot Restore(FSR)를 사용하여 즉시 고성능 복구 가능**
- **프로덕션 데이터를 독립적으로 복제하며, 성능 저하 없이 운영 가능**
- **최대한 빠른 복제를 요구하는 요구사항을 충족함**

---

# Q21.

## (1) 문제
한 전자상거래(e-commerce) 회사가 **하루에 하나의 제품을 판매하는 웹사이트를 AWS에 구축**하려고 한다.
- **매일 24시간 동안 하나의 제품만 판매**
- **시간당 수백만 개의 요청을 처리할 수 있어야 함**
- **밀리초(ms) 단위의 응답 속도가 필요**
- **운영 오버헤드가 최소화되어야 함**

## (2) 보기에 대한 설명

### ✅ D. 정답 (⭕)
**주요 키워드: Amazon S3, CloudFront, API Gateway, Lambda, DynamoDB (서버리스 아키텍처)**
- **Amazon S3 + CloudFront**: 정적 콘텐츠(HTML, CSS, JavaScript 등)를 S3에 저장하고, CloudFront를 사용하여 **전 세계적으로 빠른 콘텐츠 제공**
- **Amazon API Gateway + AWS Lambda**: API Gateway와 Lambda를 사용하여 백엔드를 **서버리스(Serverless)로 구축하여 자동 확장 및 비용 절감**
- **Amazon DynamoDB**: 초당 수백만 개의 요청을 처리할 수 있는 **완전 관리형 NoSQL 데이터베이스** → 높은 확장성과 빠른 응답 속도 제공
- **운영 오버헤드 최소화**: 서버리스 아키텍처를 사용하여 **EC2 또는 컨테이너를 직접 관리할 필요 없음**

👉 **서버리스 아키텍처를 활용하여 확장성을 극대화하고, 밀리초(ms) 단위의 응답을 보장할 수 있으므로 가장 적절한 솔루션**

---

### ❌ A. 오답 (❌)
- **Amazon S3와 CloudFront를 활용하는 것은 정적 콘텐츠 배포에 적절하지만, 백엔드 로직을 처리할 수 없음**
- **주문 데이터(order data)를 Amazon S3에 저장하는 것은 실시간 트랜잭션 처리를 요구하는 e-commerce 사이트에 부적절함**
- **S3는 데이터 저장소이지 데이터베이스가 아니므로, 빠른 검색 및 트랜잭션 처리 기능이 부족**

---

### ❌ B. 오답 (❌)
- **EC2 인스턴스를 Auto Scaling으로 확장하는 것은 가능하지만, 운영 오버헤드가 높음**
- **초당 수백만 개의 요청을 처리할 경우, EC2 인스턴스의 확장 속도가 Lambda와 같은 서버리스 솔루션보다 느릴 수 있음**
- **Amazon RDS for MySQL은 수직적 확장(scale-up) 방식이므로, 트래픽이 급격히 증가할 경우 확장성이 한계에 도달할 가능성이 있음**

---

### ❌ C. 오답 (❌)
- **Amazon EKS (Kubernetes)는 컨테이너 오케스트레이션을 위한 서비스로, 높은 확장성과 유연성을 제공하지만 운영 오버헤드가 큼**
- **Kubernetes Cluster Autoscaler를 사용하면 확장 가능하지만, 트래픽 급증 시 EC2 기반 컨테이너보다 Lambda가 더 빠르게 확장 가능**
- **데이터 저장소로 RDS를 사용하므로 트랜잭션 처리 속도가 DynamoDB보다 느릴 가능성이 높음**

---

## ✅ 최종 정답: **D (서버리스 아키텍처 - S3 + CloudFront + API Gateway + Lambda + DynamoDB)**
- **가장 낮은 운영 오버헤드**
- **자동 확장성(서버리스)**
- **밀리초(ms) 단위의 응답 속도 제공**
- **수백만 개의 요청을 효율적으로 처리 가능**

---

# Q22.

## (1) 문제
새로운 디지털 미디어 애플리케이션에서 **Amazon S3를 사용한 스토리지 아키텍처를 설계**해야 한다.
- **데이터는 AZ 손실에도 복원 가능해야 함** (내구성 및 가용성이 중요)
- **일부 파일은 자주 접근되지만, 일부 파일은 드물게 접근됨**
- **파일 접근 패턴이 예측 불가능함**
- **스토리지 및 검색 비용을 최소화해야 함**

## (2) 보기에 대한 설명

### ✅ B. 정답 (⭕)
**주요 키워드: S3 Intelligent-Tiering, 자동 비용 최적화, 가용성 존(AZ) 내구성 보장**
- **S3 Intelligent-Tiering은 자주 액세스되는 데이터와 드물게 액세스되는 데이터를 자동으로 최적화하여 비용을 절감함**
- **파일 접근 패턴이 예측 불가능한 경우에 적합함**
- **데이터가 여러 가용성 존(AZ)에 저장되어 AZ 손실에도 복원 가능**
- **운영 오버헤드 없이 자동으로 데이터를 가장 비용 효율적인 스토리지 클래스로 이동**

👉 **파일 접근 패턴이 예측 불가능한 경우에는 S3 Intelligent-Tiering이 가장 적절한 선택**

---

### ❌ A. 오답 (❌)
- **S3 Standard는 높은 가용성과 내구성을 제공하지만, 비용이 가장 높음**
- **자주 사용되지 않는 파일도 표준 가격을 적용받아 비용 최적화에 부적합**
- **접근 패턴이 예측 불가능한 경우, Intelligent-Tiering이 더 적절함**

---

### ❌ C. 오답 (❌)
- **S3 Standard-IA (Infrequent Access)는 저장 비용이 낮지만 검색 비용이 높음**
- **자주 액세스되는 데이터에 대한 비용이 비효율적이며, 접근 패턴이 불규칙한 경우 비용 절감 효과가 낮음**
- **Intelligent-Tiering과 달리 자동 계층 이동이 불가능하여, 수동 관리가 필요함**

---

### ❌ D. 오답 (❌)
- **S3 One Zone-IA는 단일 가용성 존(AZ)에만 데이터를 저장하므로, AZ 장애 시 데이터 손실 위험이 있음**
- **문제에서 "AZ 손실에도 복원 가능해야 한다"는 조건을 충족하지 못함**
- **비용은 낮지만 내구성이 낮아 디지털 미디어 애플리케이션에 적합하지 않음**

---

## ✅ 최종 정답: **B (S3 Intelligent-Tiering)**
- **자동 계층 이동으로 비용 최적화 가능**
- **다중 AZ 내구성을 보장하여 데이터 손실 방지**
- **자주 액세스 및 드물게 액세스되는 파일을 자동으로 최적화**
- **운영 오버헤드 없이 예측 불가능한 접근 패턴을 지원**  


---

# Q24.

## (1) 문제
회사는 **Amazon EC2 비용 증가를 감지**했다.
- 최근 청구서에서 **원하지 않는 EC2 인스턴스의 수직 확장(Vertical Scaling) 현상**이 발견됨
- **지난 2개월 동안의 EC2 비용을 비교하는 그래프를 생성하고, 원인을 분석해야 함**
- **운영 오버헤드가 최소화된 방법을 사용해야 함**

## (2) 보기에 대한 설명

### ✅ B. 정답 (⭕)
**주요 키워드: AWS Cost Explorer, 세부 필터링(Granular Filtering), 운영 오버헤드 최소화**
- **AWS Cost Explorer**는 비용 데이터를 **인스턴스 유형, 태그, 서비스별로 세분화하여 분석 가능**
- **"Granular Filtering" 기능을 사용하면 EC2 인스턴스 유형별 비용 변화를 쉽게 분석할 수 있음**
- **UI에서 과거 2개월의 데이터를 선택하여 비용을 그래프로 비교 가능**
- **즉각적인 비용 분석이 가능하므로 운영 오버헤드가 낮음**

👉 **비용 분석 및 시각화가 필요할 때 Cost Explorer를 활용하는 것이 가장 간편하고 빠른 방법**

---

### ❌ A. 오답 (❌)
- **AWS Budgets는 예산 초과 알림을 위한 도구이며, 세부적인 비용 분석 기능이 부족함**
- **비용 변화의 원인을 분석하기에는 Cost Explorer보다 적합하지 않음**

---

### ❌ C. 오답 (❌)
- **AWS Billing and Cost Management 대시보드는 총 비용만 보여주며, 특정 EC2 인스턴스 유형별 비용 비교가 어려움**
- **세부적인 인스턴스 분석이 필요하므로 Cost Explorer가 더 적합**

---

### ❌ D. 오답 (❌)
- **AWS Cost and Usage Reports (CUR)는 가장 상세한 비용 데이터를 제공하지만, CSV 파일을 S3에 저장하고 QuickSight로 분석해야 함**
- **설정 과정이 복잡하며, 추가적인 데이터 처리와 시각화 작업이 필요하므로 운영 오버헤드가 큼**
- **즉시 분석해야 하는 상황에서는 Cost Explorer가 더 적절함**

---

## ✅ 최종 정답: **B (AWS Cost Explorer 활용)**
- **빠르게 EC2 비용을 인스턴스 유형별로 필터링 및 시각화 가능**
- **운영 오버헤드가 가장 낮음**
- **과거 2개월의 비용을 쉽게 비교하여 원인 분석 가능**  

---

# Q25.

## (1) 문제
한 회사가 **AWS Lambda와 Amazon API Gateway를 사용하여 데이터를 수집하고, Amazon Aurora PostgreSQL에 저장하는 애플리케이션을 설계** 중이다.
- **초기 테스트(Proof-of-Concept)에서 Lambda의 한도를 대폭 증가해야 할 정도로 높은 데이터 처리량이 발생**
- **확장성을 개선하고, 설정(Configuration) 노력을 최소화해야 함**

## (2) 보기에 대한 설명

### ✅ D. 정답 (⭕)
**주요 키워드: 비동기 처리, Amazon SQS, 확장성 향상**
- **Lambda를 직접 데이터베이스에 연결하면 동시 실행 제한(Concurrency Limits) 및 연결 제한(Connection Limits) 문제 발생**
- **Amazon SQS를 사용하면 데이터를 큐에 저장한 후, 병렬적으로 데이터를 Aurora PostgreSQL로 로드 가능 → 데이터 처리 속도를 향상하고 확장성을 개선**
- **Lambda는 SQS 이벤트 소스를 기반으로 자동 확장 가능**
- **SQS는 메시지 큐잉을 통해 트래픽 급증 시에도 안정적인 데이터 처리 지원**

👉 **비동기 아키텍처를 도입하여 Lambda의 부하를 줄이고, Aurora의 연결 제한 문제를 해결할 수 있는 가장 적절한 솔루션**

---

### ❌ A. 오답 (❌)
- **Lambda에서 EC2로 변경하면 관리 오버헤드가 증가하고, 자동 확장성을 상실**
- **EC2 인스턴스에서 JDBC 연결을 직접 관리해야 하므로 Aurora 연결 제한 문제가 여전히 발생**
- **설정(Configuration) 노력이 증가하며, 확장성이 오히려 감소**

---

### ❌ B. 오답 (❌)
- **Aurora PostgreSQL을 DynamoDB로 변경하는 것은 요구사항을 변경하는 것이므로 부적절**
- **Aurora에서 복잡한 SQL 쿼리를 실행할 가능성이 있는데, DynamoDB는 SQL 지원이 제한적**
- **DynamoDB Accelerator (DAX)는 읽기 캐싱 솔루션이며, 대량의 데이터 쓰기 처리 문제를 해결하지 못함**

---

### ❌ C. 오답 (❌)
- **Amazon SNS는 푸시 기반(Pub/Sub) 서비스로, 메시지를 여러 수신자에게 브로드캐스트할 때 적합**
- **이 문제에서는 "데이터를 안정적으로 저장하고 비동기적으로 처리하는 것이 중요"하므로, 큐잉을 지원하는 SQS가 더 적절함**
- **SNS는 메시지 보관 기능이 없기 때문에, 데이터 유실 가능성이 있음**

---

## ✅ 최종 정답: **D (Amazon SQS를 사용하여 Lambda 간 비동기 통신)**
- **Lambda의 동시 실행 제한 문제를 해결하고, Aurora 연결 제한을 방지**
- **Amazon SQS를 활용하여 데이터 처리량을 확장 가능**
- **운영 오버헤드 최소화 및 구성 노력 절감**  
