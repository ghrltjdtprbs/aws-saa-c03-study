## Q1

````

한 회사는 **여러 대륙에 걸쳐 도시의 온도, 습도, 기압에 대한 데이터를 수집**합니다.
회사가 매일 각 사이트에서 수집하는 평균 데이터 양은 500GB입니다.
각 사이트에는 고속 인터넷 연결이 제공됩니다.
회사는 이러한 모든 글로벌 사이트의 **데이터를 단일 Amazon S3 버킷에 가능한 한 빨리 집계**하려고 합니다. 솔루션은 **운영상의 복잡성을 최소화**해야 합니다.
이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

A. 대상 S3 버킷에서 S3 Transfer Acceleration을 활성화합니다.
멀티파트 업로드를 사용하여 사이트 데이터를 대상 S3 버킷에 직접 업로드합니다.

B. 각 사이트의 데이터를 가장 가까운 지역의 S3 버킷에 업로드합니다.
S3 교차 리전 복제를 사용하여 대상 S3 버킷에 객체를 복사합니다. 그런 다음 원본 S3 버킷에서 데이터를 제거합니다.

C. 매일 AWS Snowball Edge Storage Optimized 디바이스 작업을 예약하여 각 사이트에서 가장 가까운 리전으로 데이터를 전송합니다.
S3 교차 리전 복제를 사용하여 대상 S3 버킷에 객체를 복사합니다.

D. 각 사이트의 데이터를 가장 가까운 지역의 Amazon EC2 인스턴스에 업로드합니다. Amazon EBS 볼륨에 데이터를 저장합니다.
정기적으로 EBS 스냅샷을 찍어 대상 S3 버킷이 포함된 리전에 복사합니다. 해당 리전에서 EBS 볼륨을 복원합니다.

````

### 문제 상황 정리

- **데이터 특성**: 각 글로벌 사이트에서 매일 약 500GB의 온도, 습도, 기압 데이터를 수집
- **네트워크 환경**: 각 사이트에는 고속 인터넷 연결이 있음
- **요구 사항**: 전 세계의 데이터를 가능한 한 빨리 단일 Amazon S3 버킷에 집계할 것
- **운영 복잡성**: 가능한 한 단순해야 함

---

### ① A

- **S3 Transfer Acceleration**
   - **기능**: Amazon S3 버킷에 데이터를 업로드할 때, AWS의 전 세계에 분포된 엣지 로케이션(CloudFront 네트워크)을 사용하여 인터넷 경로를 최적화합니다.
   - **장점**: 전 세계 어디서든 업로드 속도를 개선할 수 있으며, 별도의 인프라 구성 없이 간단하게 활성화할 수 있습니다.
   - **AWS 공식 문서**: [Amazon S3 Transfer Acceleration](https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/transfer-acceleration.html)
- **멀티파트 업로드**
    - **기능**: 대용량 파일을 여러 작은 부분으로 나누어 동시에 업로드할 수 있게 해주어, 전송 중 오류 발생 시 재전송할 부분만 다시 업로드할 수 있습니다.
    - **장점**: 전송 신뢰성이 높고, 네트워크 연결 문제 발생 시에도 전체 파일을 다시 전송할 필요가 없어 효율적입니다.
    - **AWS 공식 문서**: [Using the Amazon S3 Multipart Upload API](https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/mpuoverview.html)

  **정답인 이유**:

  - **직접 업로드**: 각 사이트가 고속 인터넷 연결을 가지고 있으므로 별도의 중간 단계를 두지 않고, 바로 대상 S3 버킷으로 데이터를 업로드할 수 있습니다.
  - **운영 복잡성 최소화**: 추가 인프라나 복잡한 프로세스를 구성할 필요 없이 S3의 기본 기능들만 사용하여 관리 부담을 줄입니다.
  - **전송 가속**: S3 Transfer Acceleration을 통해 전 세계에서 데이터 업로드 속도를 최적화할 수 있으므로, "가능한 한 빨리" 집계한다는 요구 사항을 만족시킵니다.

  ---

### ② B


- 각 사이트의 데이터를 **가장 가까운 지역의 S3 버킷**에 업로드
- **S3 교차 리전 복제**를 사용해, 각 로컬 S3 버킷의 객체를 중앙의 대상 S3 버킷으로 복사
- 복제가 완료된 후, 원본 S3 버킷의 데이터를 제거

**정답이 아닌 이유**:

  - **운영 복잡성 증가**: 사이트마다 별도의 S3 버킷을 생성하고, 교차 리전 복제를 설정해야 하며, 복제 후 데이터 삭제까지 추가적인 관리 작업이 필요합니다.
  - **비동기성 문제**: 교차 리전 복제는 비동기적으로 작동하므로, 데이터가 중앙 버킷에 완전히 반영되기까지 시간이 걸릴 수 있어 "가능한 한 빨리" 집계하라는 요구에 부합하지 않을 수 있습니다.

  ---

### ③  C

- **AWS Snowball Edge Storage Optimized** 디바이스를 매일 예약 작업으로 사용하여, 각 사이트에서 가장 가까운 리전으로 데이터를 전송
- 이후, **S3 교차 리전 복제**를 통해 대상 S3 버킷으로 데이터를 복사

**정답이 아닌 이유**:

- **네트워크 조건 고려**: Snowball Edge는 주로 네트워크 대역폭이 제한되거나 오프라인 데이터 전송이 필요한 경우 사용합니다.
- **추가 작업 필요**: 디바이스 예약, 물리적 이동, 데이터 로드 등 추가적인 운영 작업이 필요하며, 이는 복잡성을 증가시킵니다.
- **고속 인터넷 존재**: 각 사이트에 고속 인터넷 연결이 있으므로 굳이 오프라인 전송 장비를 사용할 필요가 없습니다.

  ---

### ④  D

- 각 사이트의 데이터를 **가장 가까운 지역의 Amazon EC2 인스턴스**에 업로드
- 데이터를 **Amazon EBS 볼륨**에 저장
- 주기적으로 EBS 스냅샷을 찍어, 대상 S3 버킷이 있는 리전으로 복사
- 대상 리전에서 EBS 볼륨을 복원

  **정답이 아닌 이유**:

- **과도한 인프라 관리**: EC2, EBS, 스냅샷 등 여러 서비스를 연계해야 하므로 운영상의 복잡성이 매우 높습니다.
- **불필요한 단계**: 데이터를 S3에 집계하려는 목적에 비해 너무 많은 중간 단계가 있으며, 전송 속도와 관리 효율성 면에서 비효율적입니다.
- **대체 가능한 간단한 솔루션 존재**: 이미 S3 Transfer Acceleration을 사용한 간단하고 효과적인 방법이 있으므로 굳이 복잡한 인프라를 도입할 필요가 없습니다.

  ---

### 결론

**정답은  A입니다.**

**왜 정답인가요?**
   - **간단한 구성**: 사이트에서 직접 대상 S3 버킷으로 데이터를 업로드하므로 별도의 인프라 구성이나 복잡한 관리 작업이 필요하지 않습니다.
  - **빠른 전송**: S3 Transfer Acceleration을 통해 전 세계 어디서나 빠른 데이터 업로드가 가능하며, 멀티파트 업로드를 사용해 안정적으로 대용량 데이터를 처리할 수 있습니다.
  - **운영 복잡성 최소화**: AWS S3의 기본 기능만 사용하므로, 추가적인 서비스 구성 없이도 요구 사항(빠른 데이터 집계, 운영 복잡성 최소화)을 충족합니다.


---
## Q2

```

회사에는 자사 독점 애플리케이션의 로그 파일을 분석할 수 있는 기능이 필요합니다. 
로그는 Amazon S3 버킷에 JSON 형식으로 저장됩니다. 쿼리는 간단하며 주문형으로 실행됩니다. 
솔루션 설계자는 기존 아키텍처를 최소한으로 변경하면서 분석을 수행해야 합니다.최소한의 운영 오버헤드로 이러한 요구 사항을 충족하려면 솔루션 설계자가 무엇을 해야 합니까?

A. Amazon Redshift를 사용하여 모든 콘텐츠를 한 곳에 로드하고 필요에 따라 SQL 쿼리를 실행하십시오.

B. Amazon CloudWatch Logs를 사용하여 로그를 저장합니다. Amazon CloudWatch 콘솔에서 필요에 따라 SQL 쿼리를 실행합니다.

C. Amazon S3와 함께 Amazon Athena를 직접 사용하여 필요에 따라 쿼리를 실행합니다.

D. AWS Glue를 사용하여 로그를 분류합니다. Amazon EMR에서 임시 Apache Spark 클러스터를 사용하여 필요에 따라 SQL 쿼리를 실행합니다.

```


### 문제 상황 정리

- **데이터 특성**: 자사 독점 애플리케이션의 로그 파일이 JSON 형식으로 Amazon S3 버킷에 저장됨
- **분석 요구**: 간단한 SQL 쿼리를 주문형(온디맨드 : 쓴 만큼만 비용 지불)으로 실행하여 로그 파일을 분석
- **요구 사항**: 기존 아키텍처에 최소한의 변경을 주면서 운영 오버헤드를 최소화하는 솔루션

---

###  A: Amazon Redshift 사용

  - **Amazon Redshift란?**
      - Amazon Redshift는 AWS에서 제공하는 데이터 웨어하우스 서비스로, 대규모 데이터 분석에 적합한 SQL 기반 분석 플랫폼입니다.
      - **특징**: 대용량 데이터 집계, 복잡한 쿼리, 데이터 로딩 및 ETL(추출, 변환, 적재) 작업이 필요할 때 주로 사용됩니다.
  - **문제 적용 시 고려 사항**:
      - 로그 파일이 S3에 저장되어 있는데, 이를 Redshift로 로드하려면 데이터를 ETL(추출-변환-적재)하여 로드해야 합니다.
      - **운영 오버헤드 증가**: ETL 파이프라인 구성, 데이터 로드 주기 관리 등 기존 아키텍처에 추가적인 변경이 필요합니다.
  - **결론** : 간단한 주문형 쿼리 분석 용도로는 불필요하게 복잡하며, 운영 오버헤드가 증가하므로 부적합합니다.

  ---

  ###  B: Amazon CloudWatch Logs 사용

  - **Amazon CloudWatch Logs란?**
      - CloudWatch Logs는 애플리케이션과 시스템 로그를 중앙에서 수집, 모니터링, 저장하는 서비스입니다.
      - **특징**: 실시간 로그 모니터링, 알람 설정, 로그 검색(CloudWatch Logs Insights) 기능을 제공하지만, 로그가 원래 저장되는 위치가 S3인 경우 데이터를 이동시키는 작업이 필요합니다.
  - **문제 적용 시 고려 사항**:
      - 현재 로그 파일은 이미 S3에 저장되어 있으므로, CloudWatch Logs로 옮기는 작업이 필요하게 됩니다.
      - CloudWatch Logs Insights에서 SQL과 유사한 쿼리를 실행할 수 있지만, 원래의 저장소인 S3에서 직접 쿼리하는 것보다 아키텍처 변경이 필요합니다.
  - **결론**: 로그를 S3에 그대로 두고 분석할 수 있는 더 간단한 방법이 있으므로, 운영 오버헤드를 최소화하는 측면에서는 적합하지 않습니다.

  ---

  ###  C: Amazon S3와 함께 Amazon Athena 직접 사용

  - **Amazon Athena란?**
      - Amazon Athena는 AWS에서 제공하는 서버리스 대화형 쿼리 서비스입니다.
      - **특징**:
          - **서버리스**: 인프라를 관리할 필요 없이 S3에 저장된 데이터를 SQL로 직접 쿼리할 수 있습니다.
          - **즉시 사용**: 별도의 데이터 이동이나 ETL 작업 없이, S3에 저장된 JSON 같은 다양한 데이터 형식을 바로 분석할 수 있습니다.
          - **운영 오버헤드 최소화**: 인프라 관리가 필요 없으므로, 기존 아키텍처에 영향을 주지 않고 주문형 쿼리 분석을 수행할 수 있습니다.
      - **AWS 공식 문서**: [Amazon Athena 사용자 가이드](https://docs.aws.amazon.com/ko_kr/athena/latest/ug/what-is.html)
  - **문제 적용 시 고려 사항**:
      - 로그 데이터가 이미 S3에 JSON 형식으로 저장되어 있으므로, Athena에서 바로 테이블 스키마를 정의하고 SQL 쿼리를 실행할 수 있습니다.
      - **기존 아키텍처 변경 최소화**: 별도의 데이터 이동이나 추가 인프라 구성 없이, 현재 S3에 있는 데이터를 그대로 분석할 수 있습니다.
  - **결론**: 요구 사항(간단한 주문형 SQL 쿼리 분석, 최소한의 운영 오버헤드, 기존 아키텍처 변경 최소화)을 가장 효과적으로 충족합니다.

  ---

  ###  D: AWS Glue와 Amazon EMR의 Apache Spark 클러스터 사용

  - **AWS Glue란?**
      - AWS Glue는 완전관리형 ETL(추출, 변환, 적재) 서비스로, 데이터 카탈로그 작성, 데이터 분류, 변환 작업을 자동화합니다.
  - **Amazon EMR와 Apache Spark란?**
      - Amazon EMR은 빅데이터 분석을 위한 관리형 클러스터 서비스로, Apache Spark와 같은 프레임워크를 사용하여 대규모 데이터 처리 작업을 수행합니다.
  - **문제 적용 시 고려 사항**:
      - AWS Glue를 통해 로그 파일을 분류한 후, EMR 클러스터에서 Spark를 사용하여 SQL 쿼리를 실행하는 방식은 여러 단계를 거치게 되어 운영 복잡성이 크게 증가합니다.
      - **운영 오버헤드 증가**: EMR 클러스터 구성, 관리 및 Spark 작업 실행 등 추가적인 인프라 관리가 필요하므로 단순한 주문형 쿼리 분석 요구 사항에 부합하지 않습니다.
  - **결론**: 불필요하게 복잡한 인프라와 작업이 필요하므로 최소한의 운영 오버헤드를 요구하는 상황에는 적합하지 않습니다.

  ---

  ### 최종 결론

  **정답은  C: Amazon S3와 함께 Amazon Athena를 직접 사용하여 필요에 따라 쿼리를 실행합니다.**

  - **왜  C가 정답인가요?**
      - **S3에 저장된 로그 파일 그대로 분석**: 로그 파일이 이미 S3에 JSON 형식으로 저장되어 있으므로, 별도의 데이터 이동이나 ETL 작업 없이 Athena로 바로 쿼리할 수 있습니다.
      - **서버리스 서비스**: Athena는 서버리스이기 때문에 인프라 관리를 하지 않아도 되며, 주문형으로 SQL 쿼리를 실행할 수 있습니다.
      - **운영 오버헤드 최소화**: 기존 아키텍처에 추가적인 변화를 주지 않으면서, 최소한의 설정만으로 요구 사항을 충족할 수 있습니다.


---
## Q3

``````

회사는 AWS Organizations를 사용하여 여러 부서의 여러 AWS 계정을 관리합니다. 관리 계정에는 프로젝트 보고서가 포함된 Amazon S3 버킷이 있습니다. 회사는 이 S3 버킷에 대한 액세스를 AWS Organizations의 조직 내 계정 사용자로만 제한하려고 합니다.

최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

A. 조직 ID에 대한 참조가 있는 aws PrincipalOrgID 글로벌 조건 키를 S3 버킷 정책에 추가합니다.

B. 각 부서에 대한 조직 단위(OU)를 만듭니다. S3 버킷 정책에 aws:PrincipalOrgPaths 글로벌 조건 키를 추가합니다.

C. AWS CloudTrail을 사용하여 CreateAccount, InviteAccountToOrganization, LeaveOrganization 및 RemoveAccountFromOrganization 이벤트를 모니터링합니다. 이에 따라 S3 버킷 정책을 업데이트합니다.

D. S3 버킷에 액세스해야 하는 각 사용자를 태그합니다. aws:PrincipalTag 글로벌 조건 키를 S3 버킷 정책에 추가합니다.

``````



### 문제 상황 정리

- **현재 상황**:
    - 회사는 AWS Organizations를 사용해 여러 부서의 여러 AWS 계정을 중앙에서 관리하고 있습니다.
    - 관리 계정에는 프로젝트 보고서가 저장된 Amazon S3 버킷이 있습니다.
- **요구 사항**:
    - 이 S3 버킷에 대한 액세스를 AWS Organizations 내의 계정 사용자로만 제한해야 합니다.
    - 운영상의 오버헤드를 최소화하는 방식이어야 합니다.

---

### 관련 기술 및 개념 설명

  ### 1. **AWS Organizations**

  - **기능**: 여러 AWS 계정을 중앙에서 관리하고, 정책 적용이나 결제 관리 등을 통합적으로 수행할 수 있는 서비스입니다.
  - **조직(Organization)**: 하나의 마스터(관리) 계정 아래 여러 개의 계정을 조직 내에 두어 관리합니다.

  ### 2. **Amazon S3**

  - **기본 개념**: Amazon S3는 객체(object) 스토리지 서비스로, 데이터를 버킷에 파일(객체) 단위로 저장합니다.
  - **버킷 정책**: S3 버킷에 대한 접근 제어를 설정할 때 IAM 정책과 유사한 JSON 형식의 정책을 사용합니다.

  ### 3. **AWS 글로벌 조건 키 (Global Condition Keys)**

  - AWS는 리소스 기반 정책에서 특정 조건을 검사하기 위한 글로벌 조건 키들을 제공합니다.
  - **aws:PrincipalOrgID**
      - **설명**: 이 조건 키는 요청을 보낸 주체(Principal)가 속한 AWS Organizations의 조직 ID를 의미합니다.
      - **활용**: S3 버킷 정책에 이 조건 키를 추가하면, 지정된 조직 ID와 일치하는 AWS 계정 사용자만 액세스할 수 있도록 제한할 수 있습니다.
      - **AWS 공식 문서**: [AWS Organizations 및 IAM 정책 조건 키](https://docs.aws.amazon.com/ko_kr/IAM/latest/UserGuide/reference_policies_condition-keys.html)에서 자세히 확인할 수 있습니다.
  - **aws:PrincipalOrgPaths**
      - **설명**: 이 조건 키는 주체가 속한 조직 내의 경로(조직 단위, OU)를 나타냅니다.
      - **비교**: 조직 내 특정 OU로 제한할 때 유용하지만, “조직 내 계정”이라는 요구 사항에는 단순히 조직 ID만 확인하는 aws:PrincipalOrgID가 더 간단하고 적합합니다.

---

### **A: 조직 ID에 대한 참조가 있는 aws:PrincipalOrgID 글로벌 조건 키를 S3 버킷 정책에 추가합니다.**

  - **작동 방식**:
      - S3 버킷 정책에 `"Condition": {"StringEquals": {"aws:PrincipalOrgID": "<조직ID>"}}`와 같이 조건을 추가하면, 요청하는 주체(계정)가 지정한 조직 ID에 속한 경우에만 S3 버킷에 액세스할 수 있게 됩니다.
  - **운영 오버헤드**:
      - 별도의 추가 관리 작업 없이, S3 버킷 정책 한 번의 설정으로 모든 조직 내 계정에 대해 일괄적으로 액세스를 제한할 수 있으므로 매우 간단합니다.
  - **결론**: 최소한의 운영 오버헤드로 조직 내 계정만 접근하도록 제한하는 요구 사항을 가장 효과적으로 충족합니다.

  ---

  ### **B: 각 부서에 대한 조직 단위(OU)를 만들고, S3 버킷 정책에 aws:PrincipalOrgPaths 글로벌 조건 키를 추가합니다.**

  - **작동 방식**:
      - 각 부서를 OU로 나눈 후, S3 버킷 정책에 OU 경로를 조건으로 추가하여 특정 OU에 속한 계정만 접근하도록 할 수 있습니다.
  - **문제점**:
      - 모든 계정이 반드시 특정 OU에 속하도록 조직 구조를 변경해야 하는 등 추가적인 관리 작업이 필요합니다.
      - 단순히 “조직 내 계정” 제한이라는 요구 사항에는 OU까지 고려할 필요가 없으므로 불필요한 복잡성이 증가합니다.
  - **결론**: 운영 오버헤드가 늘어나므로 적합하지 않습니다.

  ---

  ### **C: AWS CloudTrail을 사용하여 CreateAccount, InviteAccountToOrganization, LeaveOrganization 및 RemoveAccountFromOrganization 이벤트를 모니터링하고, 이에 따라 S3 버킷 정책을 업데이트합니다.**

  - **작동 방식**:
      - CloudTrail 이벤트를 모니터링하여 조직 내 계정의 변경사항(신규 생성, 초대, 탈퇴 등)을 감지한 후, 수동 또는 자동으로 S3 버킷 정책을 업데이트합니다.
  - **문제점**:
      - 이 방식은 지속적으로 이벤트를 모니터링하고 정책을 업데이트하는 추가적인 작업이 필요하여 운영 복잡성이 매우 높아집니다.
  - **결론**: 최소한의 운영 오버헤드를 요구하는 조건에 부합하지 않습니다.

  ---

  ### **D: S3 버킷에 액세스해야 하는 각 사용자를 태그하고, aws:PrincipalTag 글로벌 조건 키를 S3 버킷 정책에 추가합니다.**

  - **작동 방식**:
      - 각 사용자에게 특정 태그를 부여한 후, S3 버킷 정책에서 해당 태그가 있는 사용자만 접근할 수 있도록 제한합니다.
  - **문제점**:
      - 모든 사용자를 일일이 태그 관리해야 하며, 조직 변경 시 태그 업데이트 등의 추가 작업이 필요합니다.
  - **결론**: 운영 오버헤드가 증가하여 요구 사항에 부합하지 않습니다.

---

**정답은 A입니다.**

- **왜 A인가요?**
    - **간단함**: S3 버킷 정책에 aws:PrincipalOrgID 조건 키를 추가하는 한 번의 설정만으로, 해당 조직에 속한 모든 계정 사용자에 대해 접근을 허용할 수 있습니다.
    - **최소한의 운영 오버헤드**: 별도의 복잡한 관리나 태깅, CloudTrail 모니터링 없이 단순하게 조건을 추가하여 요구 사항을 충족할 수 있습니다.
    - **AWS Organizations와의 연동**: aws:PrincipalOrgID는 조직 내 계정임을 확인하는 데 사용되므로, 요구 사항인 “AWS Organizations의 조직 내 계정 사용자로만 제한”하는 조건에 가장 적합합니다.


---
## Q4

``````

애플리케이션은 VPC의 Amazon EC2 인스턴스에서 실행됩니다. 애플리케이션은 Amazon S3 버킷에 저장된 로그를 처리합니다. EC2 인스턴스는 인터넷에 연결하지 않고도 S3 버킷에 액세스해야 합니다.

어떤 솔루션이 Amazon S3에 프라이빗 네트워크 연결을 제공할까요?

A. S3 버킷에 대한 게이트웨이 VPC 엔드포인트를 생성합니다.

B. 로그를 Amazon CloudWatch Logs로 스트리밍합니다. 로그를 S3 버킷으로 내보냅니다.

C. S3 액세스를 허용하기 위해 Amazon EC2에 인스턴스 프로필을 생성합니다.

D. S3 엔드포인트에 액세스하기 위한 개인 링크가 있는 Amazon API Gateway API를 생성합니다.

``````


### 문제 상황 정리

- **애플리케이션 위치**: Amazon VPC 내의 Amazon EC2 인스턴스에서 실행됨
- **로그 위치**: 로그는 Amazon S3 버킷에 저장됨
- **요구 사항**:
    - EC2 인스턴스가 인터넷에 연결하지 않아도 S3 버킷에 접근할 수 있어야 함
    - S3에 프라이빗 네트워크 연결을 제공해야 함

---

### 관련 기술 설명

### 1. Amazon VPC 엔드포인트

- **기본 개념**:
    - Amazon VPC 엔드포인트는 VPC 내의 리소스(예: EC2 인스턴스)가 인터넷 게이트웨이, NAT 장치 또는 VPN 연결 없이도 AWS 서비스(예: Amazon S3, DynamoDB)에 안전하게 연결할 수 있도록 하는 기능입니다.
- **유형**:
    - **게이트웨이 VPC 엔드포인트**: Amazon S3와 Amazon DynamoDB에 연결할 때 사용하는 엔드포인트 유형입니다.
    - **인터페이스 VPC 엔드포인트**: AWS PrivateLink를 사용하여 다양한 AWS 서비스에 연결할 때 사용하는 엔드포인트 유형입니다.
  - **AWS 공식 문서**: [VPC 엔드포인트](https://docs.aws.amazon.com/ko_kr/vpc/latest/userguide/vpc-endpoints.html)

### 2. Amazon S3

- **기본 개념**:
    - Amazon S3는 데이터를 객체 단위로 저장하는 객체 스토리지 서비스입니다.
- **연결 방식**:
    - 기본적으로 S3는 인터넷을 통해 접근되지만, VPC 엔드포인트를 사용하면 프라이빗 네트워크 경로를 통해 직접 접근할 수 있습니다.

---

### **A: S3 버킷에 대한 게이트웨이 VPC 엔드포인트를 생성합니다.**

  - **작동 원리**:
      - 게이트웨이 VPC 엔드포인트를 사용하면 VPC 내의 EC2 인스턴스가 인터넷을 거치지 않고도 Amazon S3와 직접 통신할 수 있습니다.
      - VPC 엔드포인트를 한 번 설정하면, 해당 VPC의 모든 인스턴스가 프라이빗 네트워크를 통해 S3 버킷에 접근할 수 있으므로, 인터넷 연결 없이도 로그 처리 작업이 가능합니다.
  - **운영 오버헤드**:
      - 단순한 엔드포인트 생성만으로 해결되므로 추가적인 인프라나 복잡한 구성이 필요하지 않습니다.
  - **결론**: 요구 사항인 "인터넷 연결 없이 S3 버킷에 액세스"하는 문제를 가장 간단하게 해결하는 방법입니다.

  ---

  ### **B: 로그를 Amazon CloudWatch Logs로 스트리밍합니다. 로그를 S3 버킷으로 내보냅니다.**

  - **작동 원리**:
      - 이 방식은 로그 데이터를 CloudWatch Logs로 전송한 다음 다시 S3로 내보내는 방법입니다.
  - **문제점**:
      - 이 방법은 프라이빗 네트워크 연결을 제공하는 것이 아니라 로그의 저장 및 전송 경로를 변경하는 것이므로, EC2 인스턴스가 인터넷 없이 S3에 직접 접근하도록 만드는 해결책이 아닙니다.
  - **결론**: 요구 사항에 부합하지 않습니다.

  ---

  ### **C: S3 액세스를 허용하기 위해 Amazon EC2에 인스턴스 프로필을 생성합니다.**

  - **작동 원리**:
      - 인스턴스 프로필을 사용하면 EC2 인스턴스에 IAM 역할을 부여하여 S3 접근 권한을 부여할 수 있습니다.
  - **문제점**:
      - 이 옵션은 권한 부여(인증/인가)와 관련된 것으로, EC2 인스턴스가 인터넷 없이 S3에 프라이빗하게 연결되도록 만드는 네트워크 연결 방식은 제공하지 않습니다.
  - **결론**: 접근 권한은 해결할 수 있으나, 프라이빗 네트워크 연결 문제는 해결하지 못합니다.

  ---

  ### **D: S3 엔드포인트에 액세스하기 위한 개인 링크가 있는 Amazon API Gateway API를 생성합니다.**

  - **작동 원리**:
      - Amazon API Gateway를 사용하면 API를 프라이빗하게 노출할 수 있으나, S3에 직접 접근하는 표준 방법은 아닙니다.
  - **문제점**:
      - S3에 접근하기 위해 API Gateway를 사용하는 것은 불필요하게 복잡하며, AWS는 이미 S3 전용 VPC 엔드포인트(게이트웨이 엔드포인트)를 제공하고 있습니다.
  - **결론**: 불필요한 복잡성을 추가하므로 적합하지 않습니다.

---

**정답은 A입니다.**

- **프라이빗 네트워크 연결 제공**: 게이트웨이 VPC 엔드포인트를 사용하면 VPC 내의 EC2 인스턴스가 인터넷을 거치지 않고 Amazon S3에 안전하게 접근할 수 있습니다.
- **운영 오버헤드 최소화**: 단순하게 엔드포인트를 생성하는 한 번의 설정으로 요구 사항을 충족할 수 있습니다.
- **AWS 공식 방식**: AWS는 Amazon S3와 연결하기 위한 VPC 엔드포인트 사용을 권장합니다.


---
## Q5

```

한 회사가 사용자가 업로드한 문서를 Amazon EBS 볼륨에 저장하는 단일 Amazon EC2 인스턴스를 사용하여 AWS에서 웹 애플리케이션을 호스팅하고 있습니다. 더 나은 확장성과 가용성을 위해 회사는 아키텍처를 복제하고 다른 가용성 영역에 두 번째 EC2 인스턴스와 EBS 볼륨을 만들어 둘 다 애플리케이션 로드 밸런서 뒤에 배치했습니다. 이 변경을 완료한 후, 사용자들은 웹사이트를 새로 고칠 때마다 문서의 하위 집합 중 하나 또는 다른 하나를 볼 수 있지만 모든 문서를 동시에 볼 수는 없다고 보고했습니다.

솔루션 아키텍트는 사용자가 모든 문서를 한 번에 볼 수 있도록 하기 위해 무엇을 제안해야 할까요?

A. 두 EBS 볼륨 모두에 모든 문서가 포함되도록 데이터를 복사합니다.

B. 사용자를 문서가 있는 서버로 안내하도록 애플리케이션 로드 밸런서를 구성합니다.

C. 두 EBS 볼륨의 데이터를 Amazon EFS로 복사합니다. 애플리케이션을 수정하여 새 문서를 Amazon EFS에 저장합니다.

D. 두 서버 모두에 요청을 보내도록 애플리케이션 로드 밸런서를 구성합니다. 올바른 서버에서 각 문서를 반환합니다.

```


### 문제 상황 정리

- **기존 아키텍처**:
        - 단일 EC2 인스턴스와 연결된 Amazon EBS 볼륨에 사용자 업로드 문서를 저장하여 웹 애플리케이션을 호스팅하고 있었습니다.
- **변경 후 아키텍처**:
    - 더 나은 확장성과 가용성을 위해 두 개의 EC2 인스턴스(각각 다른 가용 영역에 배치)와 두 개의 EBS 볼륨을 애플리케이션 로드 밸런서 뒤에 배치하였습니다.
- **문제점**:
    - 각 EC2 인스턴스는 로컬 EBS 볼륨에 저장된 문서만 보관하고 있으므로, 사용자가 로드 밸런서를 통해 요청할 때마다 어느 인스턴스로 연결되느냐에 따라 문서의 일부만 보이는 현상이 발생합니다.
- **요구 사항**:
    - 사용자가 웹사이트를 새로 고칠 때 항상 **모든 문서**를 한 번에 볼 수 있어야 합니다.

---

  ### **A: 두 EBS 볼륨 모두에 모든 문서가 포함되도록 데이터를 복사합니다.**

  - **설명**:
      - 두 개의 EBS 볼륨 사이에 데이터를 수동 또는 자동화된 방식으로 복사하여 두 서버에 동일한 문서가 존재하도록 만드는 방법입니다.
  - **문제점**:
      - EBS는 개별 EC2 인스턴스에 연결되는 스토리지로, 기본적으로 여러 인스턴스 간에 데이터를 공유할 수 없습니다.
      - 데이터 복사 및 동기화를 위한 별도의 애플리케이션 로직이나 관리 작업이 필요하여 운영 오버헤드가 증가합니다.
      - 복제 시 발생할 수 있는 지연이나 오류로 인해 항상 최신 데이터가 반영되지 않을 위험이 있습니다.

  ### **B: 사용자를 문서가 있는 서버로 안내하도록 애플리케이션 로드 밸런서를 구성합니다.**

  - **설명**:
      - 로드 밸런서를 구성하여 사용자가 업로드한 문서가 있는 특정 서버로만 트래픽을 보내도록 하는 방법입니다.
  - **문제점**:
      - 사용자가 어느 서버에 연결될지 제어하는 것은 로드 밸런서의 기본 기능(트래픽 분산)과 맞지 않으며, 특정 서버에 부하가 집중될 위험이 있습니다.
      - 또한, 사용자가 항상 모든 문서를 보려면 서버별로 문서 저장 위치를 별도로 관리해야 하므로 아키텍처 복잡성이 증가합니다.

  ### **C: 두 EBS 볼륨의 데이터를 Amazon EFS로 복사합니다. 애플리케이션을 수정하여 새 문서를 Amazon EFS에 저장합니다.**

  - **Amazon EFS(Elastic File System)란?**
      - **기본 개념**: Amazon EFS는 AWS에서 제공하는 완전관리형 네트워크 파일 시스템으로, 여러 EC2 인스턴스가 동시에 접근할 수 있는 공유 파일 스토리지입니다.
      - **특징**:
          - 여러 가용 영역에 걸쳐 EC2 인스턴스들이 동일한 파일 시스템을 마운트하여 데이터를 읽고 쓸 수 있습니다.
          - 서버 간에 데이터를 별도로 복사할 필요 없이, 모든 인스턴스가 동일한 데이터를 공유하므로 동기화 문제가 발생하지 않습니다.
      - **AWS 공식 문서**: [Amazon EFS 사용자 가이드](https://docs.aws.amazon.com/ko_kr/efs/latest/ug/whatisefs.html)
  - **설명**:
      - 기존에 각 서버의 로컬 EBS 볼륨에 저장되던 문서를 하나의 공유 스토리지인 Amazon EFS로 옮깁니다.
      - 애플리케이션을 수정하여 새로 업로드되는 문서가 Amazon EFS에 저장되도록 하면, 모든 EC2 인스턴스가 동일한 문서 집합에 접근할 수 있습니다.
  - **장점**:
      - 데이터가 중앙에서 관리되므로 어느 인스턴스에 연결되더라도 사용자는 항상 최신의 모든 문서를 볼 수 있습니다.
      - 운영 오버헤드가 크게 줄어들고, 파일 동기화 문제도 해결됩니다.

  ### **D: 두 서버 모두에 요청을 보내도록 애플리케이션 로드 밸런서를 구성합니다. 올바른 서버에서 각 문서를 반환합니다.**

  - **설명**:
      - 로드 밸런서가 한 번의 요청을 두 개의 서버에 모두 전송하여, 두 서버의 데이터를 애플리케이션 레벨에서 합치는 방식입니다.
  - **문제점**:
      - 애플리케이션 로드 밸런서는 기본적으로 단일 인스턴스에 요청을 전달하도록 설계되어 있으며, 멀티캐스팅(여러 서버에 동시에 요청을 보내고 응답을 병합하는 기능)을 지원하지 않습니다.
      - 만약 이러한 기능을 애플리케이션에서 별도로 구현한다 하더라도, 데이터 병합 로직을 추가해야 하고, 서버 간 동기화 문제로 인해 복잡성이 매우 증가합니다.

---

  **정답은  C입니다.**
  - **공유 스토리지 제공**: Amazon EFS는 여러 EC2 인스턴스가 동시에 마운트할 수 있는 공유 파일 시스템이므로, 모든 문서를 중앙에서 관리할 수 있습니다.
  - **동기화 문제 해결**: 기존에 각 인스턴스마다 개별 EBS 볼륨에 저장되어 있던 데이터를 EFS로 옮기면, 어느 인스턴스에 요청이 전달되더라도 동일한 데이터(모든 문서)를 제공할 수 있습니다.
  - **운영 오버헤드 최소화**: 별도의 데이터 복제나 동기화 로직 없이, 애플리케이션 수정만으로 중앙의 공유 스토리지에 문서를 저장할 수 있으므로 운영 관리가 간편해집니다.

---

## Q6

``````

회사가 NFS를 사용하여 온프레미스 네트워크 연결 스토리지에 대용량 비디오 파일을 저장합니다. 각 비디오 파일의 크기는 1MB에서 500GB까지입니다. 총 스토리지는 70TB이며 더 이상 증가하지 않습니다. 회사는 비디오 파일을 Amazon S3로 마이그레이션하기로 결정했습니다. 회사는 가능한 한 빨리 비디오 파일을 마이그레이션해야 하며 가능한 한 최소한의 네트워크 대역폭을 사용해야 합니다.
어떤 솔루션이 이러한 요구 사항을 충족할까요?

A. S3 버킷을 만듭니다. S3 버킷에 쓸 수 있는 권한이 있는 IAM 역할을 만듭니다. AWS CLI를 사용하여 모든 파일을 로컬로 S3 버킷에 복사합니다.

B. AWS Snowball Edge 작업을 만듭니다. 온프레미스에서 Snowball Edge 장치를 받습니다. Snowball Edge 클라이언트를 사용하여 데이터를 장치로 전송합니다. AWS가 Amazon S3로 데이터를 가져올 수 있도록 장치를 반환합니다.

C. 온프레미스에 S3 파일 게이트웨이를 배포합니다. S3 파일 게이트웨이에 연결할 퍼블릭 서비스 엔드포인트를 만듭니다. S3 버킷을 만듭니다. S3 파일 게이트웨이에 새 NFS 파일 공유를 만듭니다. 새 파일 공유를 S3 버킷으로 지정합니다. 기존 NFS 파일 공유에서 S3 파일 게이트웨이로 데이터를 전송합니다.

D. 온프레미스 네트워크와 AWS 간에 AWS Direct Connect 연결을 설정합니다. 온프레미스에 S3 파일 게이트웨이를 배포합니다. S3 파일 게이트웨이에 연결할 퍼블릭 가상 인터페이스(VIF)를 만듭니다. S3 버킷을 만듭니다. S3 파일 게이트웨이에 새 NFS 파일 공유를 만듭니다. 새 파일 공유를 S3 버킷으로 지정합니다. 기존 NFS 파일 공유에서 S3 파일 게이트웨이로 데이터를 전송합니다.

``````

### 문제 상황 정리

- **현재 상황**:
   - 온프레미스에서는 NFS를 사용하여 대용량 비디오 파일(크기: 1MB ~ 500GB, 총 70TB)을 저장하고 있습니다.
- **요구 사항**:
    - 이 비디오 파일들을 Amazon S3로 마이그레이션해야 합니다.
    - 마이그레이션은 가능한 한 빠르게 진행되어야 하며, 온프레미스 네트워크 대역폭 사용은 최소화해야 합니다.

---

### 관련 기술 설명

### 1. AWS Snowball Edge

  - **기본 개념**:
      - AWS Snowball Edge는 대용량 데이터를 네트워크 대신 물리적인 장치를 통해 AWS로 안전하게 이전할 수 있도록 지원하는 데이터 전송 서비스입니다.
  - **특징**:
      - **네트워크 대역폭 절감**: 온프레미스에서 데이터를 Snowball Edge 장치로 로컬 복사한 후, 장치를 AWS로 배송하여 데이터를 S3로 업로드하므로, 인터넷 대역폭 사용이 거의 없습니다.
      - **대용량 데이터 전송 최적화**: 수십 테라바이트(TB) 이상의 데이터를 한 번에 전송하는 데 적합합니다.
  - **참고**: [AWS Snowball Edge 사용자 가이드](https://docs.aws.amazon.com/ko_kr/snowball/latest/ug/whatissnowball.html)

### 2. S3 파일 게이트웨이

  - **기본 개념**:
      - S3 파일 게이트웨이는 온프레미스 애플리케이션이 Amazon S3를 파일 시스템처럼 사용할 수 있도록 하는 AWS Storage Gateway의 한 형태입니다.
  - **특징**:
      - 온프레미스에서 S3와의 하이브리드 환경 구성을 위해 사용되며, 지속적으로 S3에 데이터를 동기화할 때 유용합니다.
      - **네트워크 의존성**: 데이터를 S3로 전송할 때 인터넷이나 Direct Connect 등의 네트워크 연결이 필요합니다.
  - **참고**: [AWS Storage Gateway – S3 파일 게이트웨이](https://docs.aws.amazon.com/ko_kr/storagegateway/latest/userguide/StorageGatewayConcepts.html)

---

  ### **A: AWS CLI를 사용하여 온프레미스에서 S3 버킷으로 파일 복사**

  - **설명**:
      - AWS CLI를 사용해 모든 파일을 직접 S3 버킷으로 복사하는 방법입니다.
  - **문제점**:
      - 70TB의 데이터를 인터넷을 통해 전송하게 되면 네트워크 대역폭을 크게 소모하며, 전송 시간이 매우 오래 걸릴 수 있습니다.
  - **결론**: 네트워크 대역폭 사용 최소화라는 요구 사항에 부합하지 않습니다.

  ---

  ### **B: AWS Snowball Edge 작업을 생성하여 데이터 전송**

  - **설명**:
      - 온프레미스에서 Snowball Edge 장치를 받아 로컬에서 데이터를 장치에 복사한 후, 장치를 AWS에 반송하여 AWS가 장치 내 데이터를 S3로 업로드하는 방식입니다.
  - **장점**:
      - **네트워크 대역폭 최소화**: 대용량 데이터를 물리적으로 이동하기 때문에 인터넷을 통한 데이터 전송 부담이 거의 없습니다.
      - **빠른 마이그레이션**: 물리적 장치를 사용하여 한 번에 많은 데이터를 옮길 수 있습니다.
  - **결론**: 마이그레이션 속도를 높이면서 네트워크 대역폭 사용을 최소화할 수 있는 가장 적합한 방법입니다.

  ---

  ### **C: 온프레미스에 S3 파일 게이트웨이 배포 후, NFS 파일 공유로 데이터 전송**

  - **설명**:
      - 온프레미스에 S3 파일 게이트웨이를 배포하고, 기존 NFS 파일 공유 데이터를 S3 파일 게이트웨이를 통해 S3 버킷으로 전송하는 방식입니다.
  - **문제점**:
      - 이 방식은 네트워크를 통해 데이터를 전송하기 때문에 70TB의 데이터를 옮길 때 많은 네트워크 대역폭을 사용하게 됩니다.
      - 마이그레이션 속도 역시 네트워크 속도에 영향을 받으므로 요구 사항(빠른 마이그레이션, 최소 네트워크 대역폭 사용)에 부합하지 않습니다.

  ---

  ### **D: AWS Direct Connect를 설정하고 S3 파일 게이트웨이를 배포하여 데이터 전송**

  - **설명**:
      - AWS Direct Connect를 사용해 온프레미스와 AWS 간 전용 네트워크 연결을 구축한 후, S3 파일 게이트웨이를 통해 데이터를 S3로 전송하는 방식입니다.
  - **문제점**:
      - Direct Connect는 전용 회선을 통해 보다 안정적이고 빠른 연결을 제공하지만, 여전히 데이터 전송은 네트워크를 통해 이루어집니다.
      - 70TB의 데이터를 전송하는 경우, 네트워크 대역폭 사용량은 많이 발생할 수 있으므로 요구 사항에 부합하지 않습니다.
  - **결론**: 전용 회선이라 하더라도 네트워크 전송 방식이기 때문에 옵션 B보다 네트워크 부담이 큽니다.

---

**정답은 B입니다.**
- **최소 네트워크 대역폭 사용**: AWS Snowball Edge는 온프레미스에서 데이터를 물리적으로 복사한 후, 장치를 AWS로 반송하여 S3에 데이터를 업로드하므로, 인터넷 네트워크 사용을 거의 하지 않습니다.
- **대용량 데이터 전송에 최적화**: 70TB와 같이 큰 데이터 세트를 빠르고 효율적으로 마이그레이션할 수 있습니다.
- **AWS 공식 권장**: AWS는 대용량 데이터 전송 시 Snowball Edge를 사용하는 방법을 적극 권장합니다.

---

## Q7

````

회사에 수신 메시지를 수집하는 애플리케이션이 있습니다. 수십 개의 다른 애플리케이션과 마이크로서비스가 이러한 메시지를 빠르게 소비합니다. 메시지 수는 크게 달라지며 때로는 초당 100,000개로 갑자기 증가합니다. 이 회사는 솔루션을 분리하고 확장성을 높이고자 합니다.
어떤 솔루션이 이러한 요구 사항을 충족합니까?

A. Amazon Kinesis Data Analytics에 메시지를 유지합니다. 소비자 애플리케이션을 구성하여 메시지를 읽고 처리합니다.

B. CPU 메트릭에 따라 EC2 인스턴스 수를 확장하기 위해 Auto Scaling 그룹의 Amazon EC2 인스턴스에 수집 애플리케이션을 배포합니다.

C. 단일 샤드로 Amazon Kinesis Data Streams에 메시지를 씁니다. AWS Lambda 함수를 사용하여 메시지를 사전 처리하고 Amazon DynamoDB에 저장합니다. 소비자 애플리케이션을 구성하여 DynamoDB에서 읽어 메시지를 처리합니다.

D. 여러 Amazon Simple Queue Service(Amazon SOS) 구독이 있는 Amazon Simple Notification Service(Amazon SNS) 주제에 메시지를 게시합니다. 소비자 애플리케이션을 구성하여 대기열에서 메시지를 처리합니다.

````


### 문제 상황 정리

- **현재 상황**:
   - 한 애플리케이션이 수신 메시지를 수집하고 있습니다.
   - 수십 개의 다른 애플리케이션과 마이크로서비스가 이 메시지를 빠르게 소비합니다.
   - 메시지 수는 크게 변동하며, 때로는 초당 100,000개로 급증합니다.
- **요구 사항**:
    - 솔루션을 분리(디커플링)하여 각 구성 요소가 독립적으로 확장 및 관리될 수 있도록 하고,
    - 변화하는 메시지 부하에도 탄력적으로 대처할 수 있는 확장성을 제공해야 합니다.

---

### 관련 기술 및 개념

### 1. Amazon SNS 

  - **기본 개념**:
      - SNS는 발행/구독(pub/sub) 메시징 서비스로, 발행자가 보낸 메시지를 여러 구독자(예: SQS, Lambda, HTTP/S 엔드포인트 등)로 동시에 전송할 수 있습니다.
  - **주요 특징**:
      - 높은 처리량과 확장성으로 초당 수십만 건의 메시지도 처리할 수 있습니다.
      - 구독자에게 메시지를 푸시 방식으로 전달하여 여러 소비자가 독립적으로 메시지를 받아 처리할 수 있습니다.

### 2. Amazon SQS 

  - **기본 개념**:
      - SQS는 메시지 큐잉 서비스로, 메시지를 일시적으로 저장하여 생산자와 소비자 사이의 디커플링(분리)를 지원합니다.
  - **주요 특징**:
      - 메시지가 큐에 저장되어 각 소비자가 독립적으로 메시지를 폴링하여 처리할 수 있습니다.
      - 확장성이 뛰어나며, 메시지 중복 또는 손실 없이 안정적으로 처리할 수 있습니다.
  - **SNS와 SQS의 조합**:
      - 발행자는 SNS 주제에 메시지를 게시하면, 여러 SQS 큐가 해당 주제에 구독되어 각기 메시지를 전달받습니다.
      - 이 구조는 메시지의 빠른 소비와 높은 확장성을 제공하며, 여러 소비자가 독립적으로 데이터를 처리할 수 있도록 합니다.

---

  ### **A: Amazon Kinesis Data Analytics에 메시지를 유지하고 소비자 애플리케이션이 읽도록 구성**

  - **분석**:
      - **Kinesis Data Analytics**는 스트림 데이터의 실시간 분석을 위한 서비스입니다.
      - 메시지 소비에 초점을 두기보다는 데이터를 처리하고 분석하는 용도로 주로 사용됩니다.
      - 또한, 이 서비스는 발행/구독(분리) 아키텍처를 구현하기 위한 핵심 구성 요소로 적합하지 않습니다.
  - **결론**:
      - 요구하는 디커플링 및 높은 확장성, 다수의 소비자가 메시지를 독립적으로 처리하는 패턴에는 부적합합니다.

  ### **B: Auto Scaling 그룹에 배포된 EC2 인스턴스를 사용하여 CPU 메트릭에 따라 확장**

  - **분석**:
      - 이 방식은 수집 애플리케이션 자체의 처리량을 확장하는 방법입니다.
      - 하지만, 여러 애플리케이션이 메시지를 소비해야 하는 구조에서 데이터의 분리(디커플링) 및 팬아웃 패턴을 제공하지 않습니다.
      - 또한, 단순히 EC2 인스턴스의 수를 늘린다고 하더라도 소비자 간에 메시지를 공유하거나 동일한 메시지를 전달하는 구조가 마련되지 않습니다.
  - **결론**:
      - 확장성은 향상될 수 있으나, 메시지의 디커플링 및 팬아웃(여러 소비자에게 동일한 메시지 전달) 요구 사항을 충족하지 못합니다.

  ### **C: 단일 샤드의 Amazon Kinesis Data Streams에 메시지를 기록 후, Lambda를 사용해 전처리 및 DynamoDB에 저장, 소비자가 DynamoDB에서 읽도록 구성**

  - **분석**:
      - **Kinesis Data Streams**는 스트림 데이터를 저장하고 소비자들이 순차적으로 처리할 수 있도록 하는 서비스입니다.
      - 단일 샤드는 초당 메시지 처리 한계(일반적으로 1MB/초, 약 1000건/초 정도)가 있으므로 초당 100,000건의 메시지를 처리하기엔 부적절합니다.
      - Lambda를 사용한 전처리와 DynamoDB 저장은 복잡도를 증가시키며, 데이터 저장소(DynamoDB)는 스트림 처리 및 팬아웃 패턴을 구현하는 용도로 최적화되어 있지 않습니다.
  - **결론**:
      - 확장성 및 처리량 측면에서 한계가 있으며, 메시지를 팬아웃하는 요구 사항에도 적합하지 않습니다.

  ### **D: 여러 Amazon SQS 구독이 있는 Amazon SNS 주제에 메시지를 게시하고, 소비자 애플리케이션이 각자 SQS 대기열에서 메시지를 처리**

  - **분석**:
      - SNS는 발행자가 메시지를 주제에 게시하면, 다수의 구독자(여기서는 SQS 대기열)로 메시지를 동시에 전송하는 팬아웃 아키텍처를 지원합니다.
      - 각 소비자 애플리케이션은 자신에게 할당된 SQS 대기열에서 메시지를 독립적으로 처리할 수 있으므로, 소비자 간의 분리(디커플링)와 확장성을 모두 제공합니다.
      - SNS와 SQS 모두 높은 처리량을 지원하며, 초당 100,000건과 같은 대량의 메시지도 안정적으로 처리할 수 있습니다.
  - **결론**:
      - 요구 사항인 메시지 팬아웃(여러 소비자에게 동일 메시지 전송), 디커플링, 그리고 높은 확장성을 만족하는 이상적인 솔루션입니다.

---

**정답은 D입니다.**

- **디커플링 및 팬아웃**: SNS 주제에 메시지를 게시하면, 다수의 SQS 대기열(구독자)이 각자 메시지를 받아 처리할 수 있어, 발행자와 소비자가 완전히 분리됩니다.
- **확장성**: SNS와 SQS는 모두 높은 처리량과 확장성을 제공하므로, 초당 100,000건의 메시지 급증 상황에서도 안정적인 처리가 가능합니다.
**운영의 단순함**: 별도의 복잡한 인프라 변경 없이, SNS와 SQS를 이용한 기본 패턴으로 요구 사항을 충족할 수 있습니다.

---

## Q8

``````

회사가 분산 애플리케이션을 AWS로 마이그레이션하고 있습니다. 이 애플리케이션은 가변적인 워크로드를 처리합니다. 레거시 플랫폼은 여러 컴퓨팅 노드에서 작업을 조정하는 기본 서버로 구성되어 있습니다. 이 회사는 복원성과 확장성을 극대화하는 솔루션으로 애플리케이션을 현대화하려고 합니다.
솔루션 아키텍트는 이러한 요구 사항을 충족하기 위해 어떻게 아키텍처를 설계해야 할까요?

A. Amazon Simple Queue Service(Amazon SQS) 대기열을 작업의 대상으로 구성합니다. Auto Scaling 그룹에서 관리되는 Amazon EC2 인스턴스로 컴퓨팅 노드를 구현합니다. 예약된 스케일링을 사용하도록 EC2 Auto Scaling을 구성합니다.

B. Amazon Simple Queue Service(Amazon SQS) 대기열을 작업의 대상으로 구성합니다. Auto Scaling 그룹에서 관리되는 Amazon EC2 인스턴스로 컴퓨팅 노드를 구현합니다. 대기열의 크기에 따라 EC2 Auto Scaling을 구성합니다.

C. Auto Scaling 그룹에서 관리되는 Amazon EC2 인스턴스로 기본 서버와 컴퓨팅 노드를 구현합니다. 작업의 대상으로 AWS CloudTrail을 구성합니다. 기본 서버의 부하에 따라 EC2 Auto Scaling을 구성합니다.

D. Auto Scaling 그룹에서 관리되는 Amazon EC2 인스턴스로 기본 서버와 컴퓨트 노드를 구현합니다. 작업의 대상으로 Amazon EventBridge(Amazon CloudWatch Events)를 구성합니다. 컴퓨트 노드의 부하에 따라 EC2 Auto Scaling을 구성합니다.

``````

### 문제 상황 정리

  회사는 가변적인 워크로드를 처리하는 분산 애플리케이션을 AWS로 마이그레이션하고 있습니다.

  레거시 애플리케이션은 여러 컴퓨팅 노드에서 작업을 조정하는 기본 서버(코디네이터)를 사용했습니다.

  회사는 **복원성과 확장성**을 극대화하기 위해 아키텍처를 현대화하고, 컴퓨팅 노드의 작업 조정을 디커플링(분리)하여 독립적으로 확장할 수 있는 솔루션을 원합니다.
    
---

### 관련 기술 및 개념

1. **Amazon Simple Queue Service (Amazon SQS)**
        - **역할**: 메시지나 작업을 큐에 넣어 생산자와 소비자 사이를 디커플링(분리)합니다.
        - **장점**: 대량의 작업이나 메시지를 안정적으로 저장하며, 소비자(여기서는 컴퓨팅 노드)가 큐에 쌓인 작업을 읽어 처리함으로써 확장성과 복원성이 크게 향상됩니다.
2. **EC2 Auto Scaling**
    - **역할**: EC2 인스턴스의 수를 자동으로 조정하여, 부하 변화에 따라 애플리케이션의 처리 용량을 동적으로 확장하거나 축소합니다.
    - **스케일링 기준**: 일반적으로 CPU 사용률, 네트워크 트래픽 또는 큐 길이(예: SQS 메시지 수)와 같은 지표에 기반하여 스케일 아웃(확장) 또는 스케일 인(축소)할 수 있습니다.

---

### **A**

- **구성**:
    - Amazon SQS 대기열을 작업 대상(큐)으로 사용
    - Auto Scaling 그룹에 EC2 인스턴스를 배포하여 컴퓨팅 노드를 구현
    - **예약된 스케일링**을 사용하여 EC2 Auto Scaling 구성
- **문제점**:
    - **예약된 스케일링**은 미리 정의된 시간에 따라 확장/축소되므로, 가변적이고 예측할 수 없는 워크로드(예: 초당 100,000건 급증)에 즉각적으로 대응하기 어렵습니다.
    - 동적 부하에 따른 자동 확장이 아닌 일정 시간에 따른 확장이므로 복원성과 효율성이 떨어집니다.

### **B**

- **구성**:
    - Amazon SQS 대기열을 작업 대상(큐)으로 사용
    - Auto Scaling 그룹에 EC2 인스턴스를 배포하여 컴퓨팅 노드를 구현
    - **대기열의 크기에 따라(큐 길이 기반)** EC2 Auto Scaling을 구성
- **장점**:
    - SQS를 사용하여 작업을 큐에 넣어 디커플링하면, 기본 서버 없이도 여러 컴퓨팅 노드가 독립적으로 작업을 소비할 수 있습니다.
    - **큐 길이를 기준으로 스케일링**하면, 메시지나 작업의 급증에 따라 자동으로 인스턴스 수가 늘어나므로 가변적인 워크로드에도 즉각적으로 대응할 수 있습니다.
    - 이러한 방식은 복원성과 확장성을 극대화하는 현대적인 아키텍처 패턴(마이크로서비스, 서버리스, 이벤트 드리븐 아키텍처 등)에 부합합니다.

### **C**

- **구성**:
    - Auto Scaling 그룹에 EC2 인스턴스를 배포하여 기본 서버와 컴퓨팅 노드를 모두 구현
    - 작업의 대상으로 **AWS CloudTrail**을 구성
    - 기본 서버의 부하에 따라 EC2 Auto Scaling 구성
- **문제점**:
    - **AWS CloudTrail**은 AWS API 호출 기록을 위한 서비스로, 작업 조정이나 분산 처리를 위한 메시지 큐 역할과는 관련이 없습니다.
    - 기본 서버와 컴퓨팅 노드를 함께 운영하면 디커플링이 어려워져 복원성과 확장성이 낮아집니다.

### **D**

  - **구성**:
      - Auto Scaling 그룹에 EC2 인스턴스를 배포하여 기본 서버와 컴퓨팅 노드를 모두 구현
      - 작업의 대상으로 **Amazon EventBridge (CloudWatch Events)**를 구성
      - 컴퓨팅 노드의 부하에 따라 EC2 Auto Scaling 구성
  - **문제점**:
      - Amazon EventBridge(이전의 CloudWatch Events)는 이벤트 기반 작업 조정을 지원하지만, 여기서는 기본 서버와 컴퓨팅 노드를 함께 운영하므로 디커플링되지 않습니다.
      - 기본 서버가 여전히 존재하면, 단일 실패점(single point of failure) 및 확장성 제약이 남게 됩니다.

---

**B**는 다음과 같은 이유로 가장 적합합니다.

- **디커플링**: 작업(메시지)을 Amazon SQS 대기열에 저장함으로써, 기본 서버 없이도 각 컴퓨팅 노드가 독립적으로 작업을 가져와 처리할 수 있습니다.
- **동적 확장성**: 대기열의 길이를 기준으로 EC2 Auto Scaling을 구성하면, 작업량이 급증할 때 자동으로 인스턴스 수를 늘려 가변적인 부하에 효과적으로 대응할 수 있습니다.
- **복원성 및 확장성 극대화**: 작업 큐 기반 아키텍처는 단일 실패점을 제거하고, 다양한 컴퓨팅 노드가 병렬로 작업을 처리할 수 있어 시스템의 복원성과 확장성이 크게 향상됩니다.

---
## Q9

``````
회사가 데이터 센터에서 SMB 파일 서버를 운영하고 있습니다. 파일 서버는 파일이 생성된 후 처음 며칠 동안 자주 액세스되는 대용량 파일을 저장합니다. 7일 후에는 파일에 거의 액세스하지 않습니다.

총 데이터 크기가 증가하고 있으며 회사의 총 스토리지 용량에 가깝습니다. 솔루션 아키텍트는 가장 최근에 액세스한 파일에 대한 저지연 액세스를 잃지 않으면서 회사의 사용 가능한 스토리지 공간을 늘려야 합니다. 솔루션 아키텍트는 또한 향후 스토리지 문제를 방지하기 위해 파일 수명 주기 관리를 제공해야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족할까요?

A. AWS DataSync를 사용하여 7일이 지난 데이터를 SMB 파일 서버에서 AWS로 복사합니다.

B. 회사의 스토리지 공간을 확장하기 위해 Amazon S3 파일 게이트웨이를 만듭니다. 7일 후 S3 Glacier Deep Archive로 데이터를 전환하기 위한 S3 라이프사이클 정책을 만듭니다.

C. 회사의 저장 공간을 확장하기 위해 Amazon FSx for Windows File Server 파일 시스템을 만듭니다.

D. 각 사용자의 컴퓨터에 Amazon S3에 액세스하기 위한 유틸리티를 설치합니다. 7일 후 S3 Glacier Flexible Retrieval로 데이터를 전환하기 위한 S3 Lifecycle 정책을 만듭니다.

``````

### 문제 상황 정리

- **현재 환경**:
        - 온프레미스의 SMB 파일 서버에 대용량 파일(최초 며칠간 자주 액세스, 7일 후 거의 액세스하지 않음)을 저장하고 있음
        - 총 저장 데이터가 증가하여 스토리지 용량 한계에 도달함
- **요구 사항**:
    1. **저지연 액세스**: 최근에 액세스한 파일은 빠르게 접근 가능해야 함
    2. **스토리지 공간 확장**: 온프레미스 스토리지 한계를 해소해야 함
    3. **파일 수명 주기 관리**: 파일의 액세스 패턴(7일 이후 거의 액세스되지 않음)을 고려하여 비용 효율적인 스토리지로 자동 전환 필요

---

  ### 관련 기술 및 개념

  ### 1. Amazon S3 파일 게이트웨이

  - **개념**:
      - AWS Storage Gateway의 한 유형으로, 온프레미스에서 SMB(또는 NFS) 파일 인터페이스를 제공하면서 실제 데이터는 Amazon S3에 저장합니다.
  - **특징**:
      - **로컬 캐시**: 최근에 액세스한 파일은 온프레미스 캐시에 보관되어 저지연 액세스를 제공합니다.
      - **클라우드 저장소 확장**: 온프레미스 스토리지 용량을 확장할 수 있으며, S3의 무제한 확장성을 활용할 수 있습니다.
      - **수명 주기 관리**: Amazon S3의 수명 주기 정책을 사용해 오래된 데이터를 더 저렴한 스토리지(예: S3 Glacier Deep Archive)로 전환할 수 있습니다.

  ### 2. S3 라이프사이클 정책

  - **개념**:
      - S3에 저장된 객체를 일정 기간 후에 자동으로 다른 스토리지 클래스로 전환하거나 삭제할 수 있도록 설정하는 기능입니다.
  - **적용**:
      - 예를 들어, 파일이 생성된 후 7일이 지나면 S3 Glacier Deep Archive로 전환하여 스토리지 비용을 절감할 수 있습니다.

---


  ###  A

  - **내용**: AWS DataSync를 사용하여 7일이 지난 데이터를 온프레미스 SMB 파일 서버에서 AWS로 복사
  - **문제점**:
      - DataSync는 데이터를 단순히 복사하는 도구로, 최신 파일의 로컬 저지연 액세스를 보장하지 않습니다.
      - 온프레미스에서 AWS로 단순 복사 후에도 온프레미스 사용자가 파일에 접근할 때 저지연성을 보장하기 어렵습니다.

  ###  B

  - **내용**:
      - Amazon S3 파일 게이트웨이를 배포하여 온프레미스 저장 공간을 확장
      - S3 라이프사이클 정책을 사용해 파일이 7일 후에 S3 Glacier Deep Archive로 전환되도록 구성
  - **장점**:
      - **저지연 액세스**: 최근에 액세스한 파일은 로컬 캐시에 보관되어 저지연으로 제공됨
      - **스토리지 확장**: 데이터는 Amazon S3에 저장되므로 온프레미스 스토리지 한계를 극복
      - **수명 주기 관리**: S3 라이프사이클 정책을 통해 7일 이후에는 비용 효율적인 Glacier Deep Archive로 자동 전환됨
  - **결론**: 요구 사항을 모두 충족하는 최적의 솔루션입니다.

  ###  C

  - **내용**: Amazon FSx for Windows File Server 파일 시스템을 구축하여 저장 공간 확장
  - **문제점**:
      - FSx는 관리형 파일 서버를 제공하지만, 파일 수명 주기 관리(예: 오래된 파일을 자동으로 저렴한 스토리지로 전환하는 기능)는 기본적으로 제공하지 않습니다.
      - 최신 파일에 대한 저지연 액세스는 제공할 수 있으나, 스토리지 용량 관리와 자동 아카이브 기능은 부족합니다.

  ###  D

  - **내용**: 각 사용자 컴퓨터에 S3 접근 유틸리티를 설치하고, S3 라이프사이클 정책으로 7일 후 데이터를 S3 Glacier Flexible Retrieval로 전환
  - **문제점**:
      - 사용자별 유틸리티 설치는 관리 오버헤드가 크고, 파일 시스템 인터페이스를 제공하지 않아 기존의 SMB 파일 공유와 일관성이 떨어집니다.
      - 저지연 액세스가 필요한 최신 파일의 경우, 로컬 캐시를 제공하는 방식에 비해 만족도가 낮을 수 있습니다.

---
**B**가 가장 적합합니다.

  - Amazon S3 파일 게이트웨이를 도입하면, 온프레미스에서 SMB 인터페이스를 유지하면서 백엔드로 S3를 활용하여 스토리지 용량을 무한대로 확장할 수 있습니다.
  - 최근에 자주 액세스하는 파일은 로컬 캐시에 저장되어 빠르게 접근할 수 있으며, 7일 이후에는 S3 라이프사이클 정책에 따라 S3 Glacier Deep Archive로 전환되어 비용 절감 및 저장 공간 최적화가 가능합니다.

---
## Q10

``````

회사가 AWS에서 전자상거래 웹 애플리케이션을 구축하고 있습니다. 이 애플리케이션은 새로운 주문에 대한 정보를 Amazon API Gateway REST API로 보내 처리합니다. 이 회사는 주문이 수신된 순서대로 처리되도록 하려고 합니다.
어떤 솔루션이 이러한 요구 사항을 충족할까요?

A. API Gateway 통합을 사용하여 애플리케이션이 주문을 받으면 Amazon Simple Notification Service(Amazon SNS) 토픽에 메시지를 게시합니다. 처리를 수행하기 위해 AWS Lambda 함수를 토픽에 구독합니다.

B. API Gateway 통합을 사용하여 애플리케이션이 주문을 받으면 Amazon Simple Queue Service(Amazon SQS) FIFO 대기열에 메시지를 보냅니다. 처리를 위해 AWS Lambda 함수를 호출하도록 SQS FIFO 대기열을 구성합니다.

C. API Gateway 권한 부여자를 사용하여 애플리케이션이 주문을 처리하는 동안 모든 요청을 차단합니다.

D. API Gateway 통합을 사용하여 애플리케이션이 주문을 받을 때 Amazon Simple Queue Service(Amazon SQS) 표준 대기열에 메시지를 보냅니다. 처리를 위해 AWS Lambda 함수를 호출하도록 SQS 표준 대기열을 구성합니다.

``````


### 문제 상황 정리

- **환경**: 전자상거래 웹 애플리케이션이 AWS에서 운영되며, 새로운 주문 정보가 Amazon API Gateway REST API를 통해 전달됩니다.
- **요구 사항**: 주문이 **수신된 순서대로** 처리되어야 합니다.

---

### 관련 서비스 및 개념 설명

  ### 1. Amazon API Gateway

  - **기능**: REST API를 생성하고 관리하는 서비스입니다. 애플리케이션은 API Gateway를 통해 주문 정보를 전송할 수 있습니다.
  - **역할**: API Gateway는 주문 메시지를 수신하여 백엔드로 전달하는 역할을 합니다.

  ### 2. Amazon Simple Queue Service (Amazon SQS)

  - **SQS FIFO 대기열**:
      - **특징**: FIFO(First-In-First-Out) 대기열은 메시지가 수신된 순서대로 처리되도록 보장합니다.
      - **정확한 순서 보장**: 주문과 같은 순서가 중요한 작업에 적합합니다.
      - **중복 제거**: 한 번만 처리되도록 중복 메시지를 제거할 수 있습니다.
      - **참고**: [Amazon SQS FIFO 대기열](https://docs.aws.amazon.com/ko_kr/AWSSimpleQueueService/latest/SQSDeveloperGuide/FIFO-queues.html)
  - **SQS 표준 대기열**:
      - **특징**: 높은 처리량과 확장성을 제공하지만, 메시지 순서가 보장되지 않고 중복 메시지가 발생할 수 있습니다.
      - **적합성**: 주문의 순서가 중요한 경우에는 적합하지 않습니다.

  ### 3. AWS Lambda

  - **기능**: 이벤트 기반 서버리스 컴퓨팅 서비스로, SQS 대기열의 메시지를 자동으로 트리거하여 처리할 수 있습니다.
  - **연동**: SQS FIFO 대기열과 연동하여, 순서대로 들어온 메시지를 Lambda 함수가 처리하도록 구성할 수 있습니다.

---

  ### **A**

  - **내용**:
      - API Gateway 통합을 사용하여 애플리케이션이 주문을 받으면 Amazon SNS 토픽에 메시지를 게시하고, AWS Lambda 함수가 해당 토픽에 구독되어 메시지를 처리함.
  - **문제점**:
      - **SNS의 메시지 순서**: Amazon SNS는 메시지를 발행/구독(pub/sub) 패턴으로 전달하지만, 메시지 순서가 보장되지 않습니다.
      - **결과**: 주문이 수신된 순서대로 처리된다는 요구 사항을 충족하지 못합니다.

  ### **B**

  - **내용**:
      - API Gateway 통합을 사용하여 애플리케이션이 주문을 받으면 Amazon SQS **FIFO 대기열**에 메시지를 보냅니다.
      - 처리를 위해 AWS Lambda 함수가 SQS FIFO 대기열과 연동되어 주문 메시지를 순서대로 처리합니다.
  - **장점**:
      - **순서 보장**: FIFO 대기열을 사용하면 메시지가 수신된 순서대로 처리가 보장됩니다.
      - **확장성 및 신뢰성**: SQS FIFO는 주문과 같이 순서가 중요한 메시지에 적합하며, 중복 제거 기능도 제공합니다.
  - **결과**: 주문이 수신된 순서대로 처리되는 요구 사항을 만족합니다.

  ### **C**

  - **내용**:
      - API Gateway 권한 부여자를 사용하여 애플리케이션이 주문을 처리하는 동안 모든 요청을 차단함.
  - **문제점**:
      - 요청을 차단하는 것은 메시지 처리를 위한 솔루션이 아니라, 단순히 접근을 제어하는 기능입니다.
      - **결과**: 주문 처리와 순서 보장을 위한 요구 사항을 전혀 충족하지 않습니다.

  ### **D**

  - **내용**:
      - API Gateway 통합을 사용하여 애플리케이션이 주문을 받으면 Amazon SQS **표준 대기열**에 메시지를 보내고, AWS Lambda 함수가 이를 처리하도록 구성.
  - **문제점**:
      - **표준 대기열의 순서 보장 문제**: SQS 표준 대기열은 메시지 순서가 보장되지 않기 때문에, 주문이 수신된 순서대로 처리된다는 요구 사항을 만족시키지 못합니다.

---

**B**가 요구 사항(주문이 수신된 순서대로 처리되도록)을 충족합니다.

- **FIFO 대기열 사용**: Amazon SQS FIFO 대기열은 메시지가 수신된 순서대로 처리되도록 보장하며, 주문 처리와 같이 순서가 중요한 애플리케이션에 적합합니다.
- **AWS Lambda와의 연동**: SQS FIFO 대기열의 메시지를 Lambda 함수가 순서대로 처리할 수 있도록 구성할 수 있어, 전체 아키텍처가 요구 사항을 충족합니다.

---

## Q11

``````

회사에는 Amazon EC2 인스턴스에서 실행되고 Amazon Aurora 데이터베이스를 사용하는 애플리케이션이 있습니다. EC2 인스턴스는 로컬 파일에 저장된 사용자 이름과 비밀번호를 사용하여 데이터베이스에 연결합니다. 이 회사는 자격 증명 관리의 운영 오버헤드를 최소화하려고 합니다.
솔루션 아키텍트는 이 목표를 달성하기 위해 무엇을 해야 할까요?

A. AWS Secrets Manager를 사용합니다. 자동 회전을 켭니다.

B. AWS Systems Manager Parameter Store를 사용합니다. 자동 회전을 켭니다.

C. AWS Key Management Service(AWS KMS) 암호화 키로 암호화된 객체를 저장하기 위해 Amazon S3 버킷을 만듭니다. 자격 증명 파일을 S3 버킷으로 마이그레이션합니다. 애플리케이션을 S3 버킷으로 가리킵니다.

D. 각 EC2 인스턴스에 대해 암호화된 Amazon Elastic Block Store(Amazon EBS) 볼륨을 만듭니다. 각 EC2 인스턴스에 새 EBS 볼륨을 연결합니다. 자격 증명 파일을 새 EBS 볼륨으로 마이그레이션합니다. 애플리케이션을 새 EBS 볼륨으로 가리킵니다.

``````

### 문제 상황 정리

- **현재 상황**:
   - 애플리케이션은 Amazon EC2 인스턴스에서 실행되며, Amazon Aurora 데이터베이스에 연결할 때 로컬 파일에 저장된 사용자 이름과 비밀번호를 사용합니다.
- **요구 사항**:
    - 자격 증명(데이터베이스 사용자 이름과 비밀번호)을 보다 안전하고 효율적으로 관리하여 운영 오버헤드를 최소화해야 합니다.

---

  ### 관련 기술 및 개념

  ### AWS Secrets Manager

  - **개념**:
      - AWS Secrets Manager는 애플리케이션 자격 증명, API 키, 데이터베이스 자격 증명 등을 안전하게 저장하고 관리하는 서비스입니다.
  - **주요 기능**:
      - **자동 회전(로테이션)**: 자격 증명의 주기적인 자동 교체를 지원하여, 수동으로 자격 증명을 갱신하는 작업의 운영 오버헤드를 줄여줍니다.
      - **세밀한 액세스 제어**: IAM 정책을 사용하여 자격 증명에 대한 접근을 제어할 수 있습니다.
      - **통합**: Amazon Aurora와 같은 데이터베이스와 쉽게 연동할 수 있으며, 애플리케이션이 자격 증명을 안전하게 검색하여 사용할 수 있도록 도와줍니다.

  ### AWS Systems Manager Parameter Store

  - **개념**:
      - Parameter Store는 구성 데이터와 암호와 같은 값을 저장할 수 있는 서비스입니다.
  - **제한 사항**:
      - SecureString을 사용하여 민감한 데이터를 암호화해 저장할 수 있지만, AWS Secrets Manager만큼 자격 증명의 자동 회전 기능이 내장되어 있지 않습니다.
      - 자격 증명 관리를 위해 별도의 스크립트나 추가 구성이 필요할 수 있어, 운영 오버헤드를 줄이는 측면에서 Secrets Manager보다 부적합합니다.

  ###  C와 D (S3 또는 EBS에 자격 증명 파일 저장)

  - **문제점**:
      - 이들 옵션은 자격 증명을 단순히 저장하는 위치를 변경하는 것으로, 자동 회전, 중앙 집중식 관리, 세밀한 액세스 제어와 같은 자격 증명 관리의 운영 오버헤드를 줄이는 핵심 기능을 제공하지 않습니다.

---

  AWS Secrets Manager를 사용하면:

  - 자격 증명을 안전하게 저장하고,
  - 자동 회전을 통해 주기적으로 자격 증명을 갱신할 수 있으며,
  - 애플리케이션은 API 호출을 통해 최신 자격 증명을 받아 사용할 수 있으므로,
  - 운영 오버헤드가 크게 줄어듭니다.

---

## Q12

``````

글로벌 기업이 애플리케이션 로드 밸런서(ALB) 뒤의 Amazon EC2 인스턴스에서 웹 애플리케이션을 호스팅합니다. 웹 애플리케이션에는 정적 데이터와 동적 데이터가 있습니다. 이 회사는 정적 데이터를 Amazon S3 버킷에 저장합니다. 이 회사는 정적 데이터와 동적 데이터의 성능을 개선하고 지연 시간을 줄이려고 합니다. 이 회사는 Amazon Route 53에 등록된 자체 도메인 이름을 사용하고 있습니다.
솔루션 아키텍트는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?

A. S3 버킷과 ALB를 오리진으로 하는 Amazon CloudFront 배포를 만듭니다. Route 53을 구성하여 트래픽을 CloudFront 배포로 라우팅합니다.

B. ALB를 오리진으로 하는 Amazon CloudFront 배포를 만듭니다. S3 버킷을 엔드포인트로 하는 AWS Global Accelerator 표준 가속기를 만듭니다. Route 53을 구성하여 트래픽을 CloudFront 배포로 라우팅합니다.

C. S3 버킷을 오리진으로 하는 Amazon CloudFront 배포를 만듭니다. ALB와 CloudFront 배포를 엔드포인트로 하는 AWS Global Accelerator 표준 가속기를 만듭니다. 가속기 DNS 이름을 가리키는 사용자 지정 도메인 이름을 만듭니다. 사용자 지정 도메인 이름을 웹 애플리케이션의 엔드포인트로 사용합니다.

D. ALB를 오리진으로 하는 Amazon CloudFront 배포를 만듭니다. S3 버킷을 엔드포인트로 하는 AWS Global Accelerator 표준 가속기를 만듭니다. 두 개의 도메인 이름을 만듭니다. 한 도메인 이름을 동적 콘텐츠의 CloudFront DNS 이름으로 지정합니다. 다른 도메인 이름을 정적 콘텐츠의 가속기 DNS 이름으로 지정합니다. 도메인 이름을 웹 애플리케이션의 엔드포인트로 사용합니다.

``````

### 문제 상황 정리

- **현재 환경**:
   - 웹 애플리케이션이 Amazon EC2 인스턴스에서 호스팅되며, Application Load Balancer(ALB) 뒤에서 동적 콘텐츠(예: 주문 처리, 사용자 데이터 등)를 제공하고 있음
   - 정적 콘텐츠(이미지, CSS, JavaScript, 동영상 등)는 Amazon S3 버킷에 저장됨
   - 자체 도메인 이름은 Amazon Route 53에 등록되어 있음
- **요구 사항**:
    - 정적 데이터와 동적 데이터 모두의 성능 개선 및 지연 시간 감소
    - 단일 도메인 이름을 사용하여 사용자 요청을 처리할 수 있어야 함

---

### 관련 기술 및 개념

  1. **Amazon CloudFront**
      - **CDN(콘텐츠 전송 네트워크)** 서비스로, 전 세계의 엣지 로케이션(캐시 서버)을 통해 사용자와 가까운 위치에서 콘텐츠를 제공함
      - **다중 오리진 지원**: 하나의 CloudFront 배포에 여러 오리진(예: S3 버킷, ALB)을 지정할 수 있으며, URL 경로 또는 기타 규칙에 따라 오리진을 선택할 수 있음
      - **지연 시간 감소**: 사용자 요청이 전 세계 엣지 로케이션에서 처리되므로 원본 서버까지의 거리를 줄여 지연 시간이 크게 감소됨
  2. **Amazon Route 53**
      - **DNS 서비스**로, 도메인 이름을 CloudFront 배포의 DNS 이름(알리아스 레코드)으로 매핑하여 전 세계 사용자 요청이 CloudFront를 통해 라우팅되도록 구성할 수 있음

---

  - **A**:
      - **설계**:
          - CloudFront 배포를 생성하고, 오리진으로 S3 버킷(정적 콘텐츠)과 ALB(동적 콘텐츠)를 모두 넣는다.(엣지로케이션으로 최적거리로 요청을 보내기 때문)
          - CloudFront 동작(behavior)을 설정하여, 예를 들어 URL 경로에 따라 정적 콘텐츠 요청은 S3 버킷으로, 그 외의 요청은 ALB로 전달하도록 구성할 수 있습니다.
          - Amazon Route 53에서 사용자 지정 도메인 이름을 CloudFront 배포의 DNS 이름(알리아스 레코드)으로 라우팅합니다.
      - **장점**:
          - **통합 솔루션**: 단일 CloudFront 배포를 통해 정적 및 동적 콘텐츠 모두를 전 세계 엣지 로케이션에서 빠르게 제공할 수 있습니다.
          - **지연 시간 감소**: CloudFront의 캐싱 및 글로벌 네트워크를 활용하여 사용자와 가까운 위치에서 콘텐츠를 제공하므로 응답 속도가 개선됩니다.
          - **운영 효율성**: 별도의 복잡한 구성 없이 단일 도메인 이름으로 두 종류의 콘텐츠를 효과적으로 제공할 수 있습니다.
  - **B, C, D**:
      - 옵션 B는 CloudFront와 AWS Global Accelerator를 혼합하여 구성하는데, 정적 콘텐츠에 대해 Global Accelerator를 사용하도록 설계되어 있으나, Route 53이 CloudFront로만 트래픽을 라우팅하도록 되어 있어 정적 콘텐츠 최적화가 제대로 이루어지지 않습니다.
      - 옵션 C는 ALB와 CloudFront 배포를 Global Accelerator의 엔드포인트로 사용하지만, Global Accelerator는 URL 경로별 라우팅을 지원하지 않으므로 정적/동적 콘텐츠를 분리하여 최적화하기 어렵습니다. 또한 단일 도메인 이름 사용 요구 사항과 맞지 않습니다.
      - 옵션 D는 동적 콘텐츠와 정적 콘텐츠를 별도의 도메인 이름으로 분리하는 방식으로, 사용 중인 자체 도메인 이름(단일 도메인) 요구 사항에 부합하지 않습니다.

---
**A**가 가장 적합한 솔루션입니다.

- CloudFront를 오리진으로 **S3 버킷(정적 콘텐츠)**과 **ALB(동적 콘텐츠)**를 모두 지정함으로써, 전 세계의 엣지 로케이션에서 두 종류의 콘텐츠를 최적화된 방식으로 제공할 수 있습니다.
- Amazon Route 53에서 도메인 이름을 CloudFront 배포에 매핑하면, 사용자는 단일 도메인 이름을 통해 모든 콘텐츠에 빠르게 접근할 수 있습니다.

---

## Q13

````

회사가 AWS 인프라에 대해 월별 유지 관리를 수행합니다. 이러한 유지 관리 활동 중에 회사는 여러 AWS 지역에서 Amazon RDS for MySQL 데이터베이스의 자격 증명을 순환해야 합니다.
어떤 솔루션이 가장 적은 운영 오버헤드로 이러한 요구 사항을 충족할까요?

A. 자격 증명을 AWS Secrets Manager의 비밀로 저장합니다. 필요한 리전에 다중 리전 비밀 복제를 사용합니다. Secrets Manager를 구성하여 일정에 따라 비밀을 순환합니다.

B. 보안 문자열 매개변수를 생성하여 AWS Systems Manager에서 자격 증명을 비밀로 저장합니다. 필요한 Region에 대해 다중 Region 비밀 복제를 사용합니다. Systems Manager를 구성하여 일정에 따라 비밀을 순환합니다.

C. 서버 측 암호화(SSE)가 활성화된 Amazon S3 버킷에 자격 증명을 저장합니다. Amazon EventBridge(Amazon CloudWatch Events)를 사용하여 AWS Lambda 함수를 호출하여 자격 증명을 회전합니다.

D. AWS Key Management Service(AWS KMS) 다중 지역 고객 관리 키를 사용하여 자격 증명을 비밀로 암호화합니다. Amazon DynamoDB 글로벌 테이블에 비밀을 저장합니다. AWS Lambda 함수를 사용하여 DynamoDB에서 비밀을 검색합니다. RDS API를 사용하여 비밀을 순환합니다.

````

### 문제 상황 정리

- 회사는 매월 유지 관리 활동 중 여러 AWS 리전에서 운영 중인 Amazon RDS for MySQL 데이터베이스의 자격 증명을 순환해야 합니다.
- 목표는 **최소한의 운영 오버헤드**로 자격 증명을 안전하게 관리하고 자동으로 회전하는 것입니다.

---

  ### 관련 기술 및 개념

  ### AWS Secrets Manager

  - **기능**:
      - 애플리케이션 자격 증명, 데이터베이스 사용자 이름 및 비밀번호, API 키 등 민감한 정보를 안전하게 저장하고 관리하는 서비스입니다.
  - **주요 장점**:
      - **자동 회전**: 내장된 자동 회전 기능을 통해 주기적으로 자격 증명을 갱신할 수 있으므로, 수동으로 관리할 필요가 없습니다.
      - **다중 리전 복제**: 필요한 경우 다중 리전에서 비밀을 복제할 수 있어 글로벌 인프라 환경에서 자격 증명 관리가 용이합니다.
      - **통합**: Amazon RDS와의 원활한 통합을 지원하여, 데이터베이스 자격 증명 회전을 자동화할 수 있습니다.
  - **운영 오버헤드 최소화**: Secrets Manager는 자동 회전, 보안 저장, 그리고 다중 리전 복제와 같은 기능을 기본적으로 제공하므로, 별도의 복잡한 스크립트나 수동 작업 없이 자격 증명을 관리할 수 있습니다.

---

  - **A**:
      - 자격 증명을 AWS Secrets Manager에 저장하고, 필요한 리전에서 다중 리전 비밀 복제를 사용합니다.
      - Secrets Manager의 자동 회전 기능을 활성화하면, 주기적으로 자격 증명이 자동으로 갱신되어 운영 오버헤드가 크게 줄어듭니다.
      - **결론**: AWS에서 자격 증명 회전을 관리하는 가장 간단하고 효율적인 솔루션입니다.
  - **B (AWS Systems Manager Parameter Store)**:
      - 보안 문자열 매개변수를 사용하여 자격 증명을 저장할 수 있으나, 내장된 자동 회전 기능이 부족하여 추가적인 구현이 필요합니다.
      - 결과적으로 운영 오버헤드가 증가할 수 있습니다.
  - **C (S3 및 Lambda 사용)**:
      - S3에 자격 증명을 저장하고 Lambda와 EventBridge로 회전 기능을 구현하는 방식은 자체 솔루션을 구축해야 하므로 운영 복잡성이 높습니다.
  - **D (DynamoDB, KMS, Lambda 조합)**:
      - DynamoDB 글로벌 테이블과 KMS, Lambda를 사용해 자격 증명을 관리하는 방식은 매우 복잡하며, 최소한의 운영 오버헤드를 추구하는 요구 사항에 부합하지 않습니다.

---

**A**는 AWS Secrets Manager의 자동 회전 기능과 다중 리전 비밀 복제 기능을 활용하여, 여러 AWS 리전에서 운영되는 RDS for MySQL 데이터베이스의 자격 증명을 안전하게 순환할 수 있는 가장 간단하고 관리 부담이 적은 솔루션입니다.

---

## Q14

````

회사가 ALB 뒤의 Amazon EC2 인스턴스에서 전자상거래 애플리케이션을 실행합니다. 인스턴스는 여러 가용성 영역에 걸쳐 Amazon EC2 자동 확장 그룹에서 실행됩니다. 자동 확장 그룹은 CPU 사용률 메트릭에 따라 확장됩니다. 전자상거래 애플리케이션은 대규모 EC2 인스턴스에 호스팅된 MySQL 8.0 데이터베이스에 트랜잭션 데이터를 저장합니다.
애플리케이션 부하가 증가함에 따라 데이터베이스 성능이 빠르게 저하됩니다. 애플리케이션은 쓰기 트랜잭션보다 더 많은 읽기 요청을 처리합니다. 이 회사는 높은 가용성을 유지하면서 예측할 수 없는 읽기 워크로드의 수요를 충족하도록 데이터베이스를 자동으로 확장하는 솔루션을 원합니다.
어떤 솔루션이 이러한 요구 사항을 충족할까요?

A. 리더 및 컴퓨팅 기능에 단일 노드를 갖춘 Amazon Redshift를 사용합니다.

B. 단일 AZ 배포로 Amazon RDS 사용 다른 가용성 영역에 리더 인스턴스를 추가하도록 Amazon RDS를 구성합니다.

C. Amazon Aurora를 Multi-AZ 배포와 함께 사용합니다. Aurora Replicas로 Aurora Auto Scaling을 구성합니다.

D. EC2 스팟 인스턴스와 함께 Memcached에 Amazon ElastiCache를 사용합니다.

````

### 문제 상황 정리

- 전자상거래 애플리케이션이 애플리케이션 로드 밸런서 뒤의 여러 가용 영역에 걸친 EC2 자동 확장 그룹에서 실행됩니다.
- 애플리케이션은 MySQL 8.0 데이터베이스에 트랜잭션 데이터를 저장하는데, 주로 읽기 요청이 쓰기 요청보다 많습니다.
- 애플리케이션 부하가 증가하면서 데이터베이스 성능이 빠르게 저하되고 있으며, 높은 가용성을 유지하면서 예측할 수 없는 읽기 워크로드에 대응하고자 합니다.

---

  ### 관련 기술 및 개념

  ### Amazon Aurora

  - **Amazon Aurora**는 MySQL과 호환되는 관계형 데이터베이스 서비스로, 고성능, 고가용성, 자동 복제 및 확장 기능을 제공합니다.
  - **Multi-AZ 배포**: Aurora는 기본적으로 여러 가용 영역에 걸쳐 배포되어 높은 내구성과 가용성을 보장합니다.
  - **Aurora Replicas 및 Auto Scaling**:
      - Aurora Replicas를 사용하면 읽기 요청을 여러 복제본으로 분산시켜 처리할 수 있습니다.
      - Aurora Auto Scaling 기능을 활성화하면, 읽기 부하에 따라 자동으로 Aurora Replica의 수를 조정하여 예측할 수 없는 읽기 워크로드에 대응할 수 있습니다.
      - 자세한 내용은 [Amazon Aurora 사용자 가이드](https://docs.aws.amazon.com/ko_kr/AmazonRDS/latest/AuroraUserGuide/CHAP_AuroraOverview.html)에서 확인할 수 있습니다.

---

  - **A: Amazon Redshift 단일 노드 사용**
      - **Redshift**는 데이터 웨어하우징 솔루션으로, OLTP(온라인 트랜잭션 처리) 시스템이나 전자상거래 애플리케이션의 실시간 트랜잭션 데이터베이스로 적합하지 않습니다.
      - 또한 단일 노드 구성은 고가용성과 자동 확장 요구 사항을 충족시키지 못합니다.
  - **B: 단일 AZ 배포로 Amazon RDS 사용 후 다른 가용 영역에 리더 인스턴스 추가**
      - Amazon RDS for MySQL은 읽기 복제를 지원할 수 있으나, 기본적으로 자동으로 읽기 전용 인스턴스를 추가하는 자동 확장 기능은 제공하지 않습니다.
      - 단일 AZ 배포는 고가용성을 보장하기 어렵고, 수동으로 읽기 복제본을 관리해야 하므로 운영 오버헤드가 증가합니다.
  - **C: Amazon Aurora Multi-AZ 배포와 Aurora Replicas를 통한 Auto Scaling 구성**
      - Amazon Aurora는 기본적으로 여러 가용 영역에 걸쳐 고가용성을 제공하며, 읽기 워크로드가 많은 애플리케이션에 최적화되어 있습니다.
      - Aurora Replicas와 Aurora Auto Scaling을 사용하면, 읽기 부하에 따라 자동으로 읽기 전용 복제본의 수를 조정할 수 있어 예측할 수 없는 읽기 워크로드에 유연하게 대응할 수 있습니다.
      - 이 솔루션은 높은 가용성을 유지하면서도 자동으로 데이터베이스의 읽기 용량을 확장하는 데 최적입니다.
  - **D: EC2 스팟 인스턴스와 Memcached를 사용한 Amazon ElastiCache**
      - ElastiCache(Memcached)는 캐시 솔루션으로, 읽기 부하를 줄이기 위해 데이터베이스 앞에 배치하여 캐시 히트를 통해 응답 시간을 개선할 수 있습니다.
      - 그러나 캐싱은 데이터베이스의 직접적인 확장 솔루션이 아니며, 애플리케이션의 트랜잭션 데이터 처리나 데이터의 일관성 보장 측면에서는 한계가 있습니다.
      - 또한 EC2 스팟 인스턴스는 변동성이 있으므로, 전자상거래와 같은 중요한 애플리케이션의 백엔드 데이터베이스 역할에는 적합하지 않습니다.

---

**C**가 요구 사항(높은 가용성 유지, 예측할 수 없는 읽기 워크로드에 자동 대응, 운영 오버헤드 최소화)을 가장 효과적으로 충족합니다.

  - **고가용성**: Aurora는 Multi-AZ 배포를 기본으로 지원하여 장애 발생 시에도 서비스 연속성을 보장합니다.
  - **자동 읽기 확장**: Aurora Replicas와 Auto Scaling을 통해 읽기 부하에 따라 자동으로 읽기 전용 복제본을 추가하거나 축소할 수 있습니다.
  - **읽기/쓰기 분리**: 읽기 요청이 많은 환경에서 데이터베이스의 부하를 효과적으로 분산시킬 수 있습니다.

## Q15

````

최근 AWS로 마이그레이션했고 프로덕션 VPC에서 유입되고 유출되는 트래픽을 보호하는 솔루션을 구현하려고 합니다. 이 회사는 온프레미스 데이터 센터에 검사 서버를 두었습니다. 검사 서버는 트래픽 흐름 검사 및 트래픽 필터링과 같은 특정 작업을 수행했습니다. 이 회사는 AWS 클라우드에서 동일한 기능을 원합니다.
어떤 솔루션이 이러한 요구 사항을 충족할까요?

A. 프로덕션 VPC에서 트래픽 검사 및 트래픽 필터링을 위해 Amazon GuardDuty를 사용합니다.

B. 트래픽 미러링을 사용하여 프로덕션 VPC의 트래픽을 미러링하여 트래픽 검사 및 필터링을 수행합니다.

C. AWS 네트워크 방화벽을 사용하여 프로덕션 VPC에 대한 트래픽 검사 및 트래픽 필터링에 필요한 규칙을 만듭니다.

D. AWS Firewall Manager를 사용하여 프로덕션 VPC에 대한 트래픽 검사 및 트래픽 필터링에 필요한 규칙을 만듭니다.

````

### 문제 상황 정리

회사는 AWS 프로덕션 VPC에서 인바운드와 아웃바운드 트래픽을 보호해야 합니다. 온프레미스 데이터 센터에서는 검사 서버를 사용하여 트래픽 흐름 검사 및 트래픽 필터링 작업을 수행했습니다. AWS 클라우드에서도 이와 유사하게 트래픽을 검사하고 필터링하는 기능을 원합니다.
    
---
### A. Amazon GuardDuty 사용

- **Amazon GuardDuty**는 AWS 계정과 리소스에 대한 악의적 활동이나 비정상적 동작을 탐지하는 위협 탐지 서비스입니다.
- **주요 특징**:
    - 로그 및 네트워크 활동을 모니터링하여 위협을 감지하지만, 실제로 트래픽을 차단하거나 필터링하는 기능은 제공하지 않습니다.
- **결론**: 트래픽 필터링 기능이 없으므로, 요구 사항(트래픽 검사와 필터링)에는 부적합합니다.

### B. 트래픽 미러링 사용

- **트래픽 미러링**은 VPC 내의 EC2 인스턴스에서 발생하는 네트워크 트래픽을 복제하여, 타사 보안 어플라이언스나 자체 검사 시스템으로 전송할 수 있게 해줍니다.
- **주요 특징**:
    - 트래픽 복제 및 분석에는 적합하지만, 미러링된 트래픽을 기반으로 직접 차단하거나 필터링하는 기능은 제공하지 않습니다.
- **결론**: 미러링 기능 자체는 트래픽 분석에 도움이 되지만, 요청한 **실시간 트래픽 필터링**을 직접 수행하지는 않습니다.

### C. AWS 네트워크 방화벽 사용

- **AWS 네트워크 방화벽**은 관리형 네트워크 보안 서비스로, VPC 내 트래픽에 대해 상태 기반 검사, 트래픽 필터링, 그리고 사용자 정의 규칙 적용을 지원합니다.
- **주요 특징**:
    - 트래픽 흐름을 검사하고 필터링하는 기능을 제공하여, 온프레미스에서 사용하던 검사 서버의 역할과 유사한 작업을 수행할 수 있습니다.
    - 프로덕션 VPC 내 인바운드 및 아웃바운드 트래픽을 효과적으로 보호하고 제어할 수 있습니다.
- **결론**: 요구 사항(트래픽 검사 및 필터링)을 가장 직접적으로 충족하며, 운영 오버헤드를 최소화할 수 있는 솔루션입니다.

### D. AWS Firewall Manager 사용

- **AWS Firewall Manager**는 여러 계정과 리소스에 걸쳐 AWS WAF, AWS Shield, AWS 네트워크 방화벽 등의 보안 정책을 중앙에서 관리하고 일관되게 적용할 수 있도록 도와주는 관리 도구입니다.
- **주요 특징**:
    - 자체적으로 트래픽 필터링 기능을 제공하지 않으며, 관리 및 정책 적용에 초점이 맞춰져 있습니다.
- **결론**: 단독으로 트래픽 검사나 필터링 기능을 수행하지 않으므로, 요구 사항에는 부합하지 않습니다.

---

### 최종 결론

**C, AWS 네트워크 방화벽**을 사용하면, 프로덕션 VPC의 인바운드와 아웃바운드 트래픽에 대해 필요한 검사 및 필터링 규칙을 손쉽게 구성할 수 있습니다. 이는 온프레미스 검사 서버가 수행하던 역할을 AWS 클라우드에서도 구현할 수 있도록 해주며, 운영 오버헤드도 최소화할 수 있습니다.

